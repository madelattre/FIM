<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Maud Delattre">
<meta name="author" content="Estelle Kuhn">
<meta name="dcterms.date" content="2023-07-10">
<meta name="keywords" content="Model-based standard error, moment estimate, Fisher identity, stochastic approximation algorithm">

<title>Computing an empirical Fisher information matrix estimate in latent variable models through stochastic approximation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="content_files/libs/clipboard/clipboard.min.js"></script>
<script src="content_files/libs/quarto-html/quarto.js"></script>
<script src="content_files/libs/quarto-html/popper.min.js"></script>
<script src="content_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="content_files/libs/quarto-html/anchor.min.js"></script>
<link href="content_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="content_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="content_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="content_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="content_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: #FFFFFF;
      }

      .quarto-title-block .quarto-title-banner {
        color: #FFFFFF;
background: #034E79;
      }
</style>
<link href="content_files/libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="content_files/libs/tabwid-1.1.3/tabwid.js"></script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><a href="https://computo.sfds.asso.fr">
        <img src="https://computo.sfds.asso.fr/assets/img/logo_notext_white.png" height="60px">
      </a> &nbsp; Computing an empirical Fisher information matrix estimate in latent variable models through stochastic approximation</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> source</button></div></div>
            <p><a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/80x15.png" alt="Creative Commons BY License"></a>
ISSN 2824-7795</p>
                </div>
  </div>
    
    <div class="quarto-title-meta-author">
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-heading">Affiliation</div>
          
          <div class="quarto-title-meta-contents">
        Maud Delattre 
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  Université Paris-Saclay, INRAE, MaIAGE, 78350, Jouy-en-Josas, France
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        Estelle Kuhn 
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  Université Paris-Saclay, INRAE, MaIAGE, 78350, Jouy-en-Josas, France
                </p>
            </div>
        </div>
                    
  <div class="quarto-title-meta">
                                
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 10, 2023</p>
      </div>
    </div>
                                    
      
                  
      <div>
      <div class="quarto-title-meta-heading">Keywords</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Model-based standard error, moment estimate, Fisher identity, stochastic approximation algorithm</p>
      </div>
    </div>
    
    <div>
      <div class="quarto-title-meta-heading">Status</div>
      <div class="quarto-title-meta-contents">
              <p class="date">draft</p>
                  </div>
    </div>

  </div>
                                                
  <div>
    <div class="abstract">
    <div class="abstract-title">Abstract</div>
      <p>The Fisher information matrix (FIM) is a key quantity in statistics. However its exact computation is often not trivial. In particular in many latent variable models, it is intricated due to the presence of unobserved variables. Several methods have been proposed to approximate the FIM when it can not be evaluated analytically. Different estimates have been considered, in particular moment estimates. However some of them require to compute second derivatives of the complete data log-likelihood which leads to some disadvantages. In this paper, we focus on the empirical Fisher information matrix defined as an empirical estimate of the covariance matrix of the score, which only requires to compute the first derivatives of the log-likelihood. Our contribution consists in presenting a new numerical method to evaluate this empirical Fisher information matrix in latent variable model when the proposed estimate can not be directly analytically evaluated. We propose a stochastic approximation estimation algorithm to compute this estimate as a by-product of the parameter estimate. We evaluate the finite sample size properties of the proposed estimate and the convergence properties of the estimation algorithm through simulation studies.</p>
    </div>
  </div>

  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#moment-estimates-of-the-fisher-information-matrix" id="toc-moment-estimates-of-the-fisher-information-matrix" class="nav-link" data-scroll-target="#moment-estimates-of-the-fisher-information-matrix"><span class="header-section-number">2</span> Moment estimates of the Fisher information matrix</a></li>
  <li><a href="#computing-the-estimator-i_nscotheta-in-latent-variable-model" id="toc-computing-the-estimator-i_nscotheta-in-latent-variable-model" class="nav-link" data-scroll-target="#computing-the-estimator-i_nscotheta-in-latent-variable-model"><span class="header-section-number">3</span> Computing the estimator <span class="math inline">I_{n,sco}(\theta)</span> in latent variable model</a>
  <ul class="collapse">
  <li><a href="#analytical-expressions-in-latent-variable-models" id="toc-analytical-expressions-in-latent-variable-models" class="nav-link" data-scroll-target="#analytical-expressions-in-latent-variable-models"><span class="header-section-number">3.1</span> Analytical expressions in latent variable models</a></li>
  <li><a href="#computing-i_nscotheta-using-stochastic-approximation-algorithm" id="toc-computing-i_nscotheta-using-stochastic-approximation-algorithm" class="nav-link" data-scroll-target="#computing-i_nscotheta-using-stochastic-approximation-algorithm"><span class="header-section-number">3.2</span> Computing <span class="math inline">I_{n,sco}(\theta)</span> using stochastic approximation algorithm</a>
  <ul class="collapse">
  <li><a href="#sec-algoSAEM" id="toc-sec-algoSAEM" class="nav-link" data-scroll-target="#sec-algoSAEM"><span class="header-section-number">3.2.1</span> Description of the algorithm with truncation on random boundaries in curved exponential family model</a></li>
  <li><a href="#theoretical-convergence-property" id="toc-theoretical-convergence-property" class="nav-link" data-scroll-target="#theoretical-convergence-property"><span class="header-section-number">3.2.2</span> Theoretical convergence property</a></li>
  <li><a href="#sec-generalmodel" id="toc-sec-generalmodel" class="nav-link" data-scroll-target="#sec-generalmodel"><span class="header-section-number">3.2.3</span> Description of the algorithm for general latent variables models</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-simul" id="toc-sec-simul" class="nav-link" data-scroll-target="#sec-simul"><span class="header-section-number">4</span> Simulation study</a>
  <ul class="collapse">
  <li><a href="#asymptotic-properties-of-the-estimators-i_nscotheta-and-i_nobstheta" id="toc-asymptotic-properties-of-the-estimators-i_nscotheta-and-i_nobstheta" class="nav-link" data-scroll-target="#asymptotic-properties-of-the-estimators-i_nscotheta-and-i_nobstheta"><span class="header-section-number">4.1</span> Asymptotic properties of the estimators <span class="math inline">I_{n,sco}(\theta)</span> and <span class="math inline">I_{n,obs}(\theta)</span></a>
  <ul class="collapse">
  <li><a href="#simulation-settings" id="toc-simulation-settings" class="nav-link" data-scroll-target="#simulation-settings"><span class="header-section-number">4.1.1</span> Simulation settings</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">4.1.2</span> Results</a></li>
  </ul></li>
  <li><a href="#sec-SimusNLMM" id="toc-sec-SimusNLMM" class="nav-link" data-scroll-target="#sec-SimusNLMM"><span class="header-section-number">4.2</span> Asymptotic properties of the stochastic approximation algorithm</a>
  <ul class="collapse">
  <li><a href="#sec-simuExpo" id="toc-sec-simuExpo" class="nav-link" data-scroll-target="#sec-simuExpo"><span class="header-section-number">4.2.1</span> In curved exponential family models</a></li>
  <li><a href="#sec-simuNonExpo" id="toc-sec-simuNonExpo" class="nav-link" data-scroll-target="#sec-simuNonExpo"><span class="header-section-number">4.2.2</span> In general latent variable models</a></li>
  <li><a href="#sec-simuComparison" id="toc-sec-simuComparison" class="nav-link" data-scroll-target="#sec-simuComparison"><span class="header-section-number">4.2.3</span> Comparison with other methods</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conclusion-and-discussion" id="toc-conclusion-and-discussion" class="nav-link" data-scroll-target="#conclusion-and-discussion"><span class="header-section-number">5</span> Conclusion and discussion</a></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix"><span class="header-section-number">6</span> Appendix</a>
  <ul class="collapse">
  <li><a href="#sec-algoSAEM-appendix" id="toc-sec-algoSAEM-appendix" class="nav-link" data-scroll-target="#sec-algoSAEM-appendix"><span class="header-section-number">6.1</span> Description of the algorithm without truncation on random boundaries in curved exponential family model</a></li>
  <li><a href="#theoretical-convergence-properties" id="toc-theoretical-convergence-properties" class="nav-link" data-scroll-target="#theoretical-convergence-properties"><span class="header-section-number">6.2</span> Theoretical convergence properties</a></li>
  <li><a href="#r-functions" id="toc-r-functions" class="nav-link" data-scroll-target="#r-functions"><span class="header-section-number">6.3</span> R functions</a>
  <ul class="collapse">
  <li><a href="#sec-R-exactFIMLMM" id="toc-sec-R-exactFIMLMM" class="nav-link" data-scroll-target="#sec-R-exactFIMLMM"><span class="header-section-number">6.3.1</span> Exact computation of the Fisher information matrix in the linear mixed effects model</a></li>
  <li><a href="#sec-R-estFIMLMM" id="toc-sec-R-estFIMLMM" class="nav-link" data-scroll-target="#sec-R-estFIMLMM"><span class="header-section-number">6.3.2</span> Fisher information matrix extimation in the linear mixed effects model</a></li>
  <li><a href="#sec-R-estFIMPoisson" id="toc-sec-R-estFIMPoisson" class="nav-link" data-scroll-target="#sec-R-estFIMPoisson"><span class="header-section-number">6.3.3</span> Fisher information matrix estimation in the Poisson mixture model</a></li>
  <li><a href="#sec-R-saemNLMEexp" id="toc-sec-R-saemNLMEexp" class="nav-link" data-scroll-target="#sec-R-saemNLMEexp"><span class="header-section-number">6.3.4</span> SAEM algorithm in the PK model belonging to the curved exponential family</a></li>
  <li><a href="#sec-R-saemNLMEnonexp" id="toc-sec-R-saemNLMEnonexp" class="nav-link" data-scroll-target="#sec-R-saemNLMEnonexp"><span class="header-section-number">6.3.5</span> SAEM algorithm in the PK model not belonging to the curved exponential family</a></li>
  <li><a href="#sec-R-estFIMGaussian" id="toc-sec-R-estFIMGaussian" class="nav-link" data-scroll-target="#sec-R-estFIMGaussian"><span class="header-section-number">6.3.6</span> Fisher information matrix estimation in the Gaussian mixture model</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">Bibliography</a></li>
  </ul>
</nav>
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>The Fisher information matrix (FIM) is a key quantity in statistics as it is required for examples for evaluating asymptotic precisions of parameter estimates, for building optimality criteria in experimental designs, for computing Wald test statistics or classical asymptotic distributions in statistical testing <span class="citation" data-cites="VanderVaart2000">(<a href="#ref-VanderVaart2000" role="doc-biblioref">Van der Vaart A. W. 2000</a>)</span>. It also appears more recently in post model selection inference <span class="citation" data-cites="charkhi2018asymptotic">(<a href="#ref-charkhi2018asymptotic" role="doc-biblioref">Charkhi A. and Claeskens G. 2018</a>)</span>, in asymptotic distribution of the likelihood ratio test statistics when testing variance component in mixed models <span class="citation" data-cites="baey2019asymptotic">(<a href="#ref-baey2019asymptotic" role="doc-biblioref">Baey C., Cournède P.-H., and Kuhn E. 2019</a>)</span> or as a particular Riemannian metric on complex manifold <span class="citation" data-cites="le2021fisher">(<a href="#ref-le2021fisher" role="doc-biblioref">Le Brigant A., Preston S. C., and Puechmorel S. 2021</a>)</span>. However its exact computation is often not trivial. This is in particular the case in many latent variables models, also called incomplete data models, due to the presence of the unobserved variables. Though these models are increasingly used in many fields of application, such as in ecophysiology <span class="citation" data-cites="Technow2015">(<a href="#ref-Technow2015" role="doc-biblioref">Technow F. et al. 2015</a>)</span>, in genomic <span class="citation" data-cites="Picard2007">(<a href="#ref-Picard2007" role="doc-biblioref">Picard F. et al. 2007</a>)</span> or in ecology <span class="citation" data-cites="Gloaguen2014">(<a href="#ref-Gloaguen2014" role="doc-biblioref">Gloaguen P. et al. 2014</a>)</span>. They especially allow a better consideration of the different variability sources and when appropriate, a more precise characterization of the known mechanisms at the origin of the data. When the FIM can not be exactly computed, people either approximate it numerically, for example by using Monte Carlo technics like developed in the R package MIXFIM <span class="citation" data-cites="mixfim2018">(<a href="#ref-mixfim2018" role="doc-biblioref">Riviere-Jourdan M.-K. and Mentre F. 2018</a>)</span> or focus on an estimate of the FIM. The probably most widely used is the observed FIM <span class="citation" data-cites="efron1978assessing">(<a href="#ref-efron1978assessing" role="doc-biblioref">Efron B. and Hinkley D. V. 1978</a>)</span>. When it can not be directly computed in latent variable models, several methods have been proposed to approximate it. Among the most frequently used approaches are Monte-Carlo methods or iterative algorithms derived from the missing information principle <span class="citation" data-cites="Woodbury1972">(<a href="#ref-Woodbury1972" role="doc-biblioref">Orchard T. and Woodbury M. A. 1972</a>)</span>. Indeed according to this principle, the observed Fisher information matrix can be expressed as the difference between two matrices corresponding to the complete information and the missing information due to the unobserved variables (see <em>e.g.</em> <span class="citation" data-cites="McLachlan2008">(<a href="#ref-McLachlan2008" role="doc-biblioref">McLachlan G.-J. and Krishnan T. 2008</a>)</span> chapter 4). It enables the development of alternative methods to compute the observed FIM: the Louis’s method <span class="citation" data-cites="Louis1982">(<a href="#ref-Louis1982" role="doc-biblioref">Louis T. A. 1982</a>)</span>, combined with a Monte Carlo method or a stochastic approximation algorithm by <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>, the Oakes method <span class="citation" data-cites="Oakes1999">(<a href="#ref-Oakes1999" role="doc-biblioref">Oakes D. 1999</a>)</span> or the supplemented Expectation Maximization algorithm <span class="citation" data-cites="Meng1991">(<a href="#ref-Meng1991" role="doc-biblioref">Meng X.-L. and Rubin D. B. 1991</a>)</span>. However as the observed FIM involves the second derivatives of the observed log-likelihood, all these methods require to compute second derivatives of the complete data log-likelihood which leads to some disadvantages from a computational point of view. More recently, <span class="citation" data-cites="Meng2017">(<a href="#ref-Meng2017" role="doc-biblioref">Meng L. and Spall J. C. 2017</a>)</span> proposed an accelerated algorithm based on numerical first order derivatives of the conditional expectation of the log-likelihood. Another estimate is the empirical Fisher information matrix. This estimator of the FIM is defined as the moment estimate of the covariance matrix of the score. It is much less used than the observed Fisher information matrix. However it has a nice property since it is positive definite, which is not systematically the case for the latter and it is numerically more interesting because it only requires the calculation of the first derivatives of the log-likelihood.</p>
<p>In this paper, our contribution consists in presenting a new numerical method to evaluate the empirical FIM in latent variables model. Indeed, when the proposed estimate can not be directly analytically evaluated, we propose a stochastic approximation estimation algorithm to compute it, which provides this estimate of the FIM as a by-product of model parameter estimates.</p>
<p>The paper is organized as follows. In Section 2, we recall the three main FIM estimates and discuss their immediate properties. In Section 3, we give practical tools for the computation of the empirical Fisher information matrix in incomplete data models. In particular, we introduce a new stochastic approximation procedure based on the first derivatives of the complete log-likelihood only and state its asymptotic properties. In Section 4, we illustrate the finite sample size properties of both estimators and the convergence properties of the computation algorithm through simulations. The paper ends by a discussion.</p>
</section>
<section id="moment-estimates-of-the-fisher-information-matrix" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Moment estimates of the Fisher information matrix</h1>
<p>Let us consider a random vector <span class="math inline">Y</span> taking value in <span class="math inline">\mathcal{Y}</span>. Assume <span class="math inline">Y</span> admits a density <span class="math inline">g(\cdot;\theta)</span> with respect to a given common measure <span class="math inline">\mu</span>, depending on some parameter <span class="math inline">\theta</span> taking values in an open subset <span class="math inline">\Theta</span> of <span class="math inline">\mathbb{R}^{d}</span>, such that the log-likelihood function <span class="math inline">\log g</span> is differentiable on <span class="math inline">\Theta</span> and <span class="math inline">\|\partial_\theta \log g(y;\theta) (\partial_\theta \log g(y;\theta))^t\|</span> is integrable with respect to <span class="math inline">g</span>, where <span class="math inline">x^t</span> stands for the transpose of a vector or a matrix <span class="math inline">x</span>. Then, by definition (see <span class="citation" data-cites="lehmann2006theory">(<a href="#ref-lehmann2006theory" role="doc-biblioref">Lehmann E. L. and Casella G. 2006</a>)</span>), the Fisher information matrix is given for all <span class="math inline">\theta\in\Theta</span> by: <span id="eq-fisher_der1"><span class="math display">
I(\theta) =  E_\theta\left[\partial_\theta \log g(Y;\theta) (\partial_\theta \log g(Y;\theta))^t \right].
\tag{1}</span></span></p>
<p>When this expression can not be analytically evaluated, people are interested in computing an estimate of the Fisher information matrix. Considering this expression, one can derive a first moment estimator of the Fisher information matrix based on a <span class="math inline">n</span>-sample <span class="math inline">y=(y_1, \ldots, y_{n})</span> of independent observations: <span class="math display">
I_{n,sco}(\theta,y) = \frac{1}{n} \sum_{i=1}^n I_{sco}(\theta,y_i) = \frac{1}{n} \sum_{i=1}^n \partial_\theta \log g(y_i;\theta) (\partial_\theta \log g(y_i;\theta))^t.
</span> This estimate is indeed equal to the mean of the Gram matrices of the scores.</p>
<p>Moreover, we can get another expression for the Fisher information (see <span class="citation" data-cites="lehmann2006theory">(<a href="#ref-lehmann2006theory" role="doc-biblioref">Lehmann E. L. and Casella G. 2006</a>)</span>). If we assume that the set <span class="math inline">A=\{y, g(y;\theta)&gt;0\}</span> is independent of <span class="math inline">\theta</span>, that for <span class="math inline">\mu</span>-almost all <span class="math inline">y</span>, <span class="math inline">g(y;\cdot)</span> is differentiable on <span class="math inline">\Theta</span>, and that the derivative with respect to <span class="math inline">\theta</span> on the left side of <span id="eq-density"><span class="math display">\int g(y;\theta)d\mu(y)=1 \tag{2}</span></span> can be obtained by differentiating under the integral sign, then the Fisher information matrix is given for all <span class="math inline">\theta\in\Theta</span> by: <span id="eq-fisher_der2"><span class="math display">
I(\theta) =  V_\theta\left[\partial_\theta \log g(Y;\theta) \right].
\tag{3}</span></span></p>
<p>One can also derive a second estimate from this expression defined as <span class="math display">
I_{n,cov}(\theta,y) = \frac{1}{n} \sum_{i=1}^n \partial_\theta \log g(y_i;\theta) (\partial_\theta \log g(y_i;\theta))^t-\bar{s}(\theta,y)\bar{s}(\theta,y)^t,
</span> where <span class="math inline">\bar{s}(\theta,y)=\frac{1}{n}\sum_{i=1}^n \partial_\theta \log g(y_i;\theta)</span> (see <em>e.g.</em> <span class="citation" data-cites="Scott2002">(<a href="#ref-Scott2002" role="doc-biblioref">Scott W.-A. 2002</a>)</span>). We emphasize here that the terminology “empirical Fisher information matrix” is used in the literature for both estimates (see <em>e.g.</em> <span class="citation" data-cites="kunstner2019limitations">(<a href="#ref-kunstner2019limitations" role="doc-biblioref">Kunstner F., Hennig P., and Balles L. 2019</a>)</span>).</p>
<p>Moreover if additionally the second derivative with respect to <span class="math inline">\theta</span> of <span class="math inline">\log g(y;\theta)</span> exists for all <span class="math inline">y</span> and <span class="math inline">\theta</span> and the second derivative with respect to <span class="math inline">\theta</span> of the left side of <a href="#eq-density">Equation&nbsp;2</a> can be obtained by differentiating twice under the integral sign (see <span class="citation" data-cites="lehmann2006theory">(<a href="#ref-lehmann2006theory" role="doc-biblioref">Lehmann E. L. and Casella G. 2006</a>)</span>), we have <span id="eq-fisher_der2"><span class="math display">
I(\theta) =  - E_\theta\left[\partial_\theta^2 \log g(Y;\theta) \right].
\tag{4}</span></span></p>
<p>Considering this third expression, we can derive another moment estimator of the Fisher information matrix based on a <span class="math inline">n</span>-sample <span class="math inline">(y_1, \ldots, y_{n})</span> of observations, called the observed Fisher information matrix defined as: <span class="math display">
I_{n,obs}(\theta,y) = \frac{1}{n}\sum_{i=1}^n I_{obs}(\theta,y_i) = - \frac{1}{n} \sum_{i=1}^n \partial_\theta^2 \log g(y_i;\theta).
</span></p>
<p>Some detailed discussion about the three estimators above can be found in <span class="citation" data-cites="Scott2002">(<a href="#ref-Scott2002" role="doc-biblioref">Scott W.-A. 2002</a>)</span>.</p>
<div class="remark proof">
<p><span class="proof-title"><em>Remark</em>. </span>We emphasize that the estimate <span class="math inline">I_{n,sco}(\theta,y)</span> is always positive semi-definite, since it is a mean of Gram matrices, contrary to the others estimates <span class="math inline">I_{n,obs}(\theta,y)</span> and <span class="math inline">I_{n,cov}(\theta,y)</span>. Moreover assuming <span class="math inline">n</span> sufficiently large allows to prove positive definiteness of <span class="math inline">I_{n,sco}(\theta,y)</span>. Consider for any nonzero vector <span class="math inline">x</span> the quantity <span class="math inline">x^t I_{n,sco}(\theta,y) x</span>. We have that <span class="math inline">x^t I_{n,sco}(\theta,y) x = ( \sum_{i=1}^n x^t \partial_{\theta} \log g(y_i;\theta) \partial_{\theta} \log g(y_i;\theta)^t x )/n= \sum_{i=1}^n (x^t \partial_{\theta} \log g(y_i;\theta))^2/n</span>. Thus, <span class="math inline">x^t I_{n,sco}(\theta,y) x=0</span> implies that <span class="math inline">x^t \partial_{\theta} \log g(y_i;\theta)=0</span> for all <span class="math inline">1 \leq i \leq n</span>. If <span class="math inline">n</span> is sufficiently large, there exist <span class="math inline">d</span> indexes <span class="math inline">i_1, ..., i_d</span> such that the family of vectors <span class="math inline">\{\partial_{\theta} \log g(y_{i_l};\theta), 1 \leq l \leq d\}</span> is linearly independent. Thus this implies that <span class="math inline">x=0</span> leading to the results.</p>
</div>
<div class="remark proof">
<p><span class="proof-title"><em>Remark</em>. </span>The asymptotical properties of the estimates <span class="math inline">I_{n,sco}(\theta,y)</span> and <span class="math inline">I_{n,obs}(\theta,y)</span> are straighforward when considering independent and identically distributed sample <span class="math inline">(y_1, \ldots, y_{n})</span>. In particular, assuming standard regularity conditions on <span class="math inline">g</span>, it follows directly from the central limit theorem that <span class="math inline">I_{n,sco}(\theta,y)</span> and <span class="math inline">I_{n,obs}(\theta,y)</span> are asymptotically normal. If the variables <span class="math inline">Y_1, \ldots, Y_{n}</span> are independent not identically distributed, for example if their distributions depend on some individual covariates which is often the case in practice, we can also get asymptotic properties for the estimates assuming more strengthed reguarity conditions by applying for example the Kolmogorov criterion (see <em>e.g.</em> <span class="citation" data-cites="feller1968">(<a href="#ref-feller1968" role="doc-biblioref">Feller W. 1968</a>)</span>) for the consistency and the Lindeberg theorem for the normality result (see theorem 27.2 of <span class="citation" data-cites="billingsley2013convergence">(<a href="#ref-billingsley2013convergence" role="doc-biblioref">Billingsley P. 2013</a>)</span>).</p>
</div>
<div class="remark proof">
<p><span class="proof-title"><em>Remark</em>. </span>Since both estimators <span class="math inline">I_{n,sco}(\theta,y)</span> and <span class="math inline">I_{n,obs}(\theta,y)</span> are moment estimates of <span class="math inline">I(\theta)</span>, they are unbiased for all <span class="math inline">\theta \in \Theta</span>. This is not the case for <span class="math inline">I_{n,cov}(\theta,y)</span>. Regarding the variance, none of both estimators is better than the other one. This can be highlighted through the following examples. First consider a Gaussian sample with unknown expectation and fixed variance. Then, the variance of the estimator <span class="math inline">I_{n,obs}(\theta,y)</span> is zero whereas the variance of the estimator <span class="math inline">I_{n,sco}(\theta,y)</span> is positive. Second consider a centered Gaussian sample with unknown variance. Then, the variance of <span class="math inline">I_{n,sco}(\theta,y)</span> is smaller than the variance of <span class="math inline">I_{n,obs}(\theta,y)</span>. Therefore, none of both estimators is more suitable than the other in general from this point of view.</p>
</div>
</section>
<section id="computing-the-estimator-i_nscotheta-in-latent-variable-model" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Computing the estimator <span class="math inline">I_{n,sco}(\theta)</span> in latent variable model</h1>
<p>Let us consider independent random variables <span class="math inline">Y_1, \ldots, Y_{n}</span>. Assume in the sequel that there exist independent random variables <span class="math inline">Z_1, \ldots, Z_{n}</span> taking values in <span class="math inline">\mathcal{Z}</span> and a measure <span class="math inline">\lambda</span> on <span class="math inline">\mathcal{Z}</span> such that for each <span class="math inline">1 \leq i \leq n</span>, the random vector <span class="math inline">(Y_i,Z_i)</span> admits a parametric probability density function denoted by <span class="math inline">f</span> parametrized by <span class="math inline">\theta \in \Theta</span> with respect to <span class="math inline">\mu \times \lambda</span> on <span class="math inline">\mathcal{Y}\times\mathcal{Z}</span>. We present in this section dedicated tools to compute the estimator <span class="math inline">I_{n,sco}(\theta)</span> in latent variable model when it can not be evaluated analytically.</p>
<section id="analytical-expressions-in-latent-variable-models" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="analytical-expressions-in-latent-variable-models"><span class="header-section-number">3.1</span> Analytical expressions in latent variable models</h2>
<p>In latent variable models, the estimator <span class="math inline">I_{n,sco}(\theta,y)</span> can be expressed using the conditional expectation as stated in the following proposition.</p>
<div id="prp-fisherequality" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 1 </strong></span>Assume that for all <span class="math inline">y</span> and all <span class="math inline">\theta \in \Theta</span> the function <span class="math inline">f(y,.;\theta)</span> is integrable with respect to <span class="math inline">\lambda</span>, that for all <span class="math inline">y</span> and for <span class="math inline">\lambda</span>-almost all <span class="math inline">z</span> the function <span class="math inline">f(y,z;\cdot)</span> is differentiable on <span class="math inline">\Theta</span>, that there exists a mesurable function <span class="math inline">m</span> such that <span class="math inline">\int m(z) \lambda(dz)&lt; \infty</span> and for all <span class="math inline">\theta \in \Theta</span> and for <span class="math inline">\lambda</span>-almost all <span class="math inline">z</span> <span class="math inline">|\partial_\theta f(y,z;\theta)|\leq m(z)</span>. Then for all <span class="math inline">\theta \in \Theta</span> and all <span class="math inline">n \in \mathbb{N}^*</span>:</p>
<p><span id="eq-vnmis"><span class="math display">
I_{n,sco}(\theta) = \frac{1}{n} \sum_{i=1}^n \mathrm{E}_{Z_i|Y_i;\theta} (\partial_\theta \log f(Y_i,Z_i;\theta) ) \mathrm{E}_{Z_i|Y_i;\theta} (\partial_\theta \log f(Y_i,Z_i;\theta) )^t,
\tag{5}</span></span></p>
<p>where <span class="math inline">\mathrm{E}_{Z|Y;\theta}</span> denotes the expectation under the law of <span class="math inline">Z</span> conditionally to <span class="math inline">Y</span>.</p>
</div>
<p>We apply the classical Fisher identity <span class="citation" data-cites="fisher1925">(<a href="#ref-fisher1925" role="doc-biblioref">Fisher R.A. 1925</a>)</span> to establish the equality stated in <a href="#prp-fisherequality">Proposition&nbsp;1</a>. We refer to Proposition 100 of <span class="citation" data-cites="cappe2005">(<a href="#ref-cappe2005" role="doc-biblioref">Cappé O., Moulines E., and Rydén T. 2005</a>)</span> for the statement of the Fisher identity. This statement is indeed in the same spirit as the well-known Louis formulae for the observed Fisher information matrix estimate <span class="citation" data-cites="Louis1982">(<a href="#ref-Louis1982" role="doc-biblioref">Louis T. A. 1982</a>)</span>. The result follows directly.</p>
<div class="remark proof">
<p><span class="proof-title"><em>Remark</em>. </span>In some specific cases the conditional expectations involved in the previous proposition admit exact analytical expressions for example in mixture models which are developed in <a href="#sec-simul">Section&nbsp;4</a> in some simulation studies.</p>
</div>
</section>
<section id="computing-i_nscotheta-using-stochastic-approximation-algorithm" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="computing-i_nscotheta-using-stochastic-approximation-algorithm"><span class="header-section-number">3.2</span> Computing <span class="math inline">I_{n,sco}(\theta)</span> using stochastic approximation algorithm</h2>
<p>When exact computation of the estimator <span class="math inline">I_{n,sco}(\theta)</span> is not possible for all <span class="math inline">\theta\in\Theta</span>, we propose to evaluate its value by using a new stochastic algorithm which provides the estimate <span class="math inline">I_{n,sco}(\bar{\theta}_{ML})</span> as a by-product of the maximum likelihood estimate <span class="math inline">\bar{\theta}_{ML}</span>. More precisely we provide three algorithms: a first one in the curved exponential family context which requires to simulate the latent variable from a transition kernel of an ergodic Markov chain and assumes less strength assumptions to get theoretical convergence result thanks to a truncation on random boundaries step, a second one in the curved exponential family context which does not include this additional projection step but requires more strength assumptions to ensure theoretical convergence. This second one and the related results are presented in Appendix. Finally we provide a third algorithm dedicated to general latent variables models without any theoretical results as it is usually the case for such kind of methods (see <a href="#sec-generalmodel">Section&nbsp;3.2.3</a>).</p>
<section id="sec-algoSAEM" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="sec-algoSAEM"><span class="header-section-number">3.2.1</span> Description of the algorithm with truncation on random boundaries in curved exponential family model</h3>
<p>We develop an extension of the stochastic approximation Expectation Maximization algorithm coupled with a Monte Carlo Markov Chain studied by <span class="citation" data-cites="Allassonniere2010">(<a href="#ref-Allassonniere2010" role="doc-biblioref">Allassonnière S., Kuhn E., and Trouvé A. 2010</a>)</span> which allows to compute simultaneously the maximum likelihood estimate and the FIM estimate proposed in the previous section. We assume in this section that all the individual complete log-likelihoods belong to the curved exponential family (see <span class="citation" data-cites="bickel2015mathematical">(<a href="#ref-bickel2015mathematical" role="doc-biblioref">Bickel P. J. and Doksum K. A. 2015</a>)</span>) for stating the theoretical results. As our estimate involves individual conditional expectations, we have to consider an extended form of sufficient statistics for the model at the individual level. Indeed, it is necessary to compute stochastic approximation of each individual sufficient statistic at individual level since there are required to be able to compute the proposed FIM estimate. This is the main difference with the usual algorithm. Therefore we introduce the following notations and assumptions.</p>
<p>The individual complete data likelihood function is given for all <span class="math inline">1 \leq i \leq n</span> by: <span id="eq-curvedexpo"><span class="math display">
f_i(z_i;\theta) = \exp\left(-\psi_i(\theta) + \left&lt;S_i(z_i),\phi_i(\theta)\right&gt;\right),
\tag{6}</span></span> where <span class="math inline">\left&lt;\cdot,\cdot\right&gt;</span> denotes the scalar product, <span class="math inline">S_i</span> is a function on <span class="math inline">\mathbb{R}^{d_i}</span> taking its values in a subset <span class="math inline">\mathcal{S}_i</span> of <span class="math inline">\mathbb{R}^{m_i}</span>.</p>
<p>Let us denote for all <span class="math inline">1 \leq i \leq n</span> by <span class="math inline">L_i</span> the function defined on <span class="math inline">\mathcal{S}_i \times \Theta</span> by <span class="math inline">L_i(s_i; \theta)\triangleq - \psi_i(\theta) + \left&lt;s_i,\phi_i(\theta)\right&gt;</span> and by <span class="math inline">L: \mathcal{S} \times \Theta \to \mathbb{R}</span> the function defined as <span class="math inline">L(s,\theta)=\sum_i L_i(s_i; \theta)</span> with <span class="math inline">\mathcal{S}=\prod_i \mathcal{S}_i</span> and <span class="math inline">s=(s_1,\ldots,s_n)</span>. For sake of simplicity, we omitted all dependency on the observations <span class="math inline">(y_i)_{1 \leq i \leq n}</span> since the considered stochasticity relies here on the latent variables.</p>
<p>Finally let us denote by <span class="math inline">(\gamma_k)_{k \geq 1}</span> and <span class="math inline">(\varepsilon_k)_{k \geq 1}</span> sequences of positive step sizes, by <span class="math inline">\mathrm{K}</span> a compact set of <span class="math inline">\mathbb{R}^d</span> with <span class="math inline">d=\sum d_i</span> and by <span class="math inline">(\mathcal{K}_k)</span> a sequence of increasing compact sets of <span class="math inline">\mathcal{S}</span> such that <span class="math inline">\cup \mathcal{K}_k=\mathcal{S}</span> and for all <span class="math inline">k</span> <span class="math inline">\mathcal{K}_{k} \subset int(\mathcal{K}_{k+1} )</span>.</p>
<p>Moreover we assume that there exists a function <span class="math inline">\widehat{\theta} : \ \mathcal{S} \rightarrow \Theta</span>, such that <span class="math inline">\forall s \in \mathcal{S}, \ \  \forall \theta \in \Theta, \ \ L(s; \widehat{\theta}(s))\geq L(s; \theta).</span></p>
<p><strong>Initialization step</strong>: Initialize arbitrarily for all <span class="math inline">1 \leq i \leq n</span> <span class="math inline">s_i^0</span> and <span class="math inline">\theta_0</span>. Set <span class="math inline">\kappa_0=\zeta_0=\nu_0=0</span>.</p>
<p><strong>Repeat until convergence the three steps defined at iteration <span class="math inline">k</span> by</strong>:</p>
<ul>
<li><p><strong>Simulation step</strong>: for <span class="math inline">1 \leq i \leq n</span> simulate a realization <span class="math inline">\bar{Z}_i</span> from a parametric transition kernel <span class="math inline">\Pi_i</span> of a Markov Chain parametrized by the current parameter value <span class="math inline">\theta_{k-1}</span> and having the conditional distribution given the observations <span class="math inline">Y_i</span> denoted by <span class="math inline">p_i</span> as stationary distribution</p></li>
<li><p><strong>Stochastic approximation step</strong>: compute the quantities for all <span class="math inline">1 \leq i \leq n</span> <span class="math display">
\bar{s_i} = (1-\gamma_k)s_i^{k-1} +\gamma_k  S_i(Z_i^k)
</span> where <span class="math inline">(\gamma_k)</span> is a sequence of positive step sizes satisfying <span class="math inline">\sum \gamma_k=\infty</span> and <span class="math inline">\sum \gamma_k^2 &lt;~\infty</span>.</p></li>
<li><p><strong>Truncation step</strong>: Let us denote <span class="math inline">\bar{Z}=(\bar{Z_i})</span>, <span class="math inline">\bar{s}=(\bar{s_i})</span> and <span class="math inline">s=(s_i)</span>. If <span class="math inline">\bar{s}\in\mathcal{K}_{\kappa_{k-1}}</span> and <span class="math inline">\|\bar{s}-s_{k-1} \|\leq \varepsilon_{\zeta_{k-1}}</span>, then set <span class="math inline">(Z^k,s^k)=(\bar{Z},\bar{s})</span>, <span class="math inline">\kappa_{k}=\kappa_{k-1}</span>, <span class="math inline">\nu_{k}=\nu_{k-1}+1</span>, <span class="math inline">\zeta_{k}=\zeta_{k-1}+1</span>, else set <span class="math inline">(Z^k,s^k)=(\tilde{Z},\tilde{s})\in \mathrm{K}\times \mathcal{K}_0</span>, <span class="math inline">\kappa_{k}=\kappa_{k-1}+1</span>, <span class="math inline">\nu_{k}=0</span>, <span class="math inline">\zeta_{k}=\zeta_{k-1}+ \Psi(\nu_{k-1})</span> where <span class="math inline">\Psi:\mathbb{N} \rightarrow \mathbb{Z}</span> is a function such that <span class="math inline">\Psi(k)&gt;k</span> for any <span class="math inline">k</span> and <span class="math inline">(\tilde{Z},\tilde{s})</span> chosen arbitrarily.</p></li>
<li><p><strong>Maximisation step</strong>: update of the parameter estimator according to: <span class="math display">
\theta_{k} = \arg \max_{\theta}  \sum_{i=1}^n \left( -\psi_i(\theta) + \left&lt;s_i^k,\phi_i(\theta)\right&gt;\right) = \hat{\theta}(s^{k})
</span></p></li>
</ul>
<p><strong>When convergence is reached, say at iteration <span class="math inline">K</span> of the algorithm, evaluate the FIM estimator according to</strong>: <span class="math display">
I_{n,sco}^K = \frac{1}{n} \sum_{i=1}^n \hat{\Delta}_i\left(s^{K}\right) \hat{\Delta}_i\left(s^{K}\right)^t
</span> where <span class="math inline">\hat{\Delta}_i(s) = -\partial \psi_i(\hat{\theta}(s)) + \left&lt;s_i,\partial \phi_i(\hat{\theta}(s))\right&gt;</span> for all <span class="math inline">s</span>.</p>
<div class="remark proof">
<p><span class="proof-title"><em>Remark</em>. </span>Note that the projection step which is done through the truncation procedure on random boundaries ensures the stability of the algorithm in particular for the theoretical analysis provided below. More details on this projection step are available in <span class="citation" data-cites="Andrieu2005">(<a href="#ref-Andrieu2005" role="doc-biblioref">Andrieu C., Moulines E., and Priouret P. 2005</a>)</span>.</p>
</div>
</section>
<section id="theoretical-convergence-property" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="theoretical-convergence-property"><span class="header-section-number">3.2.2</span> Theoretical convergence property</h3>
<p>The theoretical result provided in this section for the sequence <span class="math inline">(\theta_k)</span> generated by the algorithm with truncation on random boundaries is based on that of <span class="citation" data-cites="Allassonniere2010">(<a href="#ref-Allassonniere2010" role="doc-biblioref">Allassonnière S., Kuhn E., and Trouvé A. 2010</a>)</span>. Indeed it established convergence guarantees for the FIM estimate obtained as a by-product of that for the MLE. To that purpose, in addition to the exponential family assumption for each individual likelihood, we also make the same type of regularity assumptions as those presented in <span class="citation" data-cites="Allassonniere2010">(<a href="#ref-Allassonniere2010" role="doc-biblioref">Allassonnière S., Kuhn E., and Trouvé A. 2010</a>)</span> at each individual level. These assumptions are detailed in the appendix section.</p>
<p>We establish our theoretical result for transition kernels <span class="math inline">(\Pi_i)</span> corresponding to those of the random walk Metropolis Hastings algorithm <span class="citation" data-cites="jarner2000">(<a href="#ref-jarner2000" role="doc-biblioref">Jarner S. F. and Hansen E. 2000</a>)</span>. We denote by <span class="math inline">(q_i)</span> the family of symmetric densities used to generate the candidate with the proposal distribution. We introduce additional assumptions required to control the stochastic behavior of the algorithm:</p>
<ul>
<li><p><strong>(H1)</strong> There exists a constant <span class="math inline">M_0</span> such that <span class="math display">
\begin{split}
\mathcal L=
\left\{s\in\mathcal S, \langle \nabla l(\hat\theta(s)), h(s)\rangle=0
\right\}\\
\subset
\{s\in\mathcal S, -l(\hat\theta(s))&lt;M_0
\}.
\end{split}
</span> In addition, there exist <span class="math inline">M_1\in(M_0,\infty]</span> such that <span class="math inline">\{s\in\mathcal S, -l(\hat\theta(s)) \leq M_1 \}</span> is a compact set.</p></li>
<li><p><strong>(H2)</strong> For all <span class="math inline">s\in\mathcal{S}</span>, <span class="math inline">\lim_{z \rightarrow \infty} n(z).\nabla_z \log p(z;\hat{\theta}(s))=-\infty</span> and <span class="math inline">\lim_{z \rightarrow \infty} \sup n(z).m_s(z) &lt;0</span> where where <span class="math inline">n(z)=z/|z|</span> for <span class="math inline">z \neq 0</span>, and <span class="math inline">m_s(z)=\nabla_z p(z;\hat{\theta}(s)) /p(z;\hat{\theta}(s))</span> with <span class="math inline">p(z;\theta)=\prod_i p_i(z_i;\theta)</span>.</p></li>
<li><p><strong>(H3)</strong> The family <span class="math inline">\{q_i\}_{1\le i \le n}</span> of symmetric densities is such that, for <span class="math inline">i = 1,\dots,n</span>, there exist constants <span class="math inline">\eta_i &gt; 0</span> and <span class="math inline">\delta_i &lt;\infty</span> such that <span class="math inline">q_i (z) &gt; \eta_i</span> for all <span class="math inline">|z|&lt; \delta_i</span>.</p></li>
<li><p><strong>(H4)</strong> There exist <span class="math inline">C&gt;1</span>, <span class="math inline">\rho\in(0,1)</span> and <span class="math inline">\theta_0 \in \Theta</span> such that, for all <span class="math inline">z\in\mathbb{R}^d</span>, <span class="math display">
|S(z)|\le C p(z;\theta_0)^{-\rho}.
</span></p></li>
</ul>
<div class="remark proof">
<p><span class="proof-title"><em>Remark</em>. </span>Assumption <span class="math inline">(H2)</span> is standard and usually called super-exponentiality property in the literature <span class="citation" data-cites="jarner2000">(<a href="#ref-jarner2000" role="doc-biblioref">Jarner S. F. and Hansen E. 2000</a>)</span>.</p>
</div>
<div class="remark proof">
<p><span class="proof-title"><em>Remark</em>. </span>We established our results for transition kernels corresponding to random walk Metropolis Hastings algorithms which are of common use in practice. We emphasize that our result can be generalised to more general transition kernels by replacing our assumptions <span class="math inline">(H2)</span> and <span class="math inline">(H3)</span> by assumption <span class="math inline">(DRI)</span> of <span class="citation" data-cites="Andrieu2005">(<a href="#ref-Andrieu2005" role="doc-biblioref">Andrieu C., Moulines E., and Priouret P. 2005</a>)</span> which is more generic. The latter can be verified in practice for more general transition kernels.</p>
</div>
<div id="thm-conv.algo" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 </strong></span>Assume that <span class="math inline">(M1')</span> and <span class="math inline">(M2')</span>, <span class="math inline">(M3)</span> to <span class="math inline">(M5)</span>, <span class="math inline">(SAEM1)</span> and <span class="math inline">(SAEM2)</span>, <span class="math inline">(H1)</span> to <span class="math inline">(H4)</span> are fulfilled. Let us define <span class="math inline">\mathcal{L}=\{\theta \in\Theta, \partial_\theta l(y;\theta)=0\}</span> the set of stationary points of the observed log-likelihood <span class="math inline">l</span> defined as <span class="math inline">l(y;\theta)=\sum_{i=1}^n \log g(y_i;\theta)</span>. Then, for all <span class="math inline">\theta_0 \in \Theta</span>, for fixed <span class="math inline">n \in \mathbb{N}^*</span>, we get: <span class="math inline">\lim_k d(\theta_k,\mathcal{L})=0</span> a.s. and <span class="math inline">\lim_k d(I_{n,sco}^k,\mathcal{I})=0</span> a.s. where <span class="math inline">\mathcal{I}=\{I_{n,sco}(\theta), \theta \in \mathcal{L}\}</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let us denote by <span class="math inline">S(Z)=(S_1(Z_1),\ldots,S_n(Z_n))</span> the sufficient statistics of the model we consider in our approach. Let us also define <span class="math inline">H(Z,s)=S(Z)-s</span> and <span class="math inline">h(s)=\mathrm{E}_{Z|Y;\hat{\theta}(s)}(S(Z))-s</span>. The proof is composed of two steps following for example the lines of <span class="citation" data-cites="Allassonniere2010">(<a href="#ref-Allassonniere2010" role="doc-biblioref">Allassonnière S., Kuhn E., and Trouvé A. 2010</a>)</span>. First we establish the almost sure convergence of the sequence <span class="math inline">(s_k)</span> generated by the algorithm toward the zero of the function <span class="math inline">h</span>. Second we deduce the almost sure convergence of the sequences <span class="math inline">(\theta_k)</span> and <span class="math inline">(I_{n,sco}^k)</span> toward the set of critical points of the observed log-likelihood and the set <span class="math inline">\mathcal{I}</span> respectively.</p>
<p>To prove the first step we apply Theorem 5.5 of <span class="citation" data-cites="Andrieu2005">(<a href="#ref-Andrieu2005" role="doc-biblioref">Andrieu C., Moulines E., and Priouret P. 2005</a>)</span>. Therefore we have to verify that their four conditions denoted <span class="math inline">(A1)</span> to <span class="math inline">(A4)</span> are fulfilled. Our proof will follow the same global strategy as for example the one of Theorem 1 in <span class="citation" data-cites="kuhn2020">(<a href="#ref-kuhn2020" role="doc-biblioref">Kuhn E., Matias C., and Rebafka T. 2020</a>)</span>. We get first that condition <span class="math inline">(A1)</span> is satisfied by applying Lemma 2 of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>. Indeed our assumptions <span class="math inline">(M1')</span> and <span class="math inline">(M2')</span> imply that assumptions <span class="math inline">(M1)</span> and <span class="math inline">(M2)</span> of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span> are satisfied. These assumptions <span class="math inline">(M1')</span> and <span class="math inline">(M2')</span> focus on expressions and regularity properties of the individual likelihood functions and the corresponding sufficient statistics for each index <span class="math inline">i \in \{1,\ldots,n\}</span>. The implication above follows by linearity of the log-likelihood function. Then we get that assumptions <span class="math inline">(H1), (M1)-(M5), (SAEM2)</span> ensured that condition <span class="math inline">(A1)</span> is satisfied. To prove assumptions <span class="math inline">(A2)</span> and <span class="math inline">(A3)</span>, we will follow the strategy of <span class="citation" data-cites="Allassonniere2010">(<a href="#ref-Allassonniere2010" role="doc-biblioref">Allassonnière S., Kuhn E., and Trouvé A. 2010</a>)</span> to handle the difficulty of finding a common drift function <span class="math inline">V</span> for the family of posterior distributions indexed by <span class="math inline">s \in \mathcal{S}</span>. Therefore we will construct first a family of drift functions <span class="math inline">(V_s)</span> using Proposition 6.1 of <span class="citation" data-cites="Andrieu2005">(<a href="#ref-Andrieu2005" role="doc-biblioref">Andrieu C., Moulines E., and Priouret P. 2005</a>)</span>, which stated drift conditions, called <span class="math inline">(DRI)</span>, easy to very in practice. To prove condition <span class="math inline">(DRI1)</span> for each kernels, we use Theorem 4.1 and Theorem 4.3 of <span class="citation" data-cites="jarner2000">(<a href="#ref-jarner2000" role="doc-biblioref">Jarner S. F. and Hansen E. 2000</a>)</span> which stated that assumptions <span class="math inline">(H2)</span>,<span class="math inline">(H3)</span> and <span class="math inline">(H4)</span> imply that Equations <span class="math inline">(6.1)</span> and <span class="math inline">(6.3)</span> of <span class="math inline">(DRI1)</span> are satisfied with <span class="math inline">m=1</span> and <span class="math inline">V_s(z)= p(z;\hat{\theta}(s))^{- \rho}</span> with <span class="math inline">\rho</span> given by <span class="math inline">(H4)</span>. Then the common drift function is defined by <span class="math inline">V(z)= p(z;\theta_0)^{- \rho}</span> using assumption <span class="math inline">(H4)</span>. Thus for any compact <span class="math inline">\mathcal{K}</span> of <span class="math inline">\Theta</span>, there exist constants <span class="math inline">c_{\mathcal{K}}&gt;0</span> and <span class="math inline">C_{\mathcal{K}}&gt;0</span> such that for all <span class="math inline">\theta \in \mathcal{K}</span> and for all <span class="math inline">z</span>, <span class="math inline">c_{\mathcal{K}} V(z)\leq p(z;\hat{\theta}(s))^{- \rho} \leq C_{\mathcal{K}}V(z)</span>. Therefore Equations <span class="math inline">(6.1)</span> and <span class="math inline">(6.3)</span> are satisfied for this common drift function <span class="math inline">V</span>. Equation <span class="math inline">(6.2)</span> follows also from Theorem 2.1 of <span class="citation" data-cites="jarner2000">(<a href="#ref-jarner2000" role="doc-biblioref">Jarner S. F. and Hansen E. 2000</a>)</span> which concludes the proof of <span class="math inline">(DRI1)</span>. The first part of <span class="math inline">(DRI2)</span> is ensured by assumption <span class="math inline">(H4)</span>. The second part is satisfied directly with Lipschitz exponent <span class="math inline">\beta</span> equal to <span class="math inline">1</span> in our case. Finally assumption <span class="math inline">(DRI3)</span> is satisfied also with <span class="math inline">\beta=1</span> in our framework. This proof is obtained by using the usual strategy of splitting the whole space in four parts depending on the acceptance region and on the rejection region (see the proof of Lemma 4.7 in <span class="citation" data-cites="Fort2015">(<a href="#ref-Fort2015" role="doc-biblioref">Fort G. et al. 2015</a>)</span> for example) and the fact that the function <span class="math inline">\hat\theta</span> is twice continuously differentiable. Finally assumption <span class="math inline">(SAEM1)</span> allows to choose a sequence <span class="math inline">(\varepsilon_k)</span> such that <span class="math inline">(A4)</span> is satisfied (see constructive details in <span class="citation" data-cites="Andrieu2005">(<a href="#ref-Andrieu2005" role="doc-biblioref">Andrieu C., Moulines E., and Priouret P. 2005</a>)</span> after the statement of assumption <span class="math inline">(A4)</span>). This concludes the proof of the first step.</p>
<p>The function <span class="math inline">\hat\theta</span> being continuous, we get that <span class="math inline">\lim_k d(\theta_k,\mathcal{L})=0</span> applying Lemma 2 of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>. Moreover we get that for <span class="math inline">1 \leq i \leq n</span>, each sequence <span class="math inline">(s_i^k)</span> converges almost surely toward <span class="math inline">\mathrm{E}_{Z_i|Y_i;\theta} (S_i(Z_i) )</span>. Since assumption <span class="math inline">(M2')</span> ensures that for all <span class="math inline">1 \leq i \leq n</span> the functions <span class="math inline">\psi_i</span> and <span class="math inline">\phi_i</span> are twice continuously differentiable and assumption <span class="math inline">(M5)</span> ensures that the function <span class="math inline">\hat{\theta}</span> is continuously differentiable, the function <span class="math inline">\Phi_n</span> defined by <span class="math inline">\Phi_n(s^{k})=\frac1{n}\sum_{i=1}^n \hat{\Delta}_i(s^{k})\hat{\Delta}_i(s^{k})</span> is continuous. Therefore we get that <span class="math inline">\lim_k d(I_{n,sco}^k,\mathcal{I})=0</span> which concludes the whole proof.</p>
</div>
</section>
<section id="sec-generalmodel" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="sec-generalmodel"><span class="header-section-number">3.2.3</span> Description of the algorithm for general latent variables models</h3>
<p>In general settings, the SAEM algorithm can yet be applied to approximate numerically the maximum likelihood estimate of the model parameter. Nevertheless there are no more theoretical guarantees of convergence for the algorithm. However we propose an extended version of our algorithm which allows to get an estimate of the Fisher information matrix as a by-product of the estimation algorithm.</p>
<p><strong>Initialization step</strong>: Initialize arbitrarily <span class="math inline">\Delta_i^0</span> for all <span class="math inline">1 \leq i \leq n</span>, <span class="math inline">Q_0</span> and <span class="math inline">\theta_0</span>.</p>
<p><strong>Repeat until convergence the three steps defined at iteration <span class="math inline">k</span> by</strong>:</p>
<ul>
<li><p><strong>Simulation step</strong>: for <span class="math inline">1 \leq i \leq n</span> simulate a realization <span class="math inline">Z_i^k</span> direct from the conditional distribution given the observations <span class="math inline">Y_i</span>, denoted by <span class="math inline">p_i</span>, or from a transition kernel of an ergodic Markov Chain having <span class="math inline">p_i</span> as stationary distribution, using the current parameter <span class="math inline">\theta_{k-1}</span>.</p></li>
<li><p><strong>Stochastic approximation step</strong>: compute the quantities for all <span class="math inline">1 \leq i \leq n</span> <span class="math display">
Q_{k}(\theta) = (1-\gamma_k)Q_{k-1}(\theta)+\gamma_k \sum_{i=1}^n \log f(y_i,Z_i^k;\theta)
</span> <span class="math display">
\Delta_i^{k} = (1-\gamma_k)\Delta_i^{k-1} +\gamma_k \partial_\theta \log f(y_i,Z_i^k;\theta_{k-1})
</span></p></li>
<li><p><strong>Maximisation step</strong>: update of the parameter estimator according to: <span class="math display">
\theta_{k} = \arg \max_{\theta} Q_{k}(\theta).
</span></p></li>
</ul>
<p><strong>When convergence is reached, say at iteration <span class="math inline">K</span> of the algorithm, evaluate the FIM estimator according to</strong>: <span class="math display">
I_{n,sco}^K = \frac{1}{n} \sum_{i=1}^n \Delta_i^K (\Delta_i^K )^t.
</span></p>
<p>We illustrate through simulations in a nonlinear mixed effects model the performance of this algorithm in <a href="#sec-SimusNLMM">Section&nbsp;4.2</a>.</p>
</section>
</section>
</section>
<section id="sec-simul" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Simulation study</h1>
<section id="asymptotic-properties-of-the-estimators-i_nscotheta-and-i_nobstheta" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="asymptotic-properties-of-the-estimators-i_nscotheta-and-i_nobstheta"><span class="header-section-number">4.1</span> Asymptotic properties of the estimators <span class="math inline">I_{n,sco}(\theta)</span> and <span class="math inline">I_{n,obs}(\theta)</span></h2>
<p>In this section, we investigate the properties of the estimators <span class="math inline">I_{n,sco}(\theta)</span> and <span class="math inline">I_{n,obs}(\theta)</span> when the sample size <span class="math inline">n</span> grows.</p>
<section id="simulation-settings" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="simulation-settings"><span class="header-section-number">4.1.1</span> Simulation settings</h3>
<p>First we consider the following linear mixed effects model <span class="math inline">y_{ij} = \beta + z_{i} + \varepsilon_{ij},</span> where <span class="math inline">y_{ij} \in \mathbb{R}</span> denotes the <span class="math inline">j^{th}</span> observation of individual <span class="math inline">i</span>, <span class="math inline">1\leq i \leq n</span>, <span class="math inline">1\leq j \leq J</span>, <span class="math inline">z_i \in \mathbb{R}</span> the unobserved random effect of individual <span class="math inline">i</span> and <span class="math inline">\varepsilon_{ij} \in \mathbb{R}</span> the residual term. The random effects <span class="math inline">(z_{i})</span> are assumed independent and identically distributed such that <span class="math inline">z_{i} \underset{i.i.d.}{\sim} \mathcal{N}(0,\eta^2)</span>, the residuals <span class="math inline">(\varepsilon_{ij})</span> are assumed independent and identically distributed such that <span class="math inline">\varepsilon_{ij} \underset{i.i.d.}{\sim} \mathcal{N}(0,\sigma^2)</span> and the sequences <span class="math inline">(z_i)</span> and <span class="math inline">(\varepsilon_{ij})</span> are assumed mutually independent. Here, the model parameters are <span class="math inline">\theta = (\beta, \eta^2, \sigma^2)</span>. We set <span class="math inline">\beta=3</span>, <span class="math inline">\eta^2=2</span>, <span class="math inline">\sigma^2=5</span> and <span class="math inline">J=12</span>.</p>
<p>Second we consider the following Poisson mixture model where the distribution of each observation <span class="math inline">y_i</span>, <span class="math inline">1\leq i \leq n</span>, depends on a state variable <span class="math inline">z_i</span> which is latent leading to <span class="math inline">y_i|z_i=k \sim \mathcal{P}(\lambda_k)</span> with <span class="math inline">P(z_i=k) = \alpha_k</span> and <span class="math inline">\sum_{k=1}^{K} \alpha_k = 1.</span> The model parameters are <span class="math inline">\theta=(\lambda_1,\ldots,\lambda_K,\alpha_1,\ldots,\alpha_{K-1})</span>. For the simulation study, we consider a mixture of <span class="math inline">K=3</span> components, and the following values for the parameters <span class="math inline">\lambda_1=2</span>, <span class="math inline">\lambda_2=5</span>, <span class="math inline">\lambda_3=9</span>, <span class="math inline">\alpha_1=0.3</span> and <span class="math inline">\alpha_2=0.5</span>.</p>
<p>For each model, we generate <span class="math inline">M=500</span> datasets for different sample sizes <span class="math inline">n \in \left\{20,100,500 \right\}</span>. As a first step, we assume that the true parameter values, denoted by <span class="math inline">\theta^{\star}</span>, are known in order to investigate the asymptotic properties of both <span class="math inline">I_{n,sco}</span> and <span class="math inline">I_{n,obs}</span> without adding extra noise induced by the estimation of the parameters. Hence, for each value of <span class="math inline">n</span> and for each <span class="math inline">1 \leq m \leq M</span>, we derive <span class="math inline">I_{n,sco}^{(m)}(\theta^{\star})</span> and <span class="math inline">I_{n,obs}^{(m)}(\theta^{\star})</span>. The estimators <span class="math inline">I_{n,sco}(\theta^{\star})</span> and <span class="math inline">I_{n,obs}(\theta^{\star})</span> can be computed explicitly in both models by applying formula <a href="#eq-vnmis">Equation&nbsp;5</a> and Louis’ formula <span class="citation" data-cites="Louis1982">(<a href="#ref-Louis1982" role="doc-biblioref">Louis T. A. 1982</a>)</span> (see R functions provided in the Appendix section). We then compute the empirical bias and the root mean squared deviation of each component <span class="math inline">(\ell,\ell')</span> of the estimated matrix as: <span class="math display">
\frac{1}{M} \sum\limits_{m=1}^{M} I_{n,sco,\ell,\ell'}^{(m)}(\theta^\star) - I_{\ell,\ell'}(\theta^\star)  \; \; \;  \mathrm{and} \; \; \; \sqrt{\frac{1}{M} \sum\limits_{m=1}^{M} \left(I_{n,sco,\ell,\ell'}^{(m)}(\theta^\star) - I_{\ell,\ell'}(\theta^\star)\right)^2}.
</span></p>
<p>In the previous quantities, <span class="math inline">I(\theta^\star)</span> is explicit in the linear mixed effects model and approximated by a Monte-Carlo estimation based on a sample of size <span class="math inline">10^8</span> in the Poisson mixture model. The results are presented in <a href="#tbl-BiasLMM">Table&nbsp;1</a> and <a href="#tbl-SdLMM">Table&nbsp;2</a> for the linear mixed effects model and in <a href="#tbl-BiasMixt">Table&nbsp;3</a> and <a href="#tbl-SdMixt">Table&nbsp;4</a> for the mixture model. In a second step, we use the linear mixed effects model to look at what happens when the parameter <span class="math inline">\theta</span> is unknown and the estimation of the Fisher information matrix requires to compute an estimate <span class="math inline">\hat{\theta}_n</span>. We use the datasets simulated with <span class="math inline">n=500</span> and we compute the <span class="math inline">M=500</span> asymptotic confidence intervals of the three model parameters. We then deduce empirical coverage rates for the following nominal rates <span class="math inline">1-\alpha \in \{0.90, 0.95, 0.99\}</span> by using the diagonal terms of either the inversed <span class="math inline">I_{n,sco}^{(m)}(\theta^{\star})</span> (resp. <span class="math inline">I_{n,obs}^{(m)}(\theta^{\star})</span>) or the inversed <span class="math inline">I_{n,sco}^{(m)}(\hat{\theta}_n)</span> (resp. <span class="math inline">I_{n,obs}^{(m)}(\hat{\theta}_n)</span>). The results are depicted in <a href="#tbl-coverageLMM-n100">Table&nbsp;5</a> and <a href="#tbl-coverageLMM-n500">Table&nbsp;6</a>.</p>
<div class="cell" data-file="scripts/simuLMM-estimFIM.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 1- R script for studying the asymptotic properties of Iobs and Isco in the </span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="do">## linear mixed effects model</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="do">## -----------------------------------------------------------------------------</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>nsim  <span class="ot">&lt;-</span> <span class="dv">500</span>            <span class="co"># number of replicates</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>seq.n <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">20</span>,<span class="dv">100</span>,<span class="dv">500</span>)  <span class="co"># number of individuals </span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>j     <span class="ot">&lt;-</span> <span class="dv">12</span>             <span class="co"># number of observations per individual</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="do">## parameter values</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>beta   <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> <span class="dv">5</span> </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>eta2   <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>theta.true <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(beta,eta2,sigma2),<span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="do">## R objects to store estimations</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>resIobs.theta.true <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,nsim,<span class="fu">length</span>(seq.n)))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>resIsco.theta.true <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,nsim,<span class="fu">length</span>(seq.n)))</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>resIobs.theta.est  <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,nsim,<span class="fu">length</span>(seq.n)))</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>resIsco.theta.est  <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,nsim,<span class="fu">length</span>(seq.n)))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>EstF11.true <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>EstF22.true <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>EstF33.true <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>EstF12.true <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>EstF13.true <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>EstF23.true <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>EstF11.est <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>EstF22.est <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>EstF33.est <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>EstF12.est <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>EstF13.est <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>EstF23.est <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>beta.est   <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>eta2.est   <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>sigma2.est <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="do">## loop executing the nsim replicates of the experiment</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (l <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(seq.n)){</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> seq.n[l]</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>  beta.est.n   <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>  eta2.est.n   <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>  sigma2.est.n <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim){</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    <span class="do">## data simulation</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    random    <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2))</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>    residual  <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n<span class="sc">*</span>j,<span class="dv">0</span>,<span class="fu">sqrt</span>(sigma2))</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    randompop <span class="ot">&lt;-</span> <span class="fu">rep</span>(random,j)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    id        <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">seq</span>(<span class="dv">1</span>,n),j)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    obs       <span class="ot">&lt;-</span> beta<span class="sc">+</span>randompop<span class="sc">+</span>residual</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>    datamat   <span class="ot">&lt;-</span> <span class="fu">matrix</span>(obs,n,j)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    <span class="do">## evaluation of the FIM estimators in the true parameter values </span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    resIobs.theta.true[,,k,l] <span class="ot">&lt;-</span> <span class="fu">Iobs_LMM</span>(datamat,beta,sigma2,eta2)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    resIsco.theta.true[,,k,l] <span class="ot">&lt;-</span> <span class="fu">Isco_LMM</span>(datamat,beta,sigma2,eta2)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    <span class="do">## evaluation of the FIM estimators in the estimated parameter values</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>    est.mle    <span class="ot">&lt;-</span> <span class="fu">lmer</span>(obs<span class="sc">~</span>(<span class="dv">1</span><span class="sc">|</span>id),<span class="at">REML =</span> F)</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>    variances  <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">VarCorr</span>(est.mle))</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>    beta.est.n   <span class="ot">&lt;-</span> <span class="fu">c</span>(beta.est.n,est.mle<span class="sc">@</span>beta)</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>    eta2.est.n   <span class="ot">&lt;-</span> <span class="fu">c</span>(eta2.est.n,variances[<span class="dv">1</span>,<span class="st">'vcov'</span>])</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>    sigma2.est.n <span class="ot">&lt;-</span> <span class="fu">c</span>(sigma2.est.n,variances[<span class="dv">2</span>,<span class="st">'vcov'</span>])</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>    resIobs.theta.est[,,k,l] <span class="ot">&lt;-</span> <span class="fu">Iobs_LMM</span>(datamat,est.mle<span class="sc">@</span>beta,</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>                                         variances[<span class="dv">2</span>,<span class="st">'vcov'</span>],</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>                                       variances[<span class="dv">1</span>,<span class="st">'vcov'</span>])</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>    resIsco.theta.est[,,k,l] <span class="ot">&lt;-</span> <span class="fu">Isco_LMM</span>(datamat,est.mle<span class="sc">@</span>beta,</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>                                         variances[<span class="dv">2</span>,<span class="st">'vcov'</span>],</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>                                       variances[<span class="dv">1</span>,<span class="st">'vcov'</span>])</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>  EstF11.true <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF11.true,<span class="fu">c</span>(resIsco.theta.true[<span class="dv">1</span>,<span class="dv">1</span>,,l],</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>                       resIobs.theta.true[<span class="dv">1</span>,<span class="dv">1</span>,,l]))</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>  EstF22.true <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF22.true,<span class="fu">c</span>(resIsco.theta.true[<span class="dv">2</span>,<span class="dv">2</span>,,l],</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>                       resIobs.theta.true[<span class="dv">2</span>,<span class="dv">2</span>,,l]))</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>  EstF33.true <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF33.true,<span class="fu">c</span>(resIsco.theta.true[<span class="dv">3</span>,<span class="dv">3</span>,,l],</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>                       resIobs.theta.true[<span class="dv">3</span>,<span class="dv">3</span>,,l]))</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>  EstF12.true <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF12.true,<span class="fu">c</span>(resIsco.theta.true[<span class="dv">1</span>,<span class="dv">2</span>,,l],</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>                       resIobs.theta.true[<span class="dv">1</span>,<span class="dv">2</span>,,l]))</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>  EstF13.true <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF13.true,<span class="fu">c</span>(resIsco.theta.true[<span class="dv">1</span>,<span class="dv">3</span>,,l],</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>                       resIobs.theta.true[<span class="dv">1</span>,<span class="dv">3</span>,,l]))</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>  EstF23.true <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF23.true,<span class="fu">c</span>(resIsco.theta.true[<span class="dv">2</span>,<span class="dv">3</span>,,l],</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>                       resIobs.theta.true[<span class="dv">2</span>,<span class="dv">3</span>,,l]))</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>  EstF11.est <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF11.est,<span class="fu">c</span>(resIsco.theta.est[<span class="dv">1</span>,<span class="dv">1</span>,,l],</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>                                 resIobs.theta.est[<span class="dv">1</span>,<span class="dv">1</span>,,l]))</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>  EstF22.est <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF22.est,<span class="fu">c</span>(resIsco.theta.est[<span class="dv">2</span>,<span class="dv">2</span>,,l],</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>                                 resIobs.theta.est[<span class="dv">2</span>,<span class="dv">2</span>,,l]))</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>  EstF33.est <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF33.est,<span class="fu">c</span>(resIsco.theta.est[<span class="dv">3</span>,<span class="dv">3</span>,,l],</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>                                 resIobs.theta.est[<span class="dv">3</span>,<span class="dv">3</span>,,l]))</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>  EstF12.est <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF12.est,<span class="fu">c</span>(resIsco.theta.est[<span class="dv">1</span>,<span class="dv">2</span>,,l],</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>                                 resIobs.theta.est[<span class="dv">1</span>,<span class="dv">2</span>,,l]))</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>  EstF13.est <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF13.est,<span class="fu">c</span>(resIsco.theta.est[<span class="dv">1</span>,<span class="dv">3</span>,,l],</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>                                 resIobs.theta.est[<span class="dv">1</span>,<span class="dv">3</span>,,l]))</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>  EstF23.est <span class="ot">&lt;-</span> <span class="fu">c</span>(EstF23.est,<span class="fu">c</span>(resIsco.theta.est[<span class="dv">2</span>,<span class="dv">3</span>,,l],</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>                                 resIobs.theta.est[<span class="dv">2</span>,<span class="dv">3</span>,,l]))</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>  beta.est <span class="ot">&lt;-</span> <span class="fu">c</span>(beta.est,<span class="fu">rep</span>(beta.est.n,<span class="dv">2</span>))</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>  eta2.est <span class="ot">&lt;-</span> <span class="fu">c</span>(eta2.est,<span class="fu">rep</span>(eta2.est.n,<span class="dv">2</span>))</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>  sigma2.est <span class="ot">&lt;-</span> <span class="fu">c</span>(sigma2.est,<span class="fu">rep</span>(sigma2.est.n,<span class="dv">2</span>))</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>DataRes <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">EstF11.true=</span>EstF11.true, <span class="at">EstF22.true=</span>EstF22.true, </span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>                      <span class="at">EstF33.true=</span>EstF33.true, <span class="at">EstF12.true=</span>EstF12.true, </span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>                      <span class="at">EstF13.true=</span>EstF13.true, <span class="at">EstF23.true=</span>EstF23.true,</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>                      <span class="at">EstF11.est=</span>EstF11.est, <span class="at">EstF22.est=</span>EstF22.est, </span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>                      <span class="at">EstF33.est=</span>EstF33.est, <span class="at">EstF12.est=</span>EstF12.est, </span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a>                      <span class="at">EstF13.est=</span>EstF13.est, <span class="at">EstF23.est=</span>EstF23.est,</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>                      <span class="at">beta.est=</span>beta.est, <span class="at">eta2.est=</span>eta2.est, </span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>                      <span class="at">sigma2.est=</span>sigma2.est,</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>                      <span class="at">Estimate=</span><span class="fu">rep</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">'I n,sco'</span>,nsim),<span class="fu">rep</span>(<span class="st">'I n,obs'</span>,nsim)),</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>                                   <span class="fu">length</span>(seq.n)),</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>                      <span class="at">n=</span><span class="fu">rep</span>(seq.n,<span class="at">each=</span>nsim<span class="sc">*</span><span class="dv">2</span>)</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(DataRes,<span class="at">file=</span><span class="st">"Rfiles/simusLMM.Rdata"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-file="scripts/simuPoissonMixture-exactFIM-MCMC.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 2- R script for studying the asymptotic properties of Iobs and Isco in the </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Poisson mixture model - Monte-Carlo estimation of the true Fisher information </span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="do">## matrix based on a very large sample </span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="do">## -----------------------------------------------------------------------------</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>nMC <span class="ot">&lt;-</span> <span class="dv">100000000</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.3</span>,<span class="fl">0.5</span>) <span class="co"># mixture weights of the first K-1 components </span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">9</span>)  <span class="co"># parameter values of the K Poisson distributions </span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>y       <span class="ot">&lt;-</span> <span class="fu">sim_poisson_mixture</span>(nMC,lambda,alpha)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>trueFIM <span class="ot">&lt;-</span>  <span class="fu">fisher_estimation_poisson_mixture</span>(y, nMC, lambda, alpha)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>trueFIM <span class="ot">&lt;-</span> (trueFIM<span class="sc">$</span>Isco<span class="sc">+</span>trueFIM<span class="sc">$</span>Iobs)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(trueFIM,<span class="at">file=</span><span class="st">'Rfiles/PoissonMixtureTrueFIM.Rdata'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-file="scripts/simuPoissonMixture-estimFIM.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="do">## 2- R script for studying the asymptotic properties of Iobs and Isco in the </span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Poisson mixture model</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="do">## -----------------------------------------------------------------------------</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>nbsim  <span class="ot">&lt;-</span> <span class="dv">500</span>           <span class="co"># number of replicates</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>alpha  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.3</span>,<span class="fl">0.5</span>)    <span class="co"># mixture weights of the first K-1 components </span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">9</span>)      <span class="co"># parameter values of the K Poisson distributions</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>seq.n  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">20</span>,<span class="dv">100</span>,<span class="dv">500</span>) <span class="co"># sample size</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>Iobs.theta.est  <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">5</span>,nbsim))</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>Isco.theta.est  <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">5</span>,nbsim))  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>est.lambda      <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>,<span class="dv">3</span>,nbsim)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>est.alpha       <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>,<span class="dv">2</span>,nbsim)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> seq.n){</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbsim){</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Data simulation</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">sim_poisson_mixture</span>(n,lambda,alpha)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Parameter estimation</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    em.est         <span class="ot">&lt;-</span> <span class="fu">em_poisson_mixture</span>(y,<span class="dv">3</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    est.lambda[,j] <span class="ot">&lt;-</span> em.est[[<span class="dv">1</span>]]</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    est.alpha[,j]  <span class="ot">&lt;-</span> em.est[[<span class="dv">2</span>]]</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Computation of Isco and Iobs in the MLE value of the parameter</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    res.theta.est       <span class="ot">&lt;-</span> <span class="fu">fisher_estimation_poisson_mixture</span>(y, est.lambda[,j], </span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>                                                             est.alpha[,j])</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    Iobs.theta.est[,,j] <span class="ot">&lt;-</span> res.theta.est<span class="sc">$</span>Iobs</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    Isco.theta.est[,,j] <span class="ot">&lt;-</span> res.theta.est<span class="sc">$</span>Isco</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>  ResSim   <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">n=</span>n,<span class="at">Isco=</span>Isco.theta.est,<span class="at">Iobs=</span>Iobs.theta.est,<span class="at">lambda=</span>lambda,</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>                 <span class="at">alpha=</span>alpha)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>  filename <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">'Rfiles/simusMixt_n'</span>,n,<span class="st">'.Rdata'</span>,<span class="at">sep=</span><span class="st">""</span>)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">save</span>(ResSim,<span class="at">file=</span>filename)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="results" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="results"><span class="header-section-number">4.1.2</span> Results</h3>
<p>From <a href="#tbl-BiasLMM">Table&nbsp;1</a>, <a href="#tbl-SdLMM">Table&nbsp;2</a>, <a href="#tbl-BiasMixt">Table&nbsp;3</a> and <a href="#tbl-SdMixt">Table&nbsp;4</a>, we observe that whatever the model and whatever the components of <span class="math inline">I_{n,sco}(\theta^{\star})</span> and <span class="math inline">I_{n,obs}(\theta^{\star})</span>, the bias is very small even for small values of <span class="math inline">n</span>. Note that in the linear mixed effects model the second derivative with respect to parameter <span class="math inline">\beta</span> is deterministic, which explains why the bias and the dispersion of the estimations <span class="math inline">I_{n,obs}(\theta^{\star})</span> are zero for every value of <span class="math inline">n</span>. The bias and the standard deviation decrease as <span class="math inline">n</span> increases overall, which illustrates the consistency of both M-estimators. The distributions of the normalized estimations <span class="math inline">\sqrt{n} \left(I_{n,sco}^{(m)}(\theta^\star) - I(\theta^\star)\right)</span> and <span class="math inline">\sqrt{n} \left(I_{n,obs}^{(m)}(\theta^\star) - I(\theta^\star)\right)</span> are also represented when <span class="math inline">n=500</span> for some components of the matrices in <a href="#fig-simuLMM">Figure&nbsp;1</a> (linear mixed effects model) and <a href="#fig-simuPoissonMixture">Figure&nbsp;2</a> (Poisson mixture model). The empirical distributions have the shape of Gaussian distributions and illustrate the asymptotic normality of the two estimators. The numerical results highlight that neither <span class="math inline">I_{n,sco}(\theta^{\star})</span> nor <span class="math inline">I_{n,obs}(\theta^{\star})</span> is systematically better than the other one in terms of bias and asymptotic covariance matrix. In the same model, different behaviors can be observed depending on the components of the parameter vector.</p>
<div class="cell" data-file="scripts/simuLMM-resPlots.R">
<div class="cell-output-display">
<div id="fig-simuLMM" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-simuLMM-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Linear mixed effects model. Kernel density estimates of the normalized values of some components of the estimated Fisher information matrix based on the score (<span class="math inline">I_{n,sco}</span>) and of the observed Fisher information matrix (<span class="math inline">I_{n,obs}</span>) computed in the true parameter values from the 500 simulated datasets with n=500.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-file="scripts/simuPoissonMixture-resPlots.R">
<div class="cell-output-display">
<div id="fig-simuPoissonMixture" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-simuPoissonMixture-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Poisson mixture model. Kernel density estimates of the normalized values of some components of the estimated Fisher information matrix based on the score (<span class="math inline">I_{n,sco}</span>) and of the observed Fisher information matrix (<span class="math inline">I_{n,obs}</span>) computed in the true parameter values from the 500 simulated datasets with n=500.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-file="scripts/tableBiasLMM.R">
<div class="cell-output-display">
<div id="tbl-BiasLMM" class="anchored">

<div class="tabwid"><style>.cl-f4330aaa{}.cl-f426ff44{font-family:'DejaVu Sans';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f426ff58{font-family:'DejaVu Sans';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f42d1870{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f42d3a62{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f42d3a76{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f42d3a77{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-f4330aaa"><caption>Table&nbsp;1:  <p>Linear mixed effects model. Empirical bias to the Fisher Information
matrix of <span class="math inline"><em>I</em><sub><em>n</em>, <em>s</em><em>c</em><em>o</em></sub></span>
and <span class="math inline"><em>I</em><sub><em>n</em>, <em>o</em><em>b</em><em>s</em></sub></span>
computed in the true parameter values for different values of n.</p> </caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44"></span></p></th><th colspan="2" class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">n=20</span></p></th><th colspan="2" class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">n=100</span></p></th><th colspan="2" class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">n=500</span></p></th></tr><tr style="overflow-wrap:break-word;"><th class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44"></span></p></th><th class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">Isco</span></p></th><th class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">Iobs</span></p></th><th class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">Isco</span></p></th><th class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">Iobs</span></p></th><th class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">Isco</span></p></th><th class="cl-f42d3a62"><p class="cl-f42d1870"><span class="cl-f426ff44">Iobs</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">(β,β)</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">0.00552</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00000</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">0.00075</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00000</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00064</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00000</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">(η2,η2)</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">0.00325</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00228</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00138</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00031</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00122</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">-0.00027</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">(σ2,σ2)</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00314</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00009</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">0.00002</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00077</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00027</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">-0.00013</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">(β,η2)</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00241</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00255</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00040</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">-0.00062</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00058</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">-0.00133</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">(β,σ2)</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">0.00360</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00021</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00006</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">-0.00005</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00043</span></p></td><td class="cl-f42d3a76"><p class="cl-f42d1870"><span class="cl-f426ff44">-0.00011</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f42d3a77"><p class="cl-f42d1870"><span class="cl-f426ff44">(η2,σ2)</span></p></td><td class="cl-f42d3a77"><p class="cl-f42d1870"><span class="cl-f426ff58">-0.00050</span></p></td><td class="cl-f42d3a77"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00019</span></p></td><td class="cl-f42d3a77"><p class="cl-f42d1870"><span class="cl-f426ff58">0.00013</span></p></td><td class="cl-f42d3a77"><p class="cl-f42d1870"><span class="cl-f426ff44">0.00003</span></p></td><td class="cl-f42d3a77"><p class="cl-f42d1870"><span class="cl-f426ff58">0.00002</span></p></td><td class="cl-f42d3a77"><p class="cl-f42d1870"><span class="cl-f426ff44">-0.00002</span></p></td></tr></tbody></table></div>
</div>
</div>
</div>
<div class="cell" data-file="scripts/tableSdLMM.R">
<div class="cell-output-display">
<div id="tbl-SdLMM" class="anchored">

<div class="tabwid"><style>.cl-f4584856{}.cl-f44ec3ee{font-family:'DejaVu Sans';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f44ec402{font-family:'DejaVu Sans';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f452f75c{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f453132c{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4531336{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4531340{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-f4584856"><caption>Table&nbsp;2:  <p>Linear mixed effects model. Empirical squared deviation to the Fisher
Information matrix of <span class="math inline"><em>I</em><sub><em>n</em>, <em>s</em><em>c</em><em>o</em></sub></span>
and <span class="math inline"><em>I</em><sub><em>n</em>, <em>o</em><em>b</em><em>s</em></sub></span>
computed in the true parameter values for different values of n.</p> </caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee"></span></p></th><th colspan="2" class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">n=20</span></p></th><th colspan="2" class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">n=100</span></p></th><th colspan="2" class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">n=500</span></p></th></tr><tr style="overflow-wrap:break-word;"><th class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee"></span></p></th><th class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">Isco</span></p></th><th class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">Iobs</span></p></th><th class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">Isco</span></p></th><th class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">Iobs</span></p></th><th class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">Isco</span></p></th><th class="cl-f453132c"><p class="cl-f452f75c"><span class="cl-f44ec3ee">Iobs</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">(β,β)</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.13433</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00000</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.05843</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00000</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.02634</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00000</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">(η2,η2)</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.07916</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.05559</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.02931</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.02418</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.01372</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.01090</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">(σ2,σ2)</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.08201</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.04177</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.03982</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.01946</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.01729</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00819</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">(β,η2)</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.09730</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.05970</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.04380</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.02786</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.01898</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.01145</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">(β,σ2)</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.07115</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00497</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.03100</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00232</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec402">0.01378</span></p></td><td class="cl-f4531336"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00095</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4531340"><p class="cl-f452f75c"><span class="cl-f44ec3ee">(η2,σ2)</span></p></td><td class="cl-f4531340"><p class="cl-f452f75c"><span class="cl-f44ec402">0.02907</span></p></td><td class="cl-f4531340"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00463</span></p></td><td class="cl-f4531340"><p class="cl-f452f75c"><span class="cl-f44ec402">0.01308</span></p></td><td class="cl-f4531340"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00201</span></p></td><td class="cl-f4531340"><p class="cl-f452f75c"><span class="cl-f44ec402">0.00639</span></p></td><td class="cl-f4531340"><p class="cl-f452f75c"><span class="cl-f44ec3ee">0.00091</span></p></td></tr></tbody></table></div>
</div>
</div>
</div>
<div class="cell" data-file="scripts/tableBiasPoissonMixture.R">
<div class="cell-output-display">
<div id="tbl-BiasMixt" class="anchored">

<div class="tabwid"><style>.cl-f4825312{}.cl-f478d3b4{font-family:'DejaVu Sans';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f478d3c8{font-family:'DejaVu Sans';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f47d027c{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f47d1d7a{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f47d1d8e{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f47d1d8f{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-f4825312"><caption>Table&nbsp;3:  <p>Poisson mixture model. Empirical bias to the Fisher Information
matrix of <span class="math inline"><em>I</em><sub><em>n</em>, <em>s</em><em>c</em><em>o</em></sub></span>
and <span class="math inline"><em>I</em><sub><em>n</em>, <em>o</em><em>b</em><em>s</em></sub></span>
computed in the true parameter values for different values of n.</p> </caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4"></span></p></th><th colspan="2" class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">n=20</span></p></th><th colspan="2" class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">n=100</span></p></th><th colspan="2" class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">n=500</span></p></th></tr><tr style="overflow-wrap:break-word;"><th class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4"></span></p></th><th class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">Isco</span></p></th><th class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">Iobs</span></p></th><th class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">Isco</span></p></th><th class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">Iobs</span></p></th><th class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">Isco</span></p></th><th class="cl-f47d1d7a"><p class="cl-f47d027c"><span class="cl-f478d3b4">Iobs</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">(λ2,λ2)</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.00009</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">-0.00025</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">-0.00003</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.00025</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.00008</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">-0.00029</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">(λ3,λ3)</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.00005</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.00047</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">-0.00023</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">-0.00035</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.00008</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.00015</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">(α1,α1)</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.05981</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.05981</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">-0.04072</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">-0.04072</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.01849</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.01849</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">(α2,α2)</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.04756</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.04756</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">-0.04006</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">-0.04006</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.01205</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.01205</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">(λ2,λ3)</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.00009</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.00009</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">-0.00007</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">-0.00007</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.00002</span></p></td><td class="cl-f47d1d8e"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.00002</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f47d1d8f"><p class="cl-f47d027c"><span class="cl-f478d3b4">(λ3,α2)</span></p></td><td class="cl-f47d1d8f"><p class="cl-f47d027c"><span class="cl-f478d3c8">-0.00220</span></p></td><td class="cl-f47d1d8f"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.00082</span></p></td><td class="cl-f47d1d8f"><p class="cl-f47d027c"><span class="cl-f478d3c8">0.00284</span></p></td><td class="cl-f47d1d8f"><p class="cl-f47d027c"><span class="cl-f478d3b4">-0.00061</span></p></td><td class="cl-f47d1d8f"><p class="cl-f47d027c"><span class="cl-f478d3c8">-0.00077</span></p></td><td class="cl-f47d1d8f"><p class="cl-f47d027c"><span class="cl-f478d3b4">0.00041</span></p></td></tr></tbody></table></div>
</div>
</div>
</div>
<div class="cell" data-file="scripts/tableSdPoissonMixture.R">
<div class="cell-output-display">
<div id="tbl-SdMixt" class="anchored">

<div class="tabwid"><style>.cl-f4a74a78{}.cl-f49cd5a2{font-family:'DejaVu Sans';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f49cd5ac{font-family:'DejaVu Sans';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f4a1ec04{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f4a20716{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4a20720{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f4a2072a{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-f4a74a78"><caption>Table&nbsp;4:  <p>Poisson mixture model. Empirical squared deviation to the Fisher
Information matrix of <span class="math inline"><em>I</em><sub><em>n</em>, <em>s</em><em>c</em><em>o</em></sub></span>
and <span class="math inline"><em>I</em><sub><em>n</em>, <em>o</em><em>b</em><em>s</em></sub></span>
computed in the true parameter values for different values of n.</p> </caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2"></span></p></th><th colspan="2" class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">n=20</span></p></th><th colspan="2" class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">n=100</span></p></th><th colspan="2" class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">n=500</span></p></th></tr><tr style="overflow-wrap:break-word;"><th class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2"></span></p></th><th class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">Isco</span></p></th><th class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">Iobs</span></p></th><th class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">Isco</span></p></th><th class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">Iobs</span></p></th><th class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">Isco</span></p></th><th class="cl-f4a20716"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">Iobs</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">(λ2,λ2)</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.00717</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.02238</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.00310</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00996</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.00141</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00463</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">(λ3,λ3)</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.01523</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00872</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.00664</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00403</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.00299</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00167</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">(α1,α1)</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">1.20192</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">1.20192</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.52483</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.52483</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.23129</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.23129</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">(α2,α2)</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">1.05566</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">1.05566</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.46762</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.46762</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.20510</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.20510</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">(λ2,λ3)</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.00295</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00295</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.00132</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00132</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.00059</span></p></td><td class="cl-f4a20720"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00059</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f4a2072a"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">(λ3,α2)</span></p></td><td class="cl-f4a2072a"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.11013</span></p></td><td class="cl-f4a2072a"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.03428</span></p></td><td class="cl-f4a2072a"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.04614</span></p></td><td class="cl-f4a2072a"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.01561</span></p></td><td class="cl-f4a2072a"><p class="cl-f4a1ec04"><span class="cl-f49cd5ac">0.02137</span></p></td><td class="cl-f4a2072a"><p class="cl-f4a1ec04"><span class="cl-f49cd5a2">0.00712</span></p></td></tr></tbody></table></div>
</div>
</div>
</div>
<p><a href="#tbl-coverageLMM-n100">Table&nbsp;5</a> and <a href="#tbl-coverageLMM-n500">Table&nbsp;6</a> show that the empirical coverage rates computed from <span class="math inline">I_{n,sco}</span> and <span class="math inline">I_{n,obs}</span> in the linear mixed effects model are close to the nominal values, which corroborates the relevance of both estimators. Moreover there is little difference between the results obtained when using <span class="math inline">I_{n,sco}</span> or <span class="math inline">I_{n,obs}</span> to estimate the Fisher information matrix. When the parameter value is unknown, the uncertainty related to the parameter estimation leads to a deterioration of the coverage rates. Still, this deterioration diminishes when <span class="math inline">n</span> increases.</p>
<div class="cell" data-file="scripts/simuLMM-coverage-n100.R">
<div class="cell-output-display">
<div id="tbl-coverageLMM-n100" class="anchored">

<div class="tabwid"><style>.cl-f52446a4{}.cl-f51a3754{font-family:'DejaVu Sans';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f51a3768{font-family:'DejaVu Sans';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f51e814c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f51ea370{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0.75pt solid rgba(102, 102, 102, 1.00);border-right: 0.75pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f51ea37a{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0.75pt solid rgba(102, 102, 102, 1.00);border-right: 0.75pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-f52446a4"><caption>Table&nbsp;5:  <p>Linear mixed effects model. Comparison of the coverage rates computed
from both estimates of the Fisher information matrix in either the true
or the estimated parameter values when n=100.</p> </caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3754">1-α</span></p></th><th class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3754">Fisher est.</span></p></th><th class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3754">θ</span></p></th><th class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3754">β</span></p></th><th class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3754">η2</span></p></th><th class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3754">σ2</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td rowspan="4" class="cl-f51ea37a"><p class="cl-f51e814c"><span class="cl-f51a3754">0.99</span></p></td><td rowspan="2" class="cl-f51ea37a"><p class="cl-f51e814c"><span class="cl-f51a3768">Isco</span></p></td><td class="cl-f51ea37a"><p class="cl-f51e814c"><span class="cl-f51a3768">Known</span></p></td><td class="cl-f51ea37a"><p class="cl-f51e814c"><span class="cl-f51a3768">0.992</span></p></td><td class="cl-f51ea37a"><p class="cl-f51e814c"><span class="cl-f51a3768">0.98</span></p></td><td class="cl-f51ea37a"><p class="cl-f51e814c"><span class="cl-f51a3768">0.984</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Estimated</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.988</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.974</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.992</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Iobs</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Known</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.99</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.982</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.982</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Estimated</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.986</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.972</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.988</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="4" class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3754">0.95</span></p></td><td rowspan="2" class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Isco</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Known</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.964</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.946</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.948</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Estimated</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.944</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.936</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.944</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Iobs</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Known</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.96</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.944</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.948</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Estimated</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.938</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.942</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.944</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="4" class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3754">0.9</span></p></td><td rowspan="2" class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Isco</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Known</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.904</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.914</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.876</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Estimated</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.89</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.906</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.884</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Iobs</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Known</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.892</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.916</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.89</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">Estimated</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.882</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.89</span></p></td><td class="cl-f51ea370"><p class="cl-f51e814c"><span class="cl-f51a3768">0.872</span></p></td></tr></tbody></table></div>
</div>
</div>
</div>
<div class="cell" data-file="scripts/simuLMM-coverage-n500.R">
<div class="cell-output-display">
<div id="tbl-coverageLMM-n500" class="anchored">

<div class="tabwid"><style>.cl-f5a1334e{}.cl-f596aa00{font-family:'DejaVu Sans';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f596aa14{font-family:'DejaVu Sans';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f59ab690{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-f59ad01c{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0.75pt solid rgba(102, 102, 102, 1.00);border-right: 0.75pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f59ad026{width:0.8in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0.75pt solid rgba(102, 102, 102, 1.00);border-right: 0.75pt solid rgba(102, 102, 102, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-f5a1334e"><caption>Table&nbsp;6:  <p>Linear mixed effects model. Comparison of the coverage rates computed
from both estimates of the Fisher information matrix in either the true
or the estimated parameter values when n=500.</p> </caption><thead><tr style="overflow-wrap:break-word;"><th class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa00">1-α</span></p></th><th class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa00">Fisher est.</span></p></th><th class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa00">θ</span></p></th><th class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa00">β</span></p></th><th class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa00">η2</span></p></th><th class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa00">σ2</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td rowspan="4" class="cl-f59ad026"><p class="cl-f59ab690"><span class="cl-f596aa00">0.99</span></p></td><td rowspan="2" class="cl-f59ad026"><p class="cl-f59ab690"><span class="cl-f596aa14">Isco</span></p></td><td class="cl-f59ad026"><p class="cl-f59ab690"><span class="cl-f596aa14">Known</span></p></td><td class="cl-f59ad026"><p class="cl-f59ab690"><span class="cl-f596aa14">0.996</span></p></td><td class="cl-f59ad026"><p class="cl-f59ab690"><span class="cl-f596aa14">0.986</span></p></td><td class="cl-f59ad026"><p class="cl-f59ab690"><span class="cl-f596aa14">0.984</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Estimated</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.996</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.986</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.992</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Iobs</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Known</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.996</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.986</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.984</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Estimated</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.996</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.988</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.986</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="4" class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa00">0.95</span></p></td><td rowspan="2" class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Isco</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Known</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.952</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.954</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.952</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Estimated</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.95</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.956</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.944</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Iobs</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Known</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.952</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.956</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.952</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Estimated</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.95</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.95</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.946</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="4" class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa00">0.9</span></p></td><td rowspan="2" class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Isco</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Known</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.922</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.914</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.906</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Estimated</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.916</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.898</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.91</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Iobs</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Known</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.918</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.912</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.908</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">Estimated</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.914</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.888</span></p></td><td class="cl-f59ad01c"><p class="cl-f59ab690"><span class="cl-f596aa14">0.912</span></p></td></tr></tbody></table></div>
</div>
</div>
</div>
</section>
</section>
<section id="sec-SimusNLMM" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-SimusNLMM"><span class="header-section-number">4.2</span> Asymptotic properties of the stochastic approximation algorithm</h2>
<p>We now investigate the properties of our algorithm with truncation on random boundaries in the curved exponential family when the number of iterations grows (<a href="#sec-simuExpo">Section&nbsp;4.2.1</a>) and the good performance of its extended version in more general latent variable models (<a href="#sec-simuNonExpo">Section&nbsp;4.2.2</a>). We also present a short comparison with existing methods (<a href="#sec-simuComparison">Section&nbsp;4.2.3</a>).</p>
<section id="sec-simuExpo" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="sec-simuExpo"><span class="header-section-number">4.2.1</span> In curved exponential family models</h3>
<p>We consider the following nonlinear mixed effects model which is widely used in pharmacokinetics for describing the evolution of drug concentration over time: <span id="eq-modelPK"><span class="math display">
y_{ij}= g_i(t_{ij},z_i) + \varepsilon_{ij},
\tag{7}</span></span> where <span class="math inline">z_i=(\log ka_i, \log Cl_i, \log V_i)'</span> are individual random parameters such that <span class="math display">\log ka_{i}  =  \log(ka) + \eta_{i,1}, \log Cl_{i}  =  \log(Cl) + \eta_{i,2}, \log V_i  =  \log(V) + \eta_{i,3},</span> and <span class="math display">g_i(t_{ij},z_i) = \frac{d_i ka_{i}}{V_i ka_{i}-Cl_{i}}\left[e^{-\frac{Cl_{i}}{V_i} t_{ij}} - e^{-ka_{i} t_{ij}}\right].</span></p>
<p>For all <span class="math inline">1 \leq i \leq n</span> and all <span class="math inline">1\leq j \leq J</span>, <span class="math inline">y_{ij}</span> denotes the measure of drug concentration on individual <span class="math inline">i</span> at time <span class="math inline">t_{ij}</span>, <span class="math inline">d_i</span> the dose of drug administered to individual <span class="math inline">i</span>, and <span class="math inline">V_i</span>, <span class="math inline">ka_i</span> and <span class="math inline">Cl_i</span> respectively denote the volume of the central compartment, the drug’s absorption rate constant and the drug’s clearance of individual <span class="math inline">i</span>. The terms <span class="math inline">\eta_{i} = (\eta_{i,1},\eta_{i,2},\eta_{i,3})' \in \mathbb{R}^3</span> are unobserved random effects which are assumed independent and identically distributed such that <span class="math inline">\eta_i \underset{i.i.d.}{\sim} \mathcal{N}(0,\Omega)</span>, where <span class="math inline">\Omega = \mathrm{diag}(\omega^2_{ka},\omega^2_{Cl},\omega^2_{V})</span>, the residuals <span class="math inline">(\varepsilon_{ij})</span> are assumed independent and identically distributed such that <span class="math inline">\varepsilon_{ij} \underset{i.i.d.}{\sim} \mathcal{N}(0,\sigma^2)</span> and the sequences <span class="math inline">(\eta_i)</span> and <span class="math inline">(\varepsilon_{ij})</span> are assumed mutually independent. Here, the model parameter is <span class="math inline">\theta = (ka,V,Cl,\omega^2_{ka},\omega^2_{V},\omega^2_{Cl},\sigma^2)</span>.</p>
<p>In this model, as in a large majority of nonlinear mixed effects models, the likelihood does not have any analytical expression. As a consequence, neither the Fisher Information Matrix, nor the estimators <span class="math inline">I_{n,sco}(\theta)</span>, <span class="math inline">I_{n,obs}(\theta)</span> have explicit expressions. However, as the complete data log-likelihood is explicit, stochastic approximations of <span class="math inline">I_{n,sco}(\theta)</span>, <span class="math inline">I_{n,obs}(\theta)</span> can be implemented. Note moreover that this model belongs to the curved exponential family as defined in <a href="#eq-curvedexpo">Equation&nbsp;6</a> with <span class="math display">
\begin{aligned}
S_i(z_i) = \left(\sum_{j=1}^{J} (y_{ij} g_i(t_{ij}, z_i)), (\log ka_i), (\log Cl_i), (\log V_i), (\log ka_i)^2, (\log Cl_i)^2, (\log V_i)^2 \right)'\\
\phi_i(\theta) =  \left(\frac{1}{2\sigma^2},\frac{\log ka}{\omega_{ka}^2}, \frac{\log Cl}{\omega_{Cl}^2}, \frac{\log V}{\omega_{V}^2},-\frac{1}{2\omega_{ka}^2},-\frac{1}{2\omega_{Cl}^2},-\frac{1}{2\omega_{V}^2}\right),\\
\psi_i(\theta) = \frac{1}{2}\left(\frac{(\log ka)^2}{\omega_{ka}^2} + \frac{(\log Cl)^2}{\omega_{Cl}^2} + \frac{(\log V)^2}{\omega_{V}^2}\right).
\end{aligned}
</span></p>
<p>The algorithm described in <a href="#sec-algoSAEM">Section&nbsp;3.2.1</a> can therefore be easily implemented to estimate <span class="math inline">\theta</span> and the Fisher information matrix simultaneously (see R function provided in the Appendix section).</p>
<p>We take the following values for the parameters <span class="math inline">V=31</span>, <span class="math inline">ka=1.6</span>, <span class="math inline">Cl=2.8</span>, <span class="math inline">\omega^2_V=0.40</span>, <span class="math inline">\omega^2_{ka}=0.40</span>, <span class="math inline">\omega^2_{Cl}=0.40</span> and <span class="math inline">\sigma^2=0.75</span>. We consider the same dose <span class="math inline">d_i=320</span> and the same observation times (in hours): <span class="math inline">0.25</span>,<span class="math inline">0.5</span>, <span class="math inline">1</span>, <span class="math inline">2</span>, <span class="math inline">3.5</span>, <span class="math inline">5</span>, <span class="math inline">7</span>, <span class="math inline">9</span>, <span class="math inline">12</span>, <span class="math inline">24</span> for all the individuals. We simulate one dataset with <span class="math inline">n=100</span> individuals under model specified by <a href="#eq-modelPK">Equation&nbsp;7</a>. On this simulated dataset, we run <span class="math inline">M=500</span> times the stochastic approximation algorithm described in <a href="#sec-algoSAEM">Section&nbsp;3.2.1</a> for computing <span class="math inline">I_{n,sco}(\hat{\theta})</span> together with <span class="math inline">\hat{\theta}</span> and the algorithm of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span> for computing <span class="math inline">I_{n,obs}(\hat{\theta})</span>. We perform <span class="math inline">K=3000</span> iterations in total for each algorithm by setting <span class="math inline">\gamma_k=0.95</span> for <span class="math inline">1 \leq k \leq 1000</span> (burn in iterations) and <span class="math inline">\gamma_k=(k-1000)^{-3/5}</span> otherwise, <span class="math inline">\varepsilon_k=5.10^4\gamma_k^{2/5}</span> and <span class="math inline">\mathcal{K}_{\kappa} = [-20-\kappa,20+\kappa]^6\times[0,5.10^4+\kappa]</span>. At any iteration, we compute the empirical relative bias and the empirical relative standard deviation of each component <span class="math inline">(\ell,\ell')</span> of <span class="math inline">I_{n,sco}</span> defined respectively as: <span class="math display">
\frac{1}{M} \sum\limits_{m=1}^{M} \frac{\widehat{I_{n,sco,\ell,\ell'}^{(k,m)}} - I_{n,sco,\ell,\ell'}^{\star}}{I_{n,sco,\ell,\ell'}^{\star}} \; \; \; \mathrm{and}
\; \; \; \sqrt{\frac{1}{M} \sum\limits_{m=1}^{M} \left(\frac{\widehat{I_{n,sco,\ell,\ell'}^{(k,m)}} - I_{n,sco,\ell,\ell'}^{\star}}{I_{n,sco,\ell,\ell'}^{\star}}
\right)^2}
</span> where <span class="math inline">\widehat{I_{n,sco}^{(k,m)}}</span> denotes the estimated value of <span class="math inline">I_{n,sco}(\hat{\theta})</span> at iteration <span class="math inline">k</span> of the <span class="math inline">m^{th}</span> algorithm. We compute the same quantities for <span class="math inline">I_{n,obs}</span>. As the true values of <span class="math inline">I_{n,sco}^{\star}=I_{n,sco}(\theta^{\star})</span> and <span class="math inline">I_{n,obs}^{\star}=I_{n,obs}(\theta^{\star})</span> are not known, they are estimated by Monte-Carlo integration based on <span class="math inline">10^5</span> iterations, including <span class="math inline">5000</span> burnin, of a Metropolis-Hastings algorithm.</p>
<div class="cell" data-file="scripts/simuNLME-exponential-bis.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="do">## R script for studying the properties of the SAEM algorithm in the curved </span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="do">## exponential family when the number of iterations grow. </span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="do">## -----------------------------------------------------------------------------</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 1- Data simulation</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample characteristics</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">3005</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>n     <span class="ot">&lt;-</span> <span class="dv">100</span>                             <span class="co"># number of subjects</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>times <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>,<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="fl">3.5</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">9</span>,<span class="dv">12</span>,<span class="dv">24</span>) <span class="co"># observation times</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>j     <span class="ot">&lt;-</span> <span class="fu">length</span>(times)                   <span class="co"># number of observations per subject</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>dose  <span class="ot">&lt;-</span> <span class="dv">320</span>                             <span class="co"># dose</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># True parameter values</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>vpop     <span class="ot">&lt;-</span> <span class="dv">31</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>kapop    <span class="ot">&lt;-</span> <span class="fl">1.6</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>clpop    <span class="ot">&lt;-</span> <span class="fl">2.8</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>omega2v  <span class="ot">&lt;-</span> <span class="fl">0.40</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>omega2ka <span class="ot">&lt;-</span> <span class="fl">0.40</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>omega2cl <span class="ot">&lt;-</span> <span class="fl">0.40</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>sigma2   <span class="ot">&lt;-</span> <span class="fl">0.75</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation of the individual parameters</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>vind  <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(n,<span class="fu">log</span>(vpop),<span class="at">sd=</span><span class="fu">sqrt</span>(omega2v)))</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>kaind <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(n,<span class="fu">log</span>(kapop),<span class="at">sd=</span><span class="fu">sqrt</span>(omega2ka)))</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>clind <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(n,<span class="fu">log</span>(clpop),<span class="at">sd=</span><span class="fu">sqrt</span>(omega2cl)))</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation of the observations</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>ypred <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>  ypred <span class="ot">&lt;-</span> <span class="fu">c</span>(ypred,<span class="fu">model1cptsim</span>(<span class="fu">cbind</span>(kaind,vind,clind),k, times,dose))</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> ypred <span class="sc">+</span> <span class="fu">rnorm</span>(n<span class="sc">*</span>j,<span class="dv">0</span>,<span class="at">sd=</span><span class="fu">sqrt</span>(sigma2))</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>datasim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y=</span>y,<span class="at">dose=</span><span class="fu">rep</span>(dose,n<span class="sc">*</span>j),<span class="at">time=</span><span class="fu">rep</span>(times,n),</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>                      <span class="at">subject=</span><span class="fu">kronecker</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="fu">rep</span>(<span class="dv">1</span>,j)))</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="do">## 2- Numerical experiment</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="do">## a- Evaluation of both estimators of the FIM using the saem algorithm</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>nbsim <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithmic settings</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>nbiterem <span class="ot">&lt;-</span> <span class="dv">3000</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>nbiterburnin <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Saving the nbsim results</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>iscoarray <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(nbsim,<span class="dv">7</span>,<span class="dv">7</span>,nbiterem))</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>iobsarray <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(nbsim,<span class="dv">7</span>,<span class="dv">7</span>,nbiterem))</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>thetaest  <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>,<span class="dv">7</span>,nbsim)</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbsim){</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(k<span class="sc">*</span><span class="dv">100</span><span class="sc">+</span><span class="dv">10</span>)</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>  theta0         <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">vpop=</span>vpop<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.8</span>,<span class="fl">1.2</span>),</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>                         <span class="at">kapop=</span>kapop<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.8</span>,<span class="fl">1.2</span>),</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>                         <span class="at">clpop=</span>clpop<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.8</span>,<span class="fl">1.2</span>),</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>                         <span class="at">omega2v=</span>omega2v<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.4</span>,<span class="dv">2</span>),</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>                         <span class="at">omega2ka=</span>omega2ka<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.4</span>,<span class="dv">2</span>),</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>                         <span class="at">omega2cl=</span>omega2cl<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.4</span>,<span class="dv">2</span>),</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>                         <span class="at">sigma2=</span>sigma2<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.4</span>,<span class="dv">2</span>))</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>  res            <span class="ot">&lt;-</span> <span class="fu">saem</span>(datasim, nbiterem, nbiterburnin, theta0)</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>  iscoarray[k,,,]<span class="ot">&lt;-</span> res<span class="sc">$</span>isco</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>  iobsarray[k,,,]<span class="ot">&lt;-</span> res<span class="sc">$</span>iobs</span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>  thetaest[,k]   <span class="ot">&lt;-</span> res<span class="sc">$</span>thetaest[,nbiterem]</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a><span class="co"># b- Monte-Carlo evaluation of both estimates</span></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a><span class="co"># These Monte-Carlo estimations are considered as the targets for the estimates</span></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a><span class="co"># computed using the stochastic approximation algorithm</span></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>nbMC <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a>nbMCburnin <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>tm <span class="ot">&lt;-</span> <span class="fu">rowMeans</span>(thetaest)</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>thetaMean <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">kapop=</span>tm[<span class="dv">1</span>],<span class="at">vpop=</span>tm[<span class="dv">2</span>],<span class="at">clpop=</span>tm[<span class="dv">3</span>],<span class="at">omega2ka=</span>tm[<span class="dv">4</span>],</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>                  <span class="at">omega2v=</span>tm[<span class="dv">5</span>],<span class="at">omega2cl=</span>tm[<span class="dv">6</span>],<span class="at">sigma2=</span>tm[<span class="dv">7</span>])</span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>FisherMC <span class="ot">&lt;-</span> <span class="fu">FIM_mc</span>(datasim, nbMC, nbMCburnin, thetaMean)</span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>iscoMC <span class="ot">&lt;-</span> FisherMC<span class="sc">$</span>iscoMC</span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>iobsMC <span class="ot">&lt;-</span> FisherMC<span class="sc">$</span>iobsMC</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation of the mean relative bias and of the mean relative standard errors</span></span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a><span class="co"># per iteration.</span></span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>biasIsco <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">7</span>,<span class="dv">7</span>,nbsim,nbiterem))</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbsim){</span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbiterem){</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>    biasIsco[,,j,k] <span class="ot">&lt;-</span> (iscoarray[j,,,k] <span class="sc">-</span> iscoMC)<span class="sc">/</span>iscoMC</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a>biasIobs <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">7</span>,<span class="dv">7</span>,nbsim,nbiterem))</span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbsim){</span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbiterem){</span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>    biasIobs[,,j,k] <span class="ot">&lt;-</span> (iobsarray[j,,,k] <span class="sc">-</span> iobsMC)<span class="sc">/</span>iobsMC</span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a>rsdIsco <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">7</span>,<span class="dv">7</span>,nbsim,nbiterem))</span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbsim){</span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbiterem){</span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>    rsdIsco[,,j,k] <span class="ot">&lt;-</span> (iscoarray[j,,,k] <span class="sc">-</span> iscoMC)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>iscoMC<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a>rsdIobs <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">7</span>,<span class="dv">7</span>,nbsim,nbiterem))</span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbsim){</span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbiterem){</span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a>    rsdIobs[,,j,k] <span class="ot">&lt;-</span> (iobsarray[j,,,k] <span class="sc">-</span> iobsMC)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>iobsMC<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>MbiasIsco <span class="ot">&lt;-</span> <span class="fu">apply</span>(biasIsco[,,,(nbiterburnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>nbiterem],<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>),mean)</span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a>MbiasIobs <span class="ot">&lt;-</span> <span class="fu">apply</span>(biasIobs[,,,(nbiterburnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>nbiterem],<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>),mean)</span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>MsdIsco <span class="ot">&lt;-</span> <span class="fu">apply</span>(rsdIsco[,,,(nbiterburnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>nbiterem],<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>),mean)</span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a>MsdIobs <span class="ot">&lt;-</span> <span class="fu">apply</span>(rsdIobs[,,,(nbiterburnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>nbiterem],<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>),mean)</span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(MbiasIsco,<span class="at">file=</span><span class="st">'Rfiles/ResNLMEexponentialBiasIsco.Rdata'</span>)</span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(MbiasIobs,<span class="at">file=</span><span class="st">'Rfiles/ResNLMEexponentialBiasIobs.Rdata'</span>)</span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(MsdIsco,<span class="at">file=</span><span class="st">'Rfiles/ResNLMEexponentialSdIsco.Rdata'</span>)</span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(MsdIobs,<span class="at">file=</span><span class="st">'Rfiles/ResNLMEexponentialSdIobs.Rdata'</span>)</span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">'Rfiles/ResNLMEexponentialBiasIsco.Rdata'</span>)</span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">'Rfiles/ResNLMEexponentialBiasIobs.Rdata'</span>)</span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">'Rfiles/ResNLMEexponentialSdIsco.Rdata'</span>)</span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">'Rfiles/ResNLMEexponentialSdIobs.Rdata'</span>)</span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a>MbiasIobs <span class="ot">&lt;-</span> MbiasIobs[,,<span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">2000</span>,<span class="dv">10</span>)]</span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>MbiasIsco <span class="ot">&lt;-</span> MbiasIsco[,,<span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">2000</span>,<span class="dv">10</span>)]</span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>MsdIobs <span class="ot">&lt;-</span> MsdIobs[,,<span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">2000</span>,<span class="dv">10</span>)]</span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>MsdIsco <span class="ot">&lt;-</span> MsdIsco[,,<span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">2000</span>,<span class="dv">10</span>)]</span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(MbiasIsco,<span class="at">file=</span><span class="st">'Rfiles/ResNLMEexponentialBiasIsco.Rdata'</span>)</span>
<span id="cb4-154"><a href="#cb4-154" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(MbiasIobs,<span class="at">file=</span><span class="st">'Rfiles/ResNLMEexponentialBiasIobs.Rdata'</span>)</span>
<span id="cb4-155"><a href="#cb4-155" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(MsdIsco,<span class="at">file=</span><span class="st">'Rfiles/ResNLMEexponentialSdIsco.Rdata'</span>)</span>
<span id="cb4-156"><a href="#cb4-156" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(MsdIobs,<span class="at">file=</span><span class="st">'Rfiles/ResNLMEexponentialSdIobs.Rdata'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The results are displayed in <a href="#fig-simuNlme-exponential-bias">Figure&nbsp;3</a> and <a href="#fig-simuNlme-exponential-sd">Figure&nbsp;4</a>.</p>
<div class="cell" data-file="scripts/simuNLME-exponential-plots-bias.R">
<div class="cell-output-display">
<div id="fig-simuNlme-exponential-bias" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-simuNlme-exponential-bias-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Non linear mixed effects model. Representation over iterations of the mean relative bias of the diagonal components of the estimated Fisher information matrix computed from the <span class="math inline">M=500</span> runs of the stochastic algorithm. Red line corresponds to <span class="math inline">I_{n,sco}(\theta)</span> and blue line corresponds to <span class="math inline">I_{n,obs}(\theta)</span>. The burn-in iterations of the algorithm are not depicted.</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-file="scripts/simuNLME-exponential-plots-sd.R">
<div class="cell-output-display">
<div id="fig-simuNlme-exponential-sd" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-simuNlme-exponential-sd-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Non linear mixed effects model. Representation over iterations of the mean relative standard error of the diagonal components of the estimated Fisher information matrix computed from the <span class="math inline">M=500</span> runs of the stochastic algorithm. Red line corresponds to <span class="math inline">I_{n,sco}(\theta)</span> and blue line corresponds to <span class="math inline">I_{n,obs}(\theta)</span>. The burn-in iterations of the algorithme are not depicted</figcaption>
</figure>
</div>
</div>
</div>
<p>We observe that the bias and the standard deviations of the estimates of the components of both matrices decrease over iterations, and that for both estimates the bias is nearly zero when the convergence of the algorithm is reached. According to these simulation results, there is no evidence that one method is better than the other in terms of bias or standard deviation.</p>
</section>
<section id="sec-simuNonExpo" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="sec-simuNonExpo"><span class="header-section-number">4.2.2</span> In general latent variable models</h3>
<p>We use model specified by <a href="#eq-modelPK">Equation&nbsp;7</a> again, but we now consider that individual parameter <span class="math inline">V_i</span> is fixed, <em>i.e.</em> <span class="math inline">V_i \equiv V</span> <span class="math inline">\forall i = 1,\ldots,n</span>. The model is no longer exponential in the sense of equation <a href="#eq-curvedexpo">Equation&nbsp;6</a>. We must therefore use the general version of the stochastic approximation algorithm from <a href="#sec-generalmodel">Section&nbsp;3.2.3</a> to compute <span class="math inline">I_{n,sco}(\hat{\theta})</span> (see R function provided in the Appendix section). We simulate 500 datasets according to this model and we estimate <span class="math inline">I_{n,sco}(\hat{\theta})</span> and <span class="math inline">\hat{\theta}</span> for each one. We perform <span class="math inline">K=3000</span> iterations of the algorithm by setting <span class="math inline">\gamma_k=k^{-0.501}</span>. We compute the 500 asymptotic confidence intervals of the model parameters, by using either the inversed <span class="math inline">I_{n,sco}(\hat{\theta}_k)</span>’s or the inversed <span class="math inline">I_{n,obs}(\hat{\theta}_k)</span>’s and then deduce from them empirical coverage rates.</p>
<div class="cell" data-file="scripts/simuNLME-nonexponential.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="do">## R script for studying the relevance of the SAEM algorithm out of the curved </span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="do">## exponential family </span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="do">## -----------------------------------------------------------------------------</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 1- Data simulation</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Sample characteristics</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>n     <span class="ot">&lt;-</span> <span class="dv">100</span>                             <span class="co"># number of subjects</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>times <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>,<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="fl">3.5</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">9</span>,<span class="dv">12</span>,<span class="dv">24</span>) <span class="co"># observation times</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>j     <span class="ot">&lt;-</span> <span class="fu">length</span>(times)                   <span class="co"># number of observations per subject</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>dose  <span class="ot">&lt;-</span> <span class="dv">320</span>                             <span class="co"># dose</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="do">## True parameter values</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>vpop     <span class="ot">&lt;-</span> <span class="dv">31</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>kapop    <span class="ot">&lt;-</span> <span class="fl">1.6</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>clpop    <span class="ot">&lt;-</span> <span class="fl">2.8</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>omega2ka <span class="ot">&lt;-</span> <span class="fl">0.40</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>omega2cl <span class="ot">&lt;-</span> <span class="fl">0.40</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>sigma2   <span class="ot">&lt;-</span> <span class="fl">0.75</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="do">## Estimation</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>nbiterem     <span class="ot">&lt;-</span> <span class="dv">3000</span> <span class="co"># total number of iterations</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>nbiterburnin <span class="ot">&lt;-</span> <span class="dv">1000</span> <span class="co"># number of burnin iterations</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>nbsim <span class="ot">&lt;-</span> <span class="dv">500</span>  <span class="co"># number of simulated datasets  </span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>thetaest <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">6</span>,nbsim)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>isco.est <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">6</span>,<span class="dv">6</span>,nbsim))</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>iobs.est <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(<span class="dv">6</span>,<span class="dv">6</span>,nbsim))</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (kk <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbsim){</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(kk<span class="sc">*</span><span class="dv">2500</span><span class="sc">+</span><span class="dv">10</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Simulation of individual parameters</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>  vi  <span class="ot">&lt;-</span> <span class="fu">rep</span>(vpop,n)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>  kai <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(n,<span class="fu">log</span>(kapop),<span class="at">sd=</span><span class="fu">sqrt</span>(omega2ka)))</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>  cli <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">rnorm</span>(n,<span class="fu">log</span>(clpop),<span class="at">sd=</span><span class="fu">sqrt</span>(omega2cl)))</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Simulation of the observations</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>  ypred <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    ypred <span class="ot">&lt;-</span> <span class="fu">c</span>(ypred,<span class="fu">model1cptsim</span>(<span class="fu">cbind</span>(kai,vi,cli),k,times,dose))</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> ypred <span class="sc">+</span> <span class="fu">rnorm</span>(n<span class="sc">*</span>j,<span class="dv">0</span>,<span class="at">sd=</span><span class="fu">sqrt</span>(sigma2))</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>  datasim <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y=</span>y,<span class="at">dose=</span><span class="fu">rep</span>(dose,n<span class="sc">*</span>j),<span class="at">time=</span><span class="fu">rep</span>(times,n),</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>                        <span class="at">subject=</span><span class="fu">kronecker</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="fu">rep</span>(<span class="dv">1</span>,j)))</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Estimation</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>  theta0 <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">vpop=</span>vpop<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.95</span>,<span class="fl">1.05</span>),<span class="at">kapop=</span>kapop<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.8</span>,<span class="fl">1.2</span>),</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>                 <span class="at">clpop=</span>clpop<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.8</span>,<span class="fl">1.2</span>),<span class="at">omega2ka=</span>omega2ka<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.4</span>,<span class="dv">2</span>),</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>                 <span class="at">omega2cl=</span>omega2cl<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.4</span>,<span class="dv">2</span>),<span class="at">sigma2=</span>sigma2<span class="sc">*</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="fl">0.4</span>,<span class="dv">2</span>))</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">saem_non_exp</span>(datasim, nbiterem, nbiterburnin, theta0)</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>  thetaest[,kk]  <span class="ot">&lt;-</span> res<span class="sc">$</span>thetaest[,nbiterem]</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>  isco.est[,,kk] <span class="ot">&lt;-</span> res<span class="sc">$</span>isco[,,nbiterem]</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>  iobs.est[,,kk] <span class="ot">&lt;-</span> res<span class="sc">$</span>iobs[,,nbiterem]</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>  filename <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">"Rfiles/ResNLMEnonexponential.Rdata"</span>,<span class="at">sep=</span><span class="st">""</span>)</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>  resNLMEnonExp <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">thetaest=</span>thetaest,<span class="at">isco=</span>isco.est,<span class="at">iobs=</span>iobs.est)</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>  <span class="fu">save</span>(resNLMEnonExp,<span class="at">file=</span>filename)</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We obtain for the six parameters <span class="math inline">(ka,V,Cl,\omega^2_{ka},\omega^2_{Cl},\sigma^2)</span> empirical covering rates of <span class="math inline">0.96, 0.948, 0.948, 0.932, 0.948, 0.948</span> respectively for a nominal covering rate of <span class="math inline">0.95</span>. This highlights that our estimate accurately quantifies the precisions of parameter estimates. Note that empirical coverage rates computed from <span class="math inline">I_{n,obs}</span> are similar (here <span class="math inline">0.952, 0.93, 0.942, 0.924, 0.952, 0.946</span>) but that the real advantage of our method is that it requires stochastic approximation only on the first-order derivatives of the complete log-likelihood, contrary to <span class="math inline">I_{n,obs}</span> which requires deriving the complete log-likelihood at the second order and thus implies more complicated formulas since the model does not belong to the exponential family.</p>
<p>Convergence graphs obtained from a simulated data set are shown in <a href="#fig-NLMEnonexponential-conv-plot">Figure&nbsp;5</a>. Although theoretical guarantee is missing in non exponential models, the stochastic approximation algorithm proposed in <a href="#sec-generalmodel">Section&nbsp;3.2.3</a> converges in practice on this example for both the estimation of the model parameters and the estimation of the Fisher information matrix.</p>
<div class="cell" data-file="scripts/simuNLME-nonexponential-conv-plot.R">
<div class="cell-output-display">
<div id="fig-NLMEnonexponential-conv-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-NLMEnonexponential-conv-plot-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Non linear mixed effects model. Convergence plot for some parameter estimates and for some diagonal components of <span class="math inline">I_{n,sco}(\hat{\theta})</span> over iterations of the stochastic approximation algorithm.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-simuComparison" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="sec-simuComparison"><span class="header-section-number">4.2.3</span> Comparison with other methods</h3>
<p>To the best of our knowledge, although there exists contributions focusing on the estimation of the Fisher information matrix in latent variable models, there is currently no method based on the first derivatives of the log-likelihood. We compare to <span class="citation" data-cites="Meng2017">(<a href="#ref-Meng2017" role="doc-biblioref">Meng L. and Spall J. C. 2017</a>)</span> who proposed an iterative method based on numerical first order derivatives of the Q function that is computed at each E-step of the EM algorithm. The model used by <span class="citation" data-cites="Meng2017">(<a href="#ref-Meng2017" role="doc-biblioref">Meng L. and Spall J. C. 2017</a>)</span> in their simulation study is a mixture of two Gaussian distributions with unknown expectations <span class="math inline">\mu_1</span> and <span class="math inline">\mu_2</span>, fixed variances equal to <span class="math inline">1</span> and unknown proportion <span class="math inline">\pi</span>. The model parameters are denoted by <span class="math inline">\theta=(\mu_1,\mu_2,\pi)</span>.</p>
<div class="cell" data-file="scripts/simuGaussianMixture.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Numerical study in the Gaussian mixture model from (Meng and Spall, 2017)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="do">## This script computes the estimator Isco on a large number of simulated </span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="do">## datasets of size n=750. </span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># True paramater values</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>probtrue <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">/</span><span class="dv">3</span> <span class="co"># mixture proportion</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>m1true   <span class="ot">&lt;-</span> <span class="dv">3</span>   <span class="co"># mean of the first mixture proportion</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>m2true   <span class="ot">&lt;-</span> <span class="dv">0</span>   <span class="co"># mean of the second mixture proportion</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample size</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">750</span> </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of simulated datasets</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>nrep <span class="ot">&lt;-</span> <span class="dv">10000</span> </span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Nominal rate for the computation of empirical coverage rates</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>rate <span class="ot">&lt;-</span> <span class="fl">0.95</span> </span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Intermediary R objects to store the results</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>recouvprob <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>recouvm1   <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>recouvm2   <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>isco <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(nrep,<span class="dv">3</span>,<span class="dv">3</span>))</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nrep){</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">sim_gaussian_mixture</span>(n,m1true,m2true,probtrue)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>  est <span class="ot">&lt;-</span> <span class="fu">em_gaussian_mixture</span>(y)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>  iscoest <span class="ot">&lt;-</span> <span class="fu">fisher_estimation_gaussian_mixture</span>(y,est<span class="sc">$</span>m1,est<span class="sc">$</span>m2,est<span class="sc">$</span>prob)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>  ICinf <span class="ot">&lt;-</span> </span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(est<span class="sc">$</span>prob,est<span class="sc">$</span>m1,est<span class="sc">$</span>m2) <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>(<span class="dv">1</span><span class="sc">-</span>rate)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">solve</span>(iscoest)))</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>  ICsup <span class="ot">&lt;-</span> </span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(est<span class="sc">$</span>prob,est<span class="sc">$</span>m1,est<span class="sc">$</span>m2) <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="dv">1</span><span class="sc">-</span>(<span class="dv">1</span><span class="sc">-</span>rate)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">solve</span>(iscoest)))</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> ((probtrue<span class="sc">&gt;=</span>ICinf[<span class="dv">1</span>])<span class="sc">&amp;</span>(probtrue<span class="sc">&lt;=</span>ICsup[<span class="dv">1</span>])){recouvprob <span class="ot">&lt;-</span> recouvprob <span class="sc">+</span> <span class="dv">1</span>}</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> ((m1true<span class="sc">&gt;=</span>ICinf[<span class="dv">2</span>])<span class="sc">&amp;</span>(m1true<span class="sc">&lt;=</span>ICsup[<span class="dv">2</span>])){recouvm1 <span class="ot">&lt;-</span> recouvm1 <span class="sc">+</span> <span class="dv">1</span>}</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> ((m2true<span class="sc">&gt;=</span>ICinf[<span class="dv">3</span>])<span class="sc">&amp;</span>(m2true<span class="sc">&lt;=</span>ICsup[<span class="dv">3</span>])){recouvm2 <span class="ot">&lt;-</span> recouvm2 <span class="sc">+</span> <span class="dv">1</span>}</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>  isco[j,,] <span class="ot">&lt;-</span> iscoest</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">isco=</span><span class="fu">round</span>(<span class="fu">apply</span>(isco,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>),mean),<span class="dv">3</span>),<span class="at">recouvprob=</span>recouvprob<span class="sc">/</span>nrep,</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>            <span class="at">recouvm1=</span>recouvm1<span class="sc">/</span>nrep,<span class="at">recouvm2=</span>recouvm2<span class="sc">/</span>nrep)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(res,<span class="at">file=</span><span class="st">"Rfiles/ResGaussianMixture.Rdata"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We simulate 10000 datasets according to this Gaussian mixture model, using the same setting as <span class="citation" data-cites="Meng2017">(<a href="#ref-Meng2017" role="doc-biblioref">Meng L. and Spall J. C. 2017</a>)</span>, <em>i.e.</em> <span class="math inline">n=750</span>, <span class="math inline">\pi=2/3</span>, <span class="math inline">\mu_1=3</span> and <span class="math inline">\mu_2=0</span>. For each dataset <span class="math inline">k=1,\ldots,10000</span>, we compute the parameter maximum likelihood estimate <span class="math inline">\hat{\theta}_k = (\hat{\pi}_k,\widehat{\mu_1}_k,\widehat{\mu_2}_k)</span> with an EM algorithm and then we derive <span class="math inline">I_{n,sco}(\hat{\theta}_k)</span> directly according to <a href="#eq-vnmis">Equation&nbsp;5</a> (see R function provided in the Appendix section) contrary to <span class="citation" data-cites="Meng2017">(<a href="#ref-Meng2017" role="doc-biblioref">Meng L. and Spall J. C. 2017</a>)</span> who used an iterative method. We compute the empirical mean of the 10000 estimated matrices leading to:</p>
<p><span class="math display">
\frac1{10000} \sum _k I_{n,sco}(\hat{\theta}_k)= \begin{pmatrix}
2687.873 &amp; -210.795 &amp; -251.634\\
-210.795 &amp; 170.9 &amp; -61.546 \\
-251.634 &amp; -61.546 &amp; 393.115\\
\end{pmatrix}.
</span></p>
<p>Comparison with the results of <span class="citation" data-cites="Meng2017">(<a href="#ref-Meng2017" role="doc-biblioref">Meng L. and Spall J. C. 2017</a>)</span> is delicate since their numerical illustration of their method is based on a single simulated dataset thus potentially sensitive to sampling variations. However, they provide an estimation of the Fisher information matrix from this unique dataset<br>
<span class="math display">
I_{Meng} = \begin{pmatrix}
2591.3 &amp; -237.9 &amp; -231.8\\
-237.9 &amp; 155.8 &amp; -86.7\\
-231.8 &amp; -86.7 &amp; 394.5
\end{pmatrix}.
</span></p>
<p>Our results are coherent with their ones. To check the reliability of our results, we then compute as above the 10000 asymptotic confidence intervals of the three model parameters. We obtain for the three parameters <span class="math inline">(\pi,\mu_1,\mu_2)</span> empirical covering rates of <span class="math inline">0.9477</span>, <span class="math inline">0.9499</span>, <span class="math inline">0.9523</span> respectively for a nominal covering rate of <span class="math inline">0.95</span>. Thus <span class="math inline">I_{n,sco}</span> accurately quantifies the precisions of parameter estimates.</p>
</section>
</section>
</section>
<section id="conclusion-and-discussion" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Conclusion and discussion</h1>
<p>In this work, we address the estimation of the Fisher information matrix in general latent variable models. We focus on the empirical Fisher information matrix which is a moment estimate of the covariance matrix of the score. We propose stochastic approximation algorithms to compute this estimate when it can not be calculated analytically and establish theoretical convergence properties in the curved exponential family setting. We carry out a simulation study in mixed effects model and in a Poisson mixture model to compare the performances of several estimates, namely the considered empirical Fisher information matrix and the observed Fisher information matrix. We emphasize that the empirical FIM requires less regularity assumptions than the observed FIM. From a computational point of view, the implementation of the algorithm for evaluating the empirical FIM only involves the first derivatives of the log-likelihood, in contrary to the one for evaluating the observed FIM which involves the second derivatives of the log-likelihood.</p>
<p>The main perspective of this work is to adapt the procedure for statistical models whose derivatives of the log-likelihood have no tractable expressions, coupling the algorithm with numerical derivative procedures.</p>
</section>
<section id="appendix" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Appendix</h1>
<section id="sec-algoSAEM-appendix" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="sec-algoSAEM-appendix"><span class="header-section-number">6.1</span> Description of the algorithm without truncation on random boundaries in curved exponential family model</h2>
<p>We provide here a simpler algorithm based on an extension of the stochastic approximation Expectation Maximization algorithm proposed by <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span> using a simulation step performed from the conditional distribution and without truncation on random boundaries. Theoretical results are established assuming a stability condition which is usually quite difficult to check. However, this algorithm can be easily applied in practice.</p>
<p><strong>Initialization step</strong>: Initialize arbitrarily for all <span class="math inline">1 \leq i \leq n</span> <span class="math inline">s_i^0</span> and <span class="math inline">\theta_0</span>.</p>
<p><strong>Repeat until convergence the three steps defined at iteration <span class="math inline">k</span> by</strong>:</p>
<ul>
<li><p><strong>Simulation step</strong>: for <span class="math inline">1 \leq i \leq n</span> simulate a realization <span class="math inline">Z_i^k</span> from the conditional distribution given the observations <span class="math inline">Y_i</span> denoted by <span class="math inline">p_i</span> using the current parameter value <span class="math inline">\theta_{k-1}</span>.</p></li>
<li><p><strong>Stochastic approximation step</strong>: compute the quantities for all <span class="math inline">1 \leq i \leq n</span> <span class="math display">
s_i^{k} = (1-\gamma_k)s_i^{k-1} +\gamma_k  S_i(Z_i^k)
</span> where <span class="math inline">(\gamma_k)</span> is a sequence of positive step sizes satisfying <span class="math inline">\sum \gamma_k=\infty</span> and <span class="math inline">\sum \gamma_k^2 &lt;~\infty</span>.</p></li>
<li><p><strong>Maximisation step</strong>: update of the parameter estimator according to: <span class="math display">
\theta_{k} = \arg \max_{\theta}  \sum_{i=1}^n \left( -\psi_i(\theta) + \left&lt;s_i^k,\phi_i(\theta)\right&gt;\right) = \hat{\theta}(s^{k})
</span></p></li>
</ul>
<p><strong>When convergence is reached, say at iteration <span class="math inline">K</span> of the algorithm, evaluate the FIM estimator according to</strong>: <span class="math display">
I_{n,sco}^K = \frac{1}{n} \sum_{i=1}^n \hat{\Delta}_i\left(s^{K}\right) \hat{\Delta}_i\left(s^{K}\right)^t
</span> where <span class="math inline">\hat{\Delta}_i(s) = -\partial \psi_i(\hat{\theta}(s)) + \left&lt;s_i,\partial \phi_i(\hat{\theta}(s))\right&gt;</span> for all <span class="math inline">s</span>.</p>
<div class="remark proof">
<p><span class="proof-title"><em>Remark</em>. </span>In the cases where the latent variables can not be simulated from the conditional distribution, one can apply the extension coupling the stochastic algorithm with a Monte Carlo Markov Chain procedure as presented in <span class="citation" data-cites="Kuhn2004">(<a href="#ref-Kuhn2004" role="doc-biblioref">Kuhn E. and Lavielle M. 2004</a>)</span>. All the following results can be extended to this case.</p>
</div>
</section>
<section id="theoretical-convergence-properties" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="theoretical-convergence-properties"><span class="header-section-number">6.2</span> Theoretical convergence properties</h2>
<p>The theoretical following results provided convergence guarantees for the FIM estimate obtained as a by-product of the MLE. Therefore they extend those of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>. To that purpose, in addition to the exponential family assumption for each individual likelihood, we also make the same type of regularity assumptions as those presented in <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span> at each individual level. These regularity assumptions on the model are detailed at the end of the appendix section.</p>
<div id="thm-conv.algo" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 </strong></span>Assume that <span class="math inline">(M1')</span> and <span class="math inline">(M2')</span>, <span class="math inline">(M3)</span> to <span class="math inline">(M5)</span> and <span class="math inline">(SAEM1)</span> to <span class="math inline">(SAEM4)</span> are fulfilled. Assume also that with probability 1 <span class="math inline">\mathrm{clos}(\{s_k\}_{k \geq 1})</span> is a compact subset of <span class="math inline">\mathcal{S}</span>. Let us define <span class="math inline">\mathcal{L}=\{\theta \in\Theta, \partial_\theta l(y;\theta)=0\}</span> the set of stationary points of the observed log-likelihood <span class="math inline">l</span> defined as <span class="math inline">l(y;\theta)=\sum_{i=1}^n \log g(y_i;\theta)</span>. Then, for all <span class="math inline">\theta_0 \in \Theta</span>, for fixed <span class="math inline">n \in \mathbb{N}^*</span>, we get: <span class="math inline">\lim_k d(\theta_k,\mathcal{L})=0</span> and <span class="math inline">\lim_k d(I_{n,sco}^k,\mathcal{I})=0</span> a.s. where <span class="math inline">\mathcal{I}=\{I_{n,sco}(\theta), \theta \in \mathcal{L}\}</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let us denote by <span class="math inline">S(Z)=(S_1(Z_1),\ldots,S_n(Z_n))</span> the sufficient statistics of the model we consider in our approach. Note as recalled in <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>, these are not unique. Let us also define <span class="math inline">H(Z,s)=S(Z)-s</span> and <span class="math inline">h(s) = \mathrm{E}_{Z|Y;\hat{\theta}(s)}(S(Z))-s</span>. Assumptions <span class="math inline">(M1')</span> and <span class="math inline">(M2')</span> imply that assumptions <span class="math inline">(M1)</span> and <span class="math inline">(M2)</span> of Theorem 5 of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span> are fulfilled. Indeed these assumptions focus on expressions and regularity properties of the individual likelihood functions and the corresponding sufficient statistics for each index <span class="math inline">i \in \{1,\ldots,n\}</span>. Then by linearity of the log-likelihood function and of the stochastic approximation and applying Theorem 5 of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>, we get that <span class="math inline">\lim_k d(\theta_k,\mathcal{L})=0</span>. Moreover we get that for <span class="math inline">1 \leq i \leq n</span>, each sequence <span class="math inline">(s_i^k)</span> converges almost surely toward <span class="math inline">\mathrm{E}_{Z_i|Y_i;\theta} (S_i(Z_i) )</span>. Since assumption <span class="math inline">(M2')</span> ensures that for all <span class="math inline">1 \leq i \leq n</span> the functions <span class="math inline">\psi_i</span> and <span class="math inline">\phi_i</span> are twice continuously differentiable and assumption <span class="math inline">(M5)</span> ensures that the function <span class="math inline">\hat{\theta}</span> is continuously differentiable, the function <span class="math inline">\Phi_n</span> defined by <span class="math inline">\Phi_n(s^{k})=\frac1{n}\sum_{i=1}^n \hat{\Delta}_i(s^{k})\hat{\Delta}_i(s^{k})</span> is continuous. Therefore we get that <span class="math inline">\lim_k d(I_{n,sco}^k,\mathcal{I})=0</span>.</p>
</div>
<p>We now establish the asymptotic normality of the estimate <span class="math inline">\bar{I}_{n,sco}^k</span> defined as <span class="math inline">\bar{I}_{n,sco}^k=\Phi_n(\bar{s}^{k})</span> with <span class="math inline">\bar{s}^{k}=\sum_{l=1}^k s^l /k</span> using the results stated by <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>. Let us denote by <span class="math inline">Vect(A)</span> the vector composed of the elements of the triangular superior part of matrix <span class="math inline">A</span> ordered by columns.</p>
<div id="thm-conv2" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3 </strong></span>Assume that <span class="math inline">(M1')</span> and <span class="math inline">(M2')</span>, <span class="math inline">(M3)</span> to <span class="math inline">(M5)</span>, <span class="math inline">(SAEM1)</span>, <span class="math inline">(SAEM2)</span>, <span class="math inline">(SAEM3)</span>, <span class="math inline">(SAEM4)</span>, <span class="math inline">(SAEM4')</span> and <span class="math inline">(LOC1)</span> to <span class="math inline">(LOC3)</span> are fulfilled. Then, there exists a regular stable stationary point <span class="math inline">\theta^* \in \Theta</span> such that <span class="math inline">\lim_k \theta_k=\theta^*</span> a.s. Moreover the sequence <span class="math inline">(\sqrt{k}(Vect(\bar{I}_{n,sco}^k)-Vect(\bar{I}_{n,sco}(\theta^*))))\mathbb{1}_{\lim \| \theta_k-\theta^*\|=0 }</span> converges in distribution toward a centered Gaussian random vector when <span class="math inline">k</span> goes to infinity. The asymptotic covariance matrix is characterized.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof follows the lines of this of Theorem 7 of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>. Assumptions <span class="math inline">(LOC1)</span> to <span class="math inline">(LOC3)</span> are those of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span> and ensure the existence of a regular stable stationary point <span class="math inline">s^*</span> for <span class="math inline">h</span> and therefore of <span class="math inline">\theta^*=\hat{\theta}(s^*)</span> for the observed log-likelihood <span class="math inline">l</span>. Then applying Theorem 4 of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span>, we get that: <span class="math display">
\sqrt{k}( \bar{s}^k - s^*) \mathbb{1}_{\lim \| s^k-s^*\|=0 } \overset{\mathcal{L}}{ \rightarrow} \mathcal{N}(0, J(s^*)^{-1}  \Gamma(s^*) J(s^*)^{-1}  )\mathbb{1}_{\lim \| s_k-s^*\|=0 }
</span> where the function <span class="math inline">\Gamma</span> defined in assumption <span class="math inline">(SAEM4')</span> and <span class="math inline">J</span> is the Jacobian matrix of the function <span class="math inline">h</span>. Applying the Delta method, we get that: <span class="math display">
\sqrt{k}( Vect(\Phi_n(\bar{s}^k)) - Vect(\Phi_n(s^*))) \mathbb{1}_{\lim \| s^k-s^*\|=0 } \overset{\mathcal{L}}{ \rightarrow} W\mathbb{1}_{\lim \| s^k-s^*\|=0 }
</span> where <span class="math inline">W \sim \mathcal{N}(0, \partial Vect(\Phi_n (s^*)) J(s^*)^{-1} \Gamma(s^*) J(s^*)^{-1} \partial Vect(\Phi_n (s^*))^t )</span> which leads to the result.</p>
</div>
<p>Note that as usually in stochastic approximation results, the rate <span class="math inline">\sqrt{k}</span> is achieved when considering an average estimator (see Theorem 7 of <span class="citation" data-cites="Delyon1999">(<a href="#ref-Delyon1999" role="doc-biblioref">Delyon B., Lavielle M., and Moulines E. 1999</a>)</span> <em>e.g</em>).</p>
<p>It is assumed that the random variables <span class="math inline">s^0, z_1, z_2, \cdots</span> are defined on the same probability space <span class="math inline">(\Omega, \mathcal{A}, P)</span>. We denote <span class="math inline">\mathcal{F} = \{ \mathcal{F}_k \}_{k \geq 0}</span> the increasing family of <span class="math inline">\sigma</span>-algebras generated by the random variables <span class="math inline">s_0, z_1, z_2, \cdots, z_k</span>. We assume the following conditions:</p>
<ul>
<li><p><strong>(M1’)</strong> The parameter space <span class="math inline">\Theta</span> is an open subset of <span class="math inline">\mathbb{R}^{p}</span>. The individual complete data likelihood function is given for all <span class="math inline">i=1,\ldots,n</span> by: <span class="math display">
f_i(z_i;\theta)
= \exp\left(-\psi_i(\theta) + \left&lt;S_i(z_i),\phi_i(\theta)\right&gt;\right),
</span> where <span class="math inline">\left&lt;\cdot,\cdot\right&gt;</span> denotes the scalar product, <span class="math inline">S_i</span> is a Borel function on <span class="math inline">\mathbb{R}^{d_i}</span> taking its values in an open subset <span class="math inline">\mathcal{S}_i</span> of <span class="math inline">\mathbb{R}^{d_i}</span>, <span class="math inline">\phi_i</span> and <span class="math inline">\psi_i</span> are measurable function of <span class="math inline">\Theta</span> taking values in open subsets of <span class="math inline">\mathbb{R}^{d_i}</span> and <span class="math inline">\mathbb{R}</span> respectively. Moreover, the convex hull of <span class="math inline">S(\mathbb{R}^{\sum d_i})</span> is included in <span class="math inline">\mathcal{S}</span> and for all <span class="math inline">\theta \in \Theta</span> <span class="math inline">\int S(z) \prod p_i(z_i;\theta) \mu(dz) &lt; \infty</span></p></li>
<li><p><strong>(M2’)</strong> Define for each <span class="math inline">i</span> <span class="math inline">L_i : \mathcal{S}_i \times \Theta \to \mathbb{R}</span> as <span class="math inline">L_i(s_i; \theta)\triangleq - \psi_i(\theta) + \left&lt;s_i,\phi_i(\theta)\right&gt;</span>.The functions <span class="math inline">\psi_i</span> and <span class="math inline">\phi_i</span> are twice continuously differentiable on <span class="math inline">\Theta</span>.</p></li>
<li><p><strong>(M3)</strong> The function <span class="math inline">\bar{s} : \Theta \rightarrow \mathcal{S}</span> defined as <span class="math inline">\bar{s}(\theta) \triangleq \int S(z) p(z; \theta) \mu(dz)</span> is continuously differentiable on <span class="math inline">\Theta</span>.</p></li>
<li><p><strong>(M4)</strong> For all <span class="math inline">1 \leq i\leq n</span> the function <span class="math inline">l_i:\Theta \rightarrow \mathbb{R}</span> defined as <span class="math inline">l_i(\theta) = \log \int f_i(z_i;\theta) \mu_i(dz_i)</span> is continuously differentiable on <span class="math inline">\Theta</span> and <span class="math inline">\partial_\theta \int f_i(z_i; \theta) \mu_i(dz_i)= \int \partial_\theta f_i(z_i; \theta) \mu_i(dz_i)</span>.</p></li>
<li><p><strong>(M5)</strong> There exists a continuously differentiable function <span class="math inline">\widehat{\theta} : \ \mathcal{S} \rightarrow \Theta</span>, such that: <span class="math display">
\forall s \in \mathcal{S}, \ \  \forall \theta \in \Theta, \ \
L(s; \widehat{\theta}(s))\geq L(s; \theta).
</span></p></li>
</ul>
<p>In addition, we define:</p>
<ul>
<li><p><strong>(SAEM1)</strong> For all <span class="math inline">k</span> in <span class="math inline">\mathbb{N}</span>, <span class="math inline">\gamma_k \in [0,1]</span>, <span class="math inline">\sum_{k=1}^\infty \gamma_k = \infty</span> and <span class="math inline">\sum_{k=1}^\infty \gamma_k^2 &lt; \infty</span>.</p></li>
<li><p><strong>(SAEM2)</strong> <span class="math inline">l:\Theta \rightarrow \mathbb{R}</span> and <span class="math inline">\widehat{\theta} : \mathcal{S} \rightarrow \Theta</span> are <span class="math inline">m</span> times differentiable, where <span class="math inline">m</span> is the integer such that <span class="math inline">\mathcal{S}</span> is an open subset of <span class="math inline">\mathbb{R}^m</span>.</p></li>
<li><p><strong>(SAEM3)</strong> For all positive Borel functions <span class="math inline">\Phi</span>, we have <span class="math inline">E[ \Phi( z_{k+1}) | \mathcal{F}_k ] = \int \Phi( z ) p ( z; \theta_k) \mu( dz).</span></p></li>
<li><p><strong>(SAEM4)</strong> For all <span class="math inline">\theta \in \Theta</span>, <span class="math inline">\mathrm{E}_\theta(\|S(Z)\|^{2})&lt; \infty</span>, and the function <span class="math display">
\begin{split}
\Gamma(\theta) \triangleq \mathrm{Cov}_\theta [S(z)]\triangleq &amp;\int
S(z)^t S(z) p(z;\theta)\mu(dz)\\
&amp;-\left[\int S(z)p(z;\theta)\mu(dz)\right]^t\left[\int S(z)p(z;\theta)\mu(dz)\right]
\end{split}
</span> is continuous w.r.t. <span class="math inline">\theta</span>, where <span class="math inline">\mathrm{E}_\theta</span> stands for the expectation with respect to the posterior distribution <span class="math inline">p(\cdot;\theta)</span>.</p></li>
</ul>
<p>We also define assumptions required for the normality result:</p>
<ul>
<li><p><strong>(SAEM1’)</strong> There exist <span class="math inline">\gamma^*&gt;0</span> and <span class="math inline">1/2&lt; \alpha&lt;1</span> such that <span class="math inline">\lim k^\alpha /\gamma_k =\gamma^*</span>, and <span class="math inline">\gamma_k / \gamma_{k+1}=1 + O(k^{-1})</span>.</p></li>
<li><p><strong>(SAEM4’)</strong> For some <span class="math inline">\varepsilon&gt;0</span>, <span class="math inline">\sup_\theta \mathrm{E}_\theta(\|S(Z)\|^{2+\varepsilon})&lt; \infty</span> and <span class="math inline">\theta \rightarrow \Gamma(\theta)</span> is continuous w.r.t. <span class="math inline">\theta</span>.</p></li>
<li><p><strong>(LOC1)</strong> The stationary points of <span class="math inline">l</span> are isolated: any compact subset of <span class="math inline">\Theta</span> contains only a finite number of such points.</p></li>
<li><p><strong>(LOC2)</strong> For every stationary point <span class="math inline">\theta^*</span>, the matrices <span class="math inline">\mathrm{E}_\theta^*(\partial_\theta L(S(Z),\theta^*) (\partial_\theta L(S(Z),\theta^*))^t)</span> and <span class="math inline">\partial_\theta^2 L(\mathrm{E}_\theta^* (S(Z)),\theta^*)</span> are positive definite.</p></li>
<li><p><strong>(LOC3)</strong> The minimum eigenvalue of the covariance matrix <span class="math inline">R(\theta)=\mathrm{E}_\theta((S(Z)-\bar{s}(\theta))(S(Z)-\bar{s}(\theta))^t)</span> is bounded away from zero for <span class="math inline">\theta</span> in any compact subset of <span class="math inline">\Theta</span>.</p></li>
</ul>
</section>
<section id="r-functions" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="r-functions"><span class="header-section-number">6.3</span> R functions</h2>
<section id="sec-R-exactFIMLMM" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="sec-R-exactFIMLMM"><span class="header-section-number">6.3.1</span> Exact computation of the Fisher information matrix in the linear mixed effects model</h3>
<div class="cell" data-file="functions/Fisher_LMM.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Computation of the exact Fisher Information matrix in the linear mixed-effects</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="do">## model</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>Fisher_LMM <span class="ot">&lt;-</span> <span class="cf">function</span>(beta,sigma2,eta2,j){</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># beta    : value of the fixed-effect </span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sigma2  : value of the residual variance </span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># eta2    : value of the random effects variance</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># j       : number of observations per individual</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  crochet <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>j<span class="sc">*</span>eta2<span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">3</span> <span class="sc">+</span> </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="dv">4</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">3</span><span class="sc">/</span>sigma2</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>  alpha   <span class="ot">&lt;-</span> j<span class="sc">*</span>(eta2<span class="sc">+</span>sigma2)<span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">3</span> <span class="sc">-</span> </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    eta2<span class="sc">/</span><span class="dv">2</span><span class="sc">*</span>j<span class="sc">*</span>(j<span class="sc">*</span>eta2<span class="sc">+</span>sigma2)<span class="sc">*</span>crochet <span class="sc">-</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    (j<span class="dv">-1</span>)<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>  fisher  <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">c</span>(j<span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j),<span class="dv">0</span>,<span class="dv">0</span>),</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">c</span>(<span class="dv">0</span>,j<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span>,j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">c</span>(<span class="dv">0</span>,j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span>,alpha))</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(fisher)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="sec-R-estFIMLMM" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2" class="anchored" data-anchor-id="sec-R-estFIMLMM"><span class="header-section-number">6.3.2</span> Fisher information matrix extimation in the linear mixed effects model</h3>
<div class="cell" data-file="functions/Isco_LMM.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Computation of the estimator of the Fisher information matrix based on </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="do">## the score</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>Isco_LMM <span class="ot">&lt;-</span> <span class="cf">function</span>(datamat,beta,sigma2,eta2){</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># datamat : observations organized in a matrix. Each row is an individual</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#           vector of observations.</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># beta    : value of the fixed-effect </span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sigma2  : value of the residual variance </span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># eta2    : value of the random effects variance</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  n   <span class="ot">&lt;-</span> <span class="fu">dim</span>(datamat)[<span class="dv">1</span>]</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  j   <span class="ot">&lt;-</span> <span class="fu">dim</span>(datamat)[<span class="dv">2</span>]</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  derivative     <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">3</span>,n)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  derivative[<span class="dv">1</span>,] <span class="ot">&lt;-</span> <span class="fu">apply</span>(datamat<span class="sc">-</span>beta,<span class="dv">1</span>,sum)<span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  derivative[<span class="dv">2</span>,] <span class="ot">&lt;-</span> <span class="fu">apply</span>(datamat<span class="sc">-</span>beta,<span class="dv">1</span>,sum)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  derivative[<span class="dv">3</span>,] <span class="ot">&lt;-</span> <span class="fu">apply</span>((datamat<span class="sc">-</span>beta)<span class="sc">^</span><span class="dv">2</span>,<span class="dv">1</span>,sum)<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">apply</span>(datamat<span class="sc">-</span>beta,<span class="dv">1</span>,sum)<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>eta2<span class="sc">*</span>(j<span class="sc">*</span>eta2<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>sigma2)<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">-</span>(j<span class="dv">-1</span>)<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  Isco <span class="ot">&lt;-</span> derivative<span class="sc">%*%</span><span class="fu">t</span>(derivative)<span class="sc">/</span>n</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(Isco)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-file="functions/Iobs_LMM.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Computation of the observed information matrix in the linear mixed-effects </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="do">## model</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>Iobs_LMM <span class="ot">&lt;-</span> <span class="cf">function</span>(datamat,beta,sigma2,eta2){</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># datamat : observations organized in a matrix. Each row is an individual</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#           vector of observations.</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># beta    : value of the fixed-effect </span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sigma2  : value of the residual variance </span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># eta2    : value of the random effects variance</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  n   <span class="ot">&lt;-</span> <span class="fu">dim</span>(datamat)[<span class="dv">1</span>]</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  j   <span class="ot">&lt;-</span> <span class="fu">dim</span>(datamat)[<span class="dv">2</span>]</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  obs <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(datamat)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  Iobs      <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">1</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span> n<span class="sc">*</span>j<span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">2</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span> j<span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sum</span>(obs<span class="sc">-</span>beta)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">1</span>,<span class="dv">2</span>] <span class="ot">&lt;-</span> Iobs[<span class="dv">2</span>,<span class="dv">1</span>]</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">2</span>,<span class="dv">2</span>] <span class="ot">&lt;-</span> j<span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(datamat<span class="sc">-</span>beta,<span class="dv">1</span>,sum)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">-</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    n<span class="sc">*</span>j<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">3</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span><span class="fu">sum</span>(obs<span class="sc">-</span>beta)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">1</span>,<span class="dv">3</span>] <span class="ot">&lt;-</span> Iobs[<span class="dv">3</span>,<span class="dv">1</span>]</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">2</span>,<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(datamat<span class="sc">-</span>beta,<span class="dv">1</span>,sum)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">-</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    n<span class="sc">*</span>j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">3</span>,<span class="dv">2</span>] <span class="ot">&lt;-</span> Iobs[<span class="dv">2</span>,<span class="dv">3</span>]</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>  Iobs[<span class="dv">3</span>,<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>(sigma2)<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span><span class="fu">sum</span>((obs<span class="sc">-</span>beta)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">-</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    eta2<span class="sc">*</span><span class="fu">sum</span>(<span class="fu">apply</span>(datamat<span class="sc">-</span>beta,<span class="dv">1</span>,sum)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">*</span>(j<span class="sc">*</span>eta2<span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">3</span> <span class="sc">+</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">3</span><span class="sc">/</span>sigma2 ) <span class="sc">-</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    n<span class="sc">*</span>(j<span class="dv">-1</span>)<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> n<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>(sigma2<span class="sc">+</span>eta2<span class="sc">*</span>j)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>  Iobs <span class="ot">&lt;-</span> Iobs<span class="sc">/</span>n</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(Iobs)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="sec-R-estFIMPoisson" class="level3" data-number="6.3.3">
<h3 data-number="6.3.3" class="anchored" data-anchor-id="sec-R-estFIMPoisson"><span class="header-section-number">6.3.3</span> Fisher information matrix estimation in the Poisson mixture model</h3>
<div class="cell" data-file="functions/fisher_estimation_poisson_mixture.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Function for computing Isco and Iobs for Fisher Information matrix estimation </span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="do">## in Poisson mixture models </span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>fisher_estimation_poisson_mixture <span class="ot">&lt;-</span> <span class="cf">function</span>(y, lambda, alpha) {</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># y      : vector of observations</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># lambda : vector of K Poisson parameters for each component of the mixture</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">#         (in ascending order)</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># alpha  : vector of (K-1) mixture proportions</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  K <span class="ot">&lt;-</span> <span class="fu">length</span>(lambda) <span class="co"># number of components of the mixture</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)      <span class="co"># sample size</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  deriv1ind  <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>,n) </span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  deriv2     <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>) </span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>  covderiv   <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>  <span class="do">## computation of conditional expectation of the first derivatives of the </span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>  <span class="do">## complete data log-likelihood</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>  denom <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(K<span class="dv">-1</span>)){</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    denom <span class="ot">&lt;-</span> denom <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>lambda[k])<span class="sc">*</span>lambda[k]<span class="sc">^</span>y<span class="sc">*</span>alpha[k]</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>  denom <span class="ot">&lt;-</span> denom <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(K<span class="dv">-1</span>)){</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    deriv1ind[k,]   <span class="ot">&lt;-</span> </span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>      <span class="fu">exp</span>(<span class="sc">-</span>lambda[k])<span class="sc">*</span>lambda[k]<span class="sc">^</span>y<span class="sc">*</span>alpha[k]<span class="sc">/</span>denom<span class="sc">*</span>(y<span class="sc">/</span>lambda[k]<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    deriv1ind[K<span class="sc">+</span>k,] <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span>lambda[k])<span class="sc">*</span>lambda[k]<span class="sc">^</span>y<span class="sc">/</span>denom <span class="sc">-</span> </span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>      <span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">/</span>denom</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>  deriv1ind[K,] <span class="ot">&lt;-</span> </span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    <span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))<span class="sc">/</span>denom<span class="sc">*</span>(y<span class="sc">/</span>lambda[K]<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>  <span class="do">## computation of conditional expectation of the second derivatives of the </span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>  <span class="do">## complete data log-likelihood</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(K<span class="dv">-1</span>)){</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>    deriv2[k,k]     <span class="ot">&lt;-</span> </span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[k])<span class="sc">*</span>lambda[k]<span class="sc">^</span>y<span class="sc">*</span>alpha[k]<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span>y<span class="sc">/</span>lambda[k]<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    deriv2[K<span class="sc">+</span>k,K<span class="sc">+</span>k] <span class="ot">&lt;-</span> </span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>(<span class="sc">-</span><span class="fu">exp</span>(<span class="sc">-</span>lambda[k])<span class="sc">*</span>lambda[k]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">/</span>alpha[k] <span class="sc">-</span></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>                             <span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">*</span>(<span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))))</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(K<span class="dv">-2</span>)){</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (l <span class="cf">in</span> (k<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>(K<span class="dv">-1</span>)){</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>      deriv2[K<span class="sc">+</span>k,K<span class="sc">+</span>l] <span class="ot">&lt;-</span> <span class="sc">-</span> </span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">*</span>(<span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))))</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>      deriv2[K<span class="sc">+</span>l,K<span class="sc">+</span>k] <span class="ot">&lt;-</span> deriv2[K<span class="sc">+</span>k,K<span class="sc">+</span>l] </span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>  deriv2[K,K]<span class="ot">&lt;-</span></span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span>y<span class="sc">/</span>lambda[K]<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>  <span class="do">## computation of the conditional covariance matrix of the first derivatives </span></span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a>  <span class="do">## of the complete data log-likelihood</span></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(K<span class="dv">-2</span>)){</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>    covderiv[k,k] <span class="ot">&lt;-</span> </span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[k])<span class="sc">*</span>lambda[k]<span class="sc">^</span>y<span class="sc">*</span>alpha[k]<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">+</span>y<span class="sc">/</span>lambda[k])<span class="sc">^</span><span class="dv">2</span>) </span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>    covderiv[k<span class="sc">+</span>K,k<span class="sc">+</span>K] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[k])<span class="sc">*</span>lambda[k]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">/</span>alpha[k] <span class="sc">+</span></span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))) </span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (l <span class="cf">in</span> (k<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>(K<span class="dv">-1</span>)){</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a>      covderiv[k<span class="sc">+</span>K,l<span class="sc">+</span>K] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))) </span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a>      covderiv[l<span class="sc">+</span>K,k<span class="sc">+</span>K] <span class="ot">&lt;-</span> covderiv[k<span class="sc">+</span>K,l<span class="sc">+</span>K]</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a>    } </span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>    covderiv[k,K<span class="sc">+</span>k] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[k])<span class="sc">*</span>lambda[k]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">+</span>y<span class="sc">/</span>lambda[k])) </span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a>    covderiv[k<span class="sc">+</span>K,k] <span class="ot">&lt;-</span> covderiv[k,K<span class="sc">+</span>k]</span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a>    covderiv[K,K<span class="sc">+</span>k] <span class="ot">&lt;-</span> </span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">+</span>y<span class="sc">/</span>lambda[K])<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span>)) </span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true" tabindex="-1"></a>    covderiv[K<span class="sc">+</span>k,K] <span class="ot">&lt;-</span> covderiv[K,K<span class="sc">+</span>k]</span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true" tabindex="-1"></a>  covderiv[K<span class="dv">-1</span>,K<span class="dv">-1</span>] <span class="ot">&lt;-</span> </span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K<span class="dv">-1</span>])<span class="sc">*</span>lambda[K<span class="dv">-1</span>]<span class="sc">^</span>y<span class="sc">*</span>alpha[K<span class="dv">-1</span>]<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">+</span>y<span class="sc">/</span>lambda[K<span class="dv">-1</span>])<span class="sc">^</span><span class="dv">2</span>) </span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true" tabindex="-1"></a>  covderiv[<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K<span class="dv">-1</span>])<span class="sc">*</span>lambda[K<span class="dv">-1</span>]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">/</span>alpha[K<span class="dv">-1</span>]<span class="sc">+</span></span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))) </span>
<span id="cb10-84"><a href="#cb10-84" aria-hidden="true" tabindex="-1"></a>  covderiv[K<span class="dv">-1</span>,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>] <span class="ot">&lt;-</span> </span>
<span id="cb10-85"><a href="#cb10-85" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K<span class="dv">-1</span>])<span class="sc">*</span>lambda[K<span class="dv">-1</span>]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">+</span>y<span class="sc">/</span>lambda[K<span class="dv">-1</span>])) </span>
<span id="cb10-86"><a href="#cb10-86" aria-hidden="true" tabindex="-1"></a>  covderiv[<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>,K<span class="dv">-1</span>] <span class="ot">&lt;-</span> covderiv[K<span class="dv">-1</span>,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>]</span>
<span id="cb10-87"><a href="#cb10-87" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-88"><a href="#cb10-88" aria-hidden="true" tabindex="-1"></a>  covderiv[K,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>] <span class="ot">&lt;-</span> </span>
<span id="cb10-89"><a href="#cb10-89" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">+</span>y<span class="sc">/</span>lambda[K])<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span>)) </span>
<span id="cb10-90"><a href="#cb10-90" aria-hidden="true" tabindex="-1"></a>  covderiv[<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>,K] <span class="ot">&lt;-</span> covderiv[K,<span class="dv">2</span><span class="sc">*</span>K<span class="dv">-1</span>]</span>
<span id="cb10-91"><a href="#cb10-91" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-92"><a href="#cb10-92" aria-hidden="true" tabindex="-1"></a>  covderiv[K,K] <span class="ot">&lt;-</span> </span>
<span id="cb10-93"><a href="#cb10-93" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>(<span class="fu">exp</span>(<span class="sc">-</span>lambda[K])<span class="sc">*</span>lambda[K]<span class="sc">^</span>y<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(alpha))<span class="sc">/</span>denom<span class="sc">*</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">+</span>y<span class="sc">/</span>lambda[K])<span class="sc">^</span><span class="dv">2</span>) </span>
<span id="cb10-94"><a href="#cb10-94" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-95"><a href="#cb10-95" aria-hidden="true" tabindex="-1"></a>  <span class="do">## computation of Isco and Iobs</span></span>
<span id="cb10-96"><a href="#cb10-96" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-97"><a href="#cb10-97" aria-hidden="true" tabindex="-1"></a>  Isco <span class="ot">&lt;-</span> deriv1ind<span class="sc">%*%</span><span class="fu">t</span>(deriv1ind)<span class="sc">/</span>n</span>
<span id="cb10-98"><a href="#cb10-98" aria-hidden="true" tabindex="-1"></a>  Iobs <span class="ot">&lt;-</span> deriv1ind<span class="sc">%*%</span><span class="fu">t</span>(deriv1ind)<span class="sc">/</span>n <span class="sc">-</span> deriv2<span class="sc">/</span>n <span class="sc">-</span> covderiv<span class="sc">/</span>n</span>
<span id="cb10-99"><a href="#cb10-99" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-100"><a href="#cb10-100" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-101"><a href="#cb10-101" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">Isco =</span> Isco, <span class="at">Iobs =</span> Iobs)</span>
<span id="cb10-102"><a href="#cb10-102" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-103"><a href="#cb10-103" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(res)</span>
<span id="cb10-104"><a href="#cb10-104" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="sec-R-saemNLMEexp" class="level3" data-number="6.3.4">
<h3 data-number="6.3.4" class="anchored" data-anchor-id="sec-R-saemNLMEexp"><span class="header-section-number">6.3.4</span> SAEM algorithm in the PK model belonging to the curved exponential family</h3>
<div class="cell" data-file="functions/saem_nlme_exponential_bis.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="do">## R function implementing the saem algorithm to compute the parameter estimates </span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="do">## and the FIM estimates simultaneously in the PK nonlinear mixed-effects model</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="do">## with three random effects, thus belonging to the curved exponential family</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>saem <span class="ot">&lt;-</span> <span class="cf">function</span>(data, nbiterem, nbiterburnin, theta0, <span class="at">kRW=</span><span class="fl">0.5</span>) {</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># data         : dataset </span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># nbiterem     : total number of iterations of the saem algorithm</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># nbiterburnin : number of burn-in iterations of the algorithm</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># theta0       : initial parameter values</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># kRW          : coefficient used to adjust the variance of the proposal </span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  <span class="co">#                kernel of the MCMC procedure</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># data processing</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  xidep <span class="ot">&lt;-</span> <span class="fu">cbind</span>(data<span class="sc">$</span>dose,data<span class="sc">$</span>time)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  y     <span class="ot">&lt;-</span> data<span class="sc">$</span>y</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  id    <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(data<span class="sc">$</span>subject)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  n     <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">unique</span>(id))</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  j     <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>time))</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  nb.psi         <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>  dimstatexh     <span class="ot">&lt;-</span> <span class="dv">7</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initial parameter values</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>  vpop     <span class="ot">&lt;-</span> theta0<span class="sc">$</span>vpop</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>  kapop    <span class="ot">&lt;-</span> theta0<span class="sc">$</span>kapop</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>  clpop    <span class="ot">&lt;-</span> theta0<span class="sc">$</span>clpop</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>  omega2v  <span class="ot">&lt;-</span> theta0<span class="sc">$</span>omega2v</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>  omega2ka <span class="ot">&lt;-</span> theta0<span class="sc">$</span>omega2ka</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>  omega2cl <span class="ot">&lt;-</span> theta0<span class="sc">$</span>omega2cl</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>  sigma2   <span class="ot">&lt;-</span> theta0<span class="sc">$</span>sigma2</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">length</span>(theta0)</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>  thetaest     <span class="ot">&lt;-</span>  <span class="fu">matrix</span>(<span class="dv">0</span>,p,nbiterem)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>  thetaest[,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">c</span>(kapop,vpop,clpop,omega2ka,omega2v,omega2cl,sigma2)</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>  <span class="co"># variances of the proposal kernels of the MCMC procedure</span></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>  eta2v  <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2v</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>  eta2ka <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2ka</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>  eta2cl <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2cl</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sequence of step sizes</span></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>  gamma <span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fu">rep</span>(<span class="fl">0.95</span>,nbiterburnin), <span class="dv">1</span><span class="sc">/</span>(<span class="dv">2</span><span class="sc">:</span>nbiterem)<span class="sc">^</span><span class="fl">0.6</span>)</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>  C       <span class="ot">&lt;-</span> <span class="dv">50000</span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>  eta     <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">/</span><span class="dv">5</span></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>  epsilon <span class="ot">&lt;-</span> C<span class="sc">*</span>gamma<span class="sc">^</span>eta</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initialize counters for reprojections</span></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>  nu    <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>  zeta  <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>  kappa <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>  <span class="co"># intermediary R objects</span></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>  deltaindi      <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,n,nbiterem))</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a>  H              <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,p,n,nbiterem))</span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>  G2             <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,p,nbiterem))</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>  tempderiveeas  <span class="ot">&lt;-</span><span class="fu">matrix</span>(<span class="dv">0</span>,p,n)</span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>  tempderiveeas2 <span class="ot">&lt;-</span><span class="fu">matrix</span>(<span class="dv">0</span>,p,p)</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>  dimstatexh     <span class="ot">&lt;-</span> <span class="dv">7</span></span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a>  statexh        <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(dimstatexh,n,nbiterem)) </span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>  psi            <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="at">dim=</span><span class="fu">c</span>(n,nb.psi,nbiterem))</span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initial values for the individual parameters</span></span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>  currentv   <span class="ot">&lt;-</span> <span class="fu">log</span>(vpop)  <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2v))</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>  currentka  <span class="ot">&lt;-</span> <span class="fu">log</span>(kapop) <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2ka))</span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>  currentcl  <span class="ot">&lt;-</span> <span class="fu">log</span>(clpop) <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2cl))</span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a>  currentpsi <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">exp</span>(currentka),<span class="fu">exp</span>(currentv),<span class="fu">exp</span>(currentcl))</span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a>  psi[,,<span class="dv">1</span>]   <span class="ot">&lt;-</span> psiinit <span class="ot">&lt;-</span> currentpsi </span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span>(<span class="fu">compact</span>(statexh[,,<span class="dv">1</span>],kappa)<span class="sc">==</span><span class="dv">0</span>){</span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a>    currentv   <span class="ot">&lt;-</span> <span class="fu">log</span>(vpop)  <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2v))</span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a>    currentka  <span class="ot">&lt;-</span> <span class="fu">log</span>(kapop) <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2ka))</span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>    currentcl  <span class="ot">&lt;-</span> <span class="fu">log</span>(clpop) <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2cl))</span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a>    currentpsi <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">exp</span>(currentka),<span class="fu">exp</span>(currentv),<span class="fu">exp</span>(currentcl))</span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>    psi[,,<span class="dv">1</span>]   <span class="ot">&lt;-</span> psiinit <span class="ot">&lt;-</span> currentpsi </span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a>    mco           <span class="ot">&lt;-</span> <span class="fu">matrix</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(psi,id,xidep))<span class="sc">^</span><span class="dv">2</span>,n,j,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a>    statexh[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">log</span>(psi))</span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a>    statexh[<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>,,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">log</span>(psi)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a>    statexh[<span class="dv">7</span>,,<span class="dv">1</span>]   <span class="ot">&lt;-</span> <span class="fu">apply</span>(mco,<span class="dv">1</span>,sum)</span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Start of the em loop</span></span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (l <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(nbiterem<span class="dv">-1</span>)){</span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Simulation step</span></span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (nu<span class="sc">==</span><span class="dv">0</span>){ </span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a>      <span class="do">## Reprojection</span></span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a>      psi[,,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> currentpsi <span class="ot">&lt;-</span> psiinit</span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span>{</span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a>      <span class="do">## Standard simulation procedure </span></span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(n)){</span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a>        <span class="do">## Variable ka</span></span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a>        candidatka    <span class="ot">&lt;-</span> currentka</span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a>        candidatka[k] <span class="ot">&lt;-</span> candidatka[k] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2ka))</span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a>        psicandidat   <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">exp</span>(candidatka),<span class="fu">exp</span>(currentv),<span class="fu">exp</span>(currentcl))</span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a>        logs          <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(psicandidat,id,xidep))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span></span>
<span id="cb11-111"><a href="#cb11-111" aria-hidden="true" tabindex="-1"></a>          <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(currentpsi,id,xidep))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-112"><a href="#cb11-112" aria-hidden="true" tabindex="-1"></a>        logs          <span class="ot">&lt;-</span> logs<span class="dv">-1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka<span class="sc">*</span>((candidatka[k]<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span></span>
<span id="cb11-113"><a href="#cb11-113" aria-hidden="true" tabindex="-1"></a>                                              (currentka[k]<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-114"><a href="#cb11-114" aria-hidden="true" tabindex="-1"></a>        u             <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a>        logu          <span class="ot">&lt;-</span> <span class="fu">log</span>(u)</span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a>        ind           <span class="ot">&lt;-</span> (logu<span class="sc">&lt;</span>logs)</span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a>        currentpsi    <span class="ot">&lt;-</span> psicandidat<span class="sc">*</span>ind<span class="sc">+</span>currentpsi<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb11-118"><a href="#cb11-118" aria-hidden="true" tabindex="-1"></a>        currentka     <span class="ot">&lt;-</span> candidatka<span class="sc">*</span>ind<span class="sc">+</span>currentka<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb11-119"><a href="#cb11-119" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-120"><a href="#cb11-120" aria-hidden="true" tabindex="-1"></a>        <span class="do">## Variable V</span></span>
<span id="cb11-121"><a href="#cb11-121" aria-hidden="true" tabindex="-1"></a>        candidatv    <span class="ot">&lt;-</span> currentv</span>
<span id="cb11-122"><a href="#cb11-122" aria-hidden="true" tabindex="-1"></a>        candidatv[k] <span class="ot">&lt;-</span> candidatv[k] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2v))</span>
<span id="cb11-123"><a href="#cb11-123" aria-hidden="true" tabindex="-1"></a>        psicandidat  <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">exp</span>(currentka),<span class="fu">exp</span>(candidatv),<span class="fu">exp</span>(currentcl))</span>
<span id="cb11-124"><a href="#cb11-124" aria-hidden="true" tabindex="-1"></a>        logs         <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(psicandidat,id,xidep))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span> </span>
<span id="cb11-125"><a href="#cb11-125" aria-hidden="true" tabindex="-1"></a>          <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(currentpsi,id,xidep))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-126"><a href="#cb11-126" aria-hidden="true" tabindex="-1"></a>        logs         <span class="ot">&lt;-</span> logs <span class="sc">-</span></span>
<span id="cb11-127"><a href="#cb11-127" aria-hidden="true" tabindex="-1"></a>          <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2v<span class="sc">*</span>((candidatv[k]<span class="sc">-</span><span class="fu">log</span>(vpop))<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>(currentv[k]<span class="sc">-</span><span class="fu">log</span>(vpop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-128"><a href="#cb11-128" aria-hidden="true" tabindex="-1"></a>        u            <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb11-129"><a href="#cb11-129" aria-hidden="true" tabindex="-1"></a>        logu         <span class="ot">&lt;-</span> <span class="fu">log</span>(u)</span>
<span id="cb11-130"><a href="#cb11-130" aria-hidden="true" tabindex="-1"></a>        ind          <span class="ot">&lt;-</span> (logu<span class="sc">&lt;</span>logs)</span>
<span id="cb11-131"><a href="#cb11-131" aria-hidden="true" tabindex="-1"></a>        currentpsi   <span class="ot">&lt;-</span> psicandidat<span class="sc">*</span>ind<span class="sc">+</span>currentpsi<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb11-132"><a href="#cb11-132" aria-hidden="true" tabindex="-1"></a>        currentv     <span class="ot">&lt;-</span> candidatv<span class="sc">*</span>ind<span class="sc">+</span>currentv<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb11-133"><a href="#cb11-133" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-134"><a href="#cb11-134" aria-hidden="true" tabindex="-1"></a>        <span class="do">## Variable cl</span></span>
<span id="cb11-135"><a href="#cb11-135" aria-hidden="true" tabindex="-1"></a>        candidatcl    <span class="ot">&lt;-</span> currentcl</span>
<span id="cb11-136"><a href="#cb11-136" aria-hidden="true" tabindex="-1"></a>        candidatcl[k] <span class="ot">&lt;-</span> candidatcl[k] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2cl))</span>
<span id="cb11-137"><a href="#cb11-137" aria-hidden="true" tabindex="-1"></a>        psicandidat   <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">exp</span>(currentka),<span class="fu">exp</span>(currentv),<span class="fu">exp</span>(candidatcl))</span>
<span id="cb11-138"><a href="#cb11-138" aria-hidden="true" tabindex="-1"></a>        logs          <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(psicandidat,id,xidep))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span> </span>
<span id="cb11-139"><a href="#cb11-139" aria-hidden="true" tabindex="-1"></a>          <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(currentpsi,id,xidep))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-140"><a href="#cb11-140" aria-hidden="true" tabindex="-1"></a>        logs          <span class="ot">&lt;-</span> logs <span class="sc">-</span></span>
<span id="cb11-141"><a href="#cb11-141" aria-hidden="true" tabindex="-1"></a>          <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl<span class="sc">*</span>((candidatcl[k]<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>(currentcl[k]<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-142"><a href="#cb11-142" aria-hidden="true" tabindex="-1"></a>        u             <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb11-143"><a href="#cb11-143" aria-hidden="true" tabindex="-1"></a>        logu          <span class="ot">&lt;-</span> <span class="fu">log</span>(u)</span>
<span id="cb11-144"><a href="#cb11-144" aria-hidden="true" tabindex="-1"></a>        ind           <span class="ot">&lt;-</span> (logu<span class="sc">&lt;</span>logs)</span>
<span id="cb11-145"><a href="#cb11-145" aria-hidden="true" tabindex="-1"></a>        currentpsi    <span class="ot">&lt;-</span> psicandidat<span class="sc">*</span>ind<span class="sc">+</span>currentpsi<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb11-146"><a href="#cb11-146" aria-hidden="true" tabindex="-1"></a>        currentcl     <span class="ot">&lt;-</span> candidatcl<span class="sc">*</span>ind<span class="sc">+</span>currentcl<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb11-147"><a href="#cb11-147" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-148"><a href="#cb11-148" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb11-149"><a href="#cb11-149" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb11-150"><a href="#cb11-150" aria-hidden="true" tabindex="-1"></a>      psi[,,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> currentpsi</span>
<span id="cb11-151"><a href="#cb11-151" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb11-152"><a href="#cb11-152" aria-hidden="true" tabindex="-1"></a>    <span class="co"># stochastic approximation of exhaustive statistics and parameter estimation update</span></span>
<span id="cb11-153"><a href="#cb11-153" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-154"><a href="#cb11-154" aria-hidden="true" tabindex="-1"></a>    mco           <span class="ot">&lt;-</span> <span class="fu">matrix</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(psi[,,l<span class="sc">+</span><span class="dv">1</span>],id,xidep))<span class="sc">^</span><span class="dv">2</span>,n,j,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb11-155"><a href="#cb11-155" aria-hidden="true" tabindex="-1"></a>    statexh[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> statexh[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span>gamma[l]<span class="sc">*</span><span class="fu">t</span>(<span class="fu">log</span>(psi[,,l<span class="sc">+</span><span class="dv">1</span>]))</span>
<span id="cb11-156"><a href="#cb11-156" aria-hidden="true" tabindex="-1"></a>    statexh[<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>,,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> statexh[<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>,,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span>gamma[l]<span class="sc">*</span><span class="fu">t</span>(<span class="fu">log</span>(psi[,,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-157"><a href="#cb11-157" aria-hidden="true" tabindex="-1"></a>    statexh[<span class="dv">7</span>,,l<span class="sc">+</span><span class="dv">1</span>]   <span class="ot">&lt;-</span> statexh[<span class="dv">7</span>,,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span>gamma[l]<span class="sc">*</span><span class="fu">apply</span>(mco,<span class="dv">1</span>,sum)</span>
<span id="cb11-158"><a href="#cb11-158" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-159"><a href="#cb11-159" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-160"><a href="#cb11-160" aria-hidden="true" tabindex="-1"></a>    norm.delta.statexh <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((statexh[,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span>statexh[,,l])<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb11-161"><a href="#cb11-161" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-162"><a href="#cb11-162" aria-hidden="true" tabindex="-1"></a>    <span class="do">## check if reprojection will be necessary at next iteration</span></span>
<span id="cb11-163"><a href="#cb11-163" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ((norm.delta.statexh<span class="sc">&lt;=</span>epsilon[zeta]) <span class="sc">&amp;&amp;</span> (<span class="fu">compact</span>(statexh[,,l<span class="sc">+</span><span class="dv">1</span>],kappa)<span class="sc">==</span><span class="dv">1</span>)){</span>
<span id="cb11-164"><a href="#cb11-164" aria-hidden="true" tabindex="-1"></a>      kappa <span class="ot">&lt;-</span> kappa</span>
<span id="cb11-165"><a href="#cb11-165" aria-hidden="true" tabindex="-1"></a>      zeta  <span class="ot">&lt;-</span> zeta <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb11-166"><a href="#cb11-166" aria-hidden="true" tabindex="-1"></a>      nu    <span class="ot">&lt;-</span> nu <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb11-167"><a href="#cb11-167" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span>{</span>
<span id="cb11-168"><a href="#cb11-168" aria-hidden="true" tabindex="-1"></a>      nu    <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb11-169"><a href="#cb11-169" aria-hidden="true" tabindex="-1"></a>      kappa <span class="ot">&lt;-</span> kappa <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb11-170"><a href="#cb11-170" aria-hidden="true" tabindex="-1"></a>      zeta  <span class="ot">&lt;-</span> zeta <span class="sc">+</span> <span class="dv">1</span> </span>
<span id="cb11-171"><a href="#cb11-171" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb11-172"><a href="#cb11-172" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-173"><a href="#cb11-173" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-174"><a href="#cb11-174" aria-hidden="true" tabindex="-1"></a>    kapop    <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">mean</span>(statexh[<span class="dv">1</span>,,l<span class="sc">+</span><span class="dv">1</span>]))</span>
<span id="cb11-175"><a href="#cb11-175" aria-hidden="true" tabindex="-1"></a>    vpop     <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">mean</span>(statexh[<span class="dv">2</span>,,l<span class="sc">+</span><span class="dv">1</span>]))</span>
<span id="cb11-176"><a href="#cb11-176" aria-hidden="true" tabindex="-1"></a>    clpop    <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">mean</span>(statexh[<span class="dv">3</span>,,l<span class="sc">+</span><span class="dv">1</span>]))</span>
<span id="cb11-177"><a href="#cb11-177" aria-hidden="true" tabindex="-1"></a>    omega2ka <span class="ot">&lt;-</span> <span class="fu">mean</span>(statexh[<span class="dv">4</span>,,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">mean</span>(statexh[<span class="dv">1</span>,,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-178"><a href="#cb11-178" aria-hidden="true" tabindex="-1"></a>    omega2v  <span class="ot">&lt;-</span> <span class="fu">mean</span>(statexh[<span class="dv">5</span>,,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">mean</span>(statexh[<span class="dv">2</span>,,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-179"><a href="#cb11-179" aria-hidden="true" tabindex="-1"></a>    omega2cl <span class="ot">&lt;-</span> <span class="fu">mean</span>(statexh[<span class="dv">6</span>,,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">mean</span>(statexh[<span class="dv">3</span>,,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-180"><a href="#cb11-180" aria-hidden="true" tabindex="-1"></a>    sigma2   <span class="ot">&lt;-</span> <span class="fu">sum</span>(statexh[<span class="dv">7</span>,,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">/</span>n<span class="sc">/</span>j</span>
<span id="cb11-181"><a href="#cb11-181" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-182"><a href="#cb11-182" aria-hidden="true" tabindex="-1"></a>    thetaest[,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">c</span>(kapop, vpop, clpop, omega2ka, omega2v, omega2cl, sigma2)</span>
<span id="cb11-183"><a href="#cb11-183" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-184"><a href="#cb11-184" aria-hidden="true" tabindex="-1"></a>    eta2ka   <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2ka</span>
<span id="cb11-185"><a href="#cb11-185" aria-hidden="true" tabindex="-1"></a>    eta2v    <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2v</span>
<span id="cb11-186"><a href="#cb11-186" aria-hidden="true" tabindex="-1"></a>    eta2cl   <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2cl</span>
<span id="cb11-187"><a href="#cb11-187" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-188"><a href="#cb11-188" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Stochastic approximation of the derivatives of the complete log-likelihood</span></span>
<span id="cb11-189"><a href="#cb11-189" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-190"><a href="#cb11-190" aria-hidden="true" tabindex="-1"></a>    <span class="do">### For the computation of Isco</span></span>
<span id="cb11-191"><a href="#cb11-191" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-192"><a href="#cb11-192" aria-hidden="true" tabindex="-1"></a>    deltaindi[<span class="dv">1</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span> (statexh[<span class="dv">1</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">/</span>omega2ka<span class="sc">/</span>kapop</span>
<span id="cb11-193"><a href="#cb11-193" aria-hidden="true" tabindex="-1"></a>    deltaindi[<span class="dv">2</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span> (statexh[<span class="dv">2</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span><span class="fu">log</span>(vpop))<span class="sc">/</span>omega2v<span class="sc">/</span>vpop</span>
<span id="cb11-194"><a href="#cb11-194" aria-hidden="true" tabindex="-1"></a>    deltaindi[<span class="dv">3</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span> (statexh[<span class="dv">3</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">/</span>omega2cl<span class="sc">/</span>clpop</span>
<span id="cb11-195"><a href="#cb11-195" aria-hidden="true" tabindex="-1"></a>    deltaindi[<span class="dv">4</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka <span class="sc">+</span></span>
<span id="cb11-196"><a href="#cb11-196" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(statexh[<span class="dv">4</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span><span class="dv">2</span><span class="sc">*</span>statexh[<span class="dv">1</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">*</span><span class="fu">log</span>(kapop)<span class="sc">+</span><span class="fu">log</span>(kapop)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-197"><a href="#cb11-197" aria-hidden="true" tabindex="-1"></a>    deltaindi[<span class="dv">5</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2v <span class="sc">+</span></span>
<span id="cb11-198"><a href="#cb11-198" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2v<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(statexh[<span class="dv">5</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span><span class="dv">2</span><span class="sc">*</span>statexh[<span class="dv">2</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">*</span><span class="fu">log</span>(vpop)<span class="sc">+</span><span class="fu">log</span>(vpop)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-199"><a href="#cb11-199" aria-hidden="true" tabindex="-1"></a>    deltaindi[<span class="dv">6</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl <span class="sc">+</span></span>
<span id="cb11-200"><a href="#cb11-200" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(statexh[<span class="dv">6</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span><span class="dv">2</span><span class="sc">*</span>statexh[<span class="dv">3</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">*</span><span class="fu">log</span>(clpop)<span class="sc">+</span><span class="fu">log</span>(clpop)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-201"><a href="#cb11-201" aria-hidden="true" tabindex="-1"></a>    deltaindi[<span class="dv">7</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span> <span class="sc">-</span>j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">+</span>statexh[<span class="dv">7</span>,,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-202"><a href="#cb11-202" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-203"><a href="#cb11-203" aria-hidden="true" tabindex="-1"></a>    <span class="do">### For the computation of Iobs</span></span>
<span id="cb11-204"><a href="#cb11-204" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-205"><a href="#cb11-205" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">1</span>,]<span class="ot">&lt;-</span> (<span class="fu">log</span>(psi[,<span class="dv">1</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">/</span>omega2ka<span class="sc">/</span>kapop</span>
<span id="cb11-206"><a href="#cb11-206" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">2</span>,]<span class="ot">&lt;-</span> (<span class="fu">log</span>(psi[,<span class="dv">2</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(vpop))<span class="sc">/</span>omega2v<span class="sc">/</span>vpop</span>
<span id="cb11-207"><a href="#cb11-207" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">3</span>,]<span class="ot">&lt;-</span> (<span class="fu">log</span>(psi[,<span class="dv">3</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">/</span>omega2cl<span class="sc">/</span>clpop</span>
<span id="cb11-208"><a href="#cb11-208" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">4</span>,]<span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka <span class="sc">+</span></span>
<span id="cb11-209"><a href="#cb11-209" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(<span class="fu">log</span>(psi[,<span class="dv">1</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-210"><a href="#cb11-210" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">5</span>,]<span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2v <span class="sc">+</span></span>
<span id="cb11-211"><a href="#cb11-211" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2v<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(<span class="fu">log</span>(psi[,<span class="dv">2</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(vpop))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-212"><a href="#cb11-212" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">6</span>,]<span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl <span class="sc">+</span></span>
<span id="cb11-213"><a href="#cb11-213" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(<span class="fu">log</span>(psi[,<span class="dv">3</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-214"><a href="#cb11-214" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">7</span>,]<span class="ot">&lt;-</span> <span class="sc">-</span>j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">+</span><span class="fu">apply</span>(mco,<span class="dv">1</span>,sum)<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-215"><a href="#cb11-215" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-216"><a href="#cb11-216" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-217"><a href="#cb11-217" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">1</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span>  <span class="fu">sum</span>(<span class="sc">-</span><span class="fu">log</span>(psi[,<span class="dv">1</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">+</span><span class="fu">log</span>(kapop)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>omega2ka<span class="sc">/</span>kapop<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-218"><a href="#cb11-218" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">2</span>,<span class="dv">2</span>] <span class="ot">&lt;-</span>  <span class="fu">sum</span>(<span class="sc">-</span><span class="fu">log</span>(psi[,<span class="dv">2</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">+</span><span class="fu">log</span>(vpop)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>omega2v<span class="sc">/</span>vpop<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-219"><a href="#cb11-219" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">3</span>,<span class="dv">3</span>] <span class="ot">&lt;-</span>  <span class="fu">sum</span>(<span class="sc">-</span><span class="fu">log</span>(psi[,<span class="dv">3</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">+</span><span class="fu">log</span>(clpop)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>omega2cl<span class="sc">/</span>clpop<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb11-220"><a href="#cb11-220" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">4</span>,<span class="dv">4</span>] <span class="ot">&lt;-</span>  n<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span></span>
<span id="cb11-221"><a href="#cb11-221" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span><span class="fu">sum</span>((<span class="fu">log</span>(psi[,<span class="dv">1</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-222"><a href="#cb11-222" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">5</span>,<span class="dv">5</span>] <span class="ot">&lt;-</span>  n<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2v<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span></span>
<span id="cb11-223"><a href="#cb11-223" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span>omega2v<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span><span class="fu">sum</span>((<span class="fu">log</span>(psi[,<span class="dv">2</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(vpop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-224"><a href="#cb11-224" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">6</span>,<span class="dv">6</span>] <span class="ot">&lt;-</span>  n<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span></span>
<span id="cb11-225"><a href="#cb11-225" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span><span class="fu">sum</span>((<span class="fu">log</span>(psi[,<span class="dv">3</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb11-226"><a href="#cb11-226" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">7</span>,<span class="dv">7</span>] <span class="ot">&lt;-</span>  n<span class="sc">*</span>j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span></span>
<span id="cb11-227"><a href="#cb11-227" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cpt</span>(psi[,,l<span class="sc">+</span><span class="dv">1</span>],id,xidep))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">3</span></span>
<span id="cb11-228"><a href="#cb11-228" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">1</span>,<span class="dv">4</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(psi[,<span class="dv">1</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>kapop</span>
<span id="cb11-229"><a href="#cb11-229" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">2</span>,<span class="dv">5</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(psi[,<span class="dv">2</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(vpop))<span class="sc">/</span>omega2v<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>vpop</span>
<span id="cb11-230"><a href="#cb11-230" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">3</span>,<span class="dv">6</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(psi[,<span class="dv">3</span>,l<span class="sc">+</span><span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>clpop</span>
<span id="cb11-231"><a href="#cb11-231" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">4</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span> tempderiveeas2[<span class="dv">1</span>,<span class="dv">4</span>]</span>
<span id="cb11-232"><a href="#cb11-232" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">5</span>,<span class="dv">2</span>] <span class="ot">&lt;-</span> tempderiveeas2[<span class="dv">2</span>,<span class="dv">5</span>]</span>
<span id="cb11-233"><a href="#cb11-233" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">6</span>,<span class="dv">3</span>] <span class="ot">&lt;-</span> tempderiveeas2[<span class="dv">3</span>,<span class="dv">6</span>]</span>
<span id="cb11-234"><a href="#cb11-234" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-235"><a href="#cb11-235" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-236"><a href="#cb11-236" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb11-237"><a href="#cb11-237" aria-hidden="true" tabindex="-1"></a>      H[,,i,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span>H[,,i,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span></span>
<span id="cb11-238"><a href="#cb11-238" aria-hidden="true" tabindex="-1"></a>        gamma[l]<span class="sc">*</span>(tempderiveeas[,i]<span class="sc">%*%</span><span class="fu">t</span>(tempderiveeas[,i]))</span>
<span id="cb11-239"><a href="#cb11-239" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb11-240"><a href="#cb11-240" aria-hidden="true" tabindex="-1"></a>    G2[,,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> G2[,,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span>gamma[l]<span class="sc">*</span>(tempderiveeas2<span class="sc">/</span>n)</span>
<span id="cb11-241"><a href="#cb11-241" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-242"><a href="#cb11-242" aria-hidden="true" tabindex="-1"></a>  <span class="do">## End of the em loop</span></span>
<span id="cb11-243"><a href="#cb11-243" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-244"><a href="#cb11-244" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Computation of the FIM estimations</span></span>
<span id="cb11-245"><a href="#cb11-245" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-246"><a href="#cb11-246" aria-hidden="true" tabindex="-1"></a>  isco <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,p,nbiterem)) </span>
<span id="cb11-247"><a href="#cb11-247" aria-hidden="true" tabindex="-1"></a>  iobs <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,p,nbiterem)) </span>
<span id="cb11-248"><a href="#cb11-248" aria-hidden="true" tabindex="-1"></a>  SH   <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">"list"</span>,nbiterem)</span>
<span id="cb11-249"><a href="#cb11-249" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-250"><a href="#cb11-250" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-251"><a href="#cb11-251" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbiterem){</span>
<span id="cb11-252"><a href="#cb11-252" aria-hidden="true" tabindex="-1"></a>    isco[,,t] <span class="ot">&lt;-</span> deltaindi[,,t]<span class="sc">%*%</span><span class="fu">t</span>(deltaindi[,,t])<span class="sc">/</span>n</span>
<span id="cb11-253"><a href="#cb11-253" aria-hidden="true" tabindex="-1"></a>    SH[[t]]<span class="ot">&lt;-</span><span class="fu">matrix</span>(<span class="dv">0</span>,p,p)</span>
<span id="cb11-254"><a href="#cb11-254" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb11-255"><a href="#cb11-255" aria-hidden="true" tabindex="-1"></a>      SH[[t]]<span class="ot">&lt;-</span>SH[[t]]<span class="sc">+</span>H[,,i,t]</span>
<span id="cb11-256"><a href="#cb11-256" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb11-257"><a href="#cb11-257" aria-hidden="true" tabindex="-1"></a>    iobs[,,t] <span class="ot">&lt;-</span> <span class="sc">-</span>G2[,,t] <span class="sc">-</span> SH[[t]]<span class="sc">/</span>n <span class="sc">+</span> isco[,,t]</span>
<span id="cb11-258"><a href="#cb11-258" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-259"><a href="#cb11-259" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-260"><a href="#cb11-260" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">thetaest =</span> thetaest, <span class="at">isco =</span> isco, <span class="at">iobs =</span> iobs)</span>
<span id="cb11-261"><a href="#cb11-261" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-262"><a href="#cb11-262" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(res)</span>
<span id="cb11-263"><a href="#cb11-263" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb11-264"><a href="#cb11-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-265"><a href="#cb11-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-266"><a href="#cb11-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-267"><a href="#cb11-267" aria-hidden="true" tabindex="-1"></a>compact <span class="ot">&lt;-</span> <span class="cf">function</span>(s,kappa){</span>
<span id="cb11-268"><a href="#cb11-268" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-269"><a href="#cb11-269" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">prod</span>((s[<span class="dv">1</span>,]<span class="sc">&lt;=</span>(<span class="dv">20</span><span class="sc">+</span>kappa))<span class="sc">*</span>(s[<span class="dv">1</span>,]<span class="sc">&gt;=</span>(<span class="sc">-</span><span class="dv">20</span><span class="sc">-</span>kappa))<span class="sc">*</span></span>
<span id="cb11-270"><a href="#cb11-270" aria-hidden="true" tabindex="-1"></a>                (s[<span class="dv">2</span>,]<span class="sc">&lt;=</span>(<span class="dv">20</span><span class="sc">+</span>kappa))<span class="sc">*</span>(s[<span class="dv">2</span>,]<span class="sc">&gt;=</span>(<span class="sc">-</span><span class="dv">20</span><span class="sc">-</span>kappa))<span class="sc">*</span></span>
<span id="cb11-271"><a href="#cb11-271" aria-hidden="true" tabindex="-1"></a>                (s[<span class="dv">3</span>,]<span class="sc">&lt;=</span>(<span class="dv">20</span><span class="sc">+</span>kappa))<span class="sc">*</span>(s[<span class="dv">3</span>,]<span class="sc">&gt;=</span>(<span class="sc">-</span><span class="dv">20</span><span class="sc">-</span>kappa))<span class="sc">*</span></span>
<span id="cb11-272"><a href="#cb11-272" aria-hidden="true" tabindex="-1"></a>                (s[<span class="dv">4</span>,]<span class="sc">&lt;=</span>(<span class="dv">20</span><span class="sc">+</span>kappa))<span class="sc">*</span></span>
<span id="cb11-273"><a href="#cb11-273" aria-hidden="true" tabindex="-1"></a>                (s[<span class="dv">5</span>,]<span class="sc">&lt;=</span>(<span class="dv">20</span><span class="sc">+</span>kappa))<span class="sc">*</span></span>
<span id="cb11-274"><a href="#cb11-274" aria-hidden="true" tabindex="-1"></a>                (s[<span class="dv">6</span>,]<span class="sc">&lt;=</span>(<span class="dv">20</span><span class="sc">+</span>kappa))<span class="sc">*</span></span>
<span id="cb11-275"><a href="#cb11-275" aria-hidden="true" tabindex="-1"></a>                (s[<span class="dv">7</span>,]<span class="sc">&lt;=</span>(<span class="dv">50000</span>))) </span>
<span id="cb11-276"><a href="#cb11-276" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(res)</span>
<span id="cb11-277"><a href="#cb11-277" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(res)</span>
<span id="cb11-278"><a href="#cb11-278" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="sec-R-saemNLMEnonexp" class="level3" data-number="6.3.5">
<h3 data-number="6.3.5" class="anchored" data-anchor-id="sec-R-saemNLMEnonexp"><span class="header-section-number">6.3.5</span> SAEM algorithm in the PK model not belonging to the curved exponential family</h3>
<div class="cell" data-file="functions/saem_nlme_non_exponential.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="do">## R function implementing the saem algorithm to compute the parameter estimates </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="do">## and the FIM estimates simultaneously in the PK nonlinear mixed-effects model</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="do">## with two random effects, thus not belonging to the curved exponential family</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>saem_non_exp <span class="ot">&lt;-</span> <span class="cf">function</span>(data, nbiterem, nbiterburnin, theta0, <span class="at">kRW=</span><span class="fl">0.5</span>) {</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># data         : dataset </span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># nbiterem     : total number of iterations of the SAEM algorithm</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># nbiterburnin : number of burn-in iterations of the algorithm</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># theta0       : initial parameter values</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># kRW          : coefficient used to adjust the variance of the proposal kernel </span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>  <span class="co">#                of the MCMC procedure</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Q quantity </span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  floglik <span class="ot">&lt;-</span> <span class="cf">function</span>(v,y,psi,xidep,id,alpha){</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    l <span class="ot">&lt;-</span> <span class="fu">length</span>(alpha)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    psi <span class="ot">&lt;-</span> <span class="fu">array</span>(psi,<span class="at">dim=</span><span class="fu">c</span>(n,<span class="dv">2</span>,l))</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    value <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (ll <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>l){</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>      moyij <span class="ot">&lt;-</span> <span class="fu">model1cptV</span>(psi[,,ll],id,xidep,v)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>      value <span class="ot">&lt;-</span> value <span class="sc">+</span> alpha[ll]<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span>moyij)<span class="sc">^</span><span class="dv">2</span>) </span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(value)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># data processing</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>  xidep <span class="ot">&lt;-</span> <span class="fu">cbind</span>(data<span class="sc">$</span>dose,data<span class="sc">$</span>time)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>  y     <span class="ot">&lt;-</span> data<span class="sc">$</span>y</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>  id    <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(data<span class="sc">$</span>subject)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>  n     <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">unique</span>(id))</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>  j     <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">unique</span>(data<span class="sc">$</span>time))</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initial parameter values</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>  vpop     <span class="ot">&lt;-</span> theta0<span class="sc">$</span>vpop</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>  kapop    <span class="ot">&lt;-</span> theta0<span class="sc">$</span>kapop</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>  clpop    <span class="ot">&lt;-</span> theta0<span class="sc">$</span>clpop</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>  omega2ka <span class="ot">&lt;-</span> theta0<span class="sc">$</span>omega2ka</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>  omega2cl <span class="ot">&lt;-</span> theta0<span class="sc">$</span>omega2cl</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>  sigma2   <span class="ot">&lt;-</span> theta0<span class="sc">$</span>sigma2</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">length</span>(theta0) </span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>  thetaest     <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,p,nbiterem)</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>  thetaest[,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">c</span>(kapop, vpop, clpop, omega2ka, omega2cl, sigma2)</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>  <span class="co"># variances of the proposal kernels of the MCMC procedure</span></span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>  eta2ka  <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2ka</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>  eta2cl  <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2cl</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>  <span class="co"># sequence of step sizes </span></span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>  gamma <span class="ot">&lt;-</span>  <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">:</span>(nbiterem))<span class="sc">^</span><span class="fl">0.501</span></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>  cumgamma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,nbiterem,nbiterem) </span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">diag</span>(cumgamma) <span class="ot">&lt;-</span> gamma</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (l <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>nbiterem){</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (m <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(l<span class="dv">-1</span>)){</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>      cumgamma[l,m] <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">*</span>cumgamma[l<span class="dv">-1</span>,m]  </span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>    }  </span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a>  <span class="co"># intermediary R objects</span></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>  deltaindi     <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,n,nbiterem))</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a>  tempderiveeas <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,p,n)</span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>  dimstatexh    <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a>  statexh       <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,dimstatexh,nbiterem)</span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>  mco           <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>,<span class="fu">c</span>(n,j))</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a>  mco2          <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(nbiterem,n,j))</span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>  mco3          <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="cn">NA</span>,<span class="at">dim=</span><span class="fu">c</span>(nbiterem,n,j))</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>  mcos          <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,n)</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>  mcos2         <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>,nbiterem,n)</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a>  STATEXH       <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>,dimstatexh)</span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a>  psisauv       <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(n,<span class="dv">2</span>,nbiterem))</span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a>  H              <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,p,n,nbiterem))</span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a>  G2             <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,p,nbiterem))</span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a>  tempderiveeas2 <span class="ot">&lt;-</span><span class="fu">matrix</span>(<span class="dv">0</span>,p,p)</span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a>  <span class="co"># initial values for the individual parameters</span></span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a>  currentka  <span class="ot">&lt;-</span> <span class="fu">log</span>(kapop) <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2ka))</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a>  currentcl  <span class="ot">&lt;-</span> <span class="fu">log</span>(clpop) <span class="sc">+</span> <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2cl))</span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a>  currentpsi <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">exp</span>(currentka),<span class="fu">exp</span>(currentcl))</span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Start of the EM loop</span></span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (l <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(nbiterem<span class="dv">-1</span>)){</span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Simulation step </span></span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(n)){</span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Parameter ka</span></span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a>      candidatka    <span class="ot">&lt;-</span> currentka</span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a>      candidatka[k] <span class="ot">&lt;-</span> candidatka[k] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2ka))</span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a>      psicandidat   <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">exp</span>(candidatka),<span class="fu">exp</span>(currentcl))</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a>      logs          <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cptV</span>(psicandidat,id,xidep,vpop))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span></span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cptV</span>(currentpsi,id,xidep,vpop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a>      logs          <span class="ot">&lt;-</span> logs<span class="sc">-</span></span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka<span class="sc">*</span>((candidatka[k]<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>(currentka[k]<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a>      u             <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb12-104"><a href="#cb12-104" aria-hidden="true" tabindex="-1"></a>      logu          <span class="ot">&lt;-</span> <span class="fu">log</span>(u)</span>
<span id="cb12-105"><a href="#cb12-105" aria-hidden="true" tabindex="-1"></a>      ind           <span class="ot">&lt;-</span> (logu<span class="sc">&lt;</span>logs)</span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a>      currentpsi    <span class="ot">&lt;-</span> psicandidat<span class="sc">*</span>ind <span class="sc">+</span> currentpsi<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a>      currentka     <span class="ot">&lt;-</span> candidatka<span class="sc">*</span>ind <span class="sc">+</span> currentka<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb12-108"><a href="#cb12-108" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb12-109"><a href="#cb12-109" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Parameter cl</span></span>
<span id="cb12-110"><a href="#cb12-110" aria-hidden="true" tabindex="-1"></a>      candidatcl    <span class="ot">&lt;-</span> currentcl</span>
<span id="cb12-111"><a href="#cb12-111" aria-hidden="true" tabindex="-1"></a>      candidatcl[k] <span class="ot">&lt;-</span> candidatcl[k] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="fu">sqrt</span>(eta2cl))</span>
<span id="cb12-112"><a href="#cb12-112" aria-hidden="true" tabindex="-1"></a>      psicandidat   <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">exp</span>(currentka),<span class="fu">exp</span>(candidatcl))</span>
<span id="cb12-113"><a href="#cb12-113" aria-hidden="true" tabindex="-1"></a>      logs          <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cptV</span>(psicandidat,id,xidep,vpop))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">+</span></span>
<span id="cb12-114"><a href="#cb12-114" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">*</span><span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cptV</span>(currentpsi,id,xidep,vpop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-115"><a href="#cb12-115" aria-hidden="true" tabindex="-1"></a>      logs          <span class="ot">&lt;-</span> logs <span class="sc">-</span></span>
<span id="cb12-116"><a href="#cb12-116" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl<span class="sc">*</span>((candidatcl[k]<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span>(currentcl[k]<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-117"><a href="#cb12-117" aria-hidden="true" tabindex="-1"></a>      u             <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb12-118"><a href="#cb12-118" aria-hidden="true" tabindex="-1"></a>      logu          <span class="ot">&lt;-</span> <span class="fu">log</span>(u)</span>
<span id="cb12-119"><a href="#cb12-119" aria-hidden="true" tabindex="-1"></a>      ind           <span class="ot">&lt;-</span> (logu<span class="sc">&lt;</span>logs)</span>
<span id="cb12-120"><a href="#cb12-120" aria-hidden="true" tabindex="-1"></a>      currentpsi    <span class="ot">&lt;-</span> psicandidat<span class="sc">*</span>ind <span class="sc">+</span> currentpsi<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb12-121"><a href="#cb12-121" aria-hidden="true" tabindex="-1"></a>      currentcl     <span class="ot">&lt;-</span> candidatcl<span class="sc">*</span>ind <span class="sc">+</span> currentcl<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>ind)</span>
<span id="cb12-122"><a href="#cb12-122" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb12-123"><a href="#cb12-123" aria-hidden="true" tabindex="-1"></a>      <span class="co"># saving simulated data </span></span>
<span id="cb12-124"><a href="#cb12-124" aria-hidden="true" tabindex="-1"></a>      psisauv[,,l]  <span class="ot">&lt;-</span> currentpsi</span>
<span id="cb12-125"><a href="#cb12-125" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-126"><a href="#cb12-126" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-127"><a href="#cb12-127" aria-hidden="true" tabindex="-1"></a>    psi <span class="ot">&lt;-</span> psisauv[,,l]</span>
<span id="cb12-128"><a href="#cb12-128" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-129"><a href="#cb12-129" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Parameter estimation update</span></span>
<span id="cb12-130"><a href="#cb12-130" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-131"><a href="#cb12-131" aria-hidden="true" tabindex="-1"></a>    <span class="co"># estimation of the fixed effect by numerical optimization</span></span>
<span id="cb12-132"><a href="#cb12-132" aria-hidden="true" tabindex="-1"></a>    resvpop <span class="ot">&lt;-</span> <span class="fu">optimize</span>(<span class="at">interval=</span><span class="fu">c</span>(<span class="fl">0.001</span>,<span class="dv">50</span>),<span class="at">f=</span>floglik,<span class="at">y=</span>y,<span class="at">psi=</span>psisauv[,,<span class="dv">1</span><span class="sc">:</span>l],</span>
<span id="cb12-133"><a href="#cb12-133" aria-hidden="true" tabindex="-1"></a>                        <span class="at">xidep=</span>xidep,<span class="at">id=</span>id,<span class="at">alpha=</span>cumgamma[l,<span class="dv">1</span><span class="sc">:</span>l])</span>
<span id="cb12-134"><a href="#cb12-134" aria-hidden="true" tabindex="-1"></a>    vpop    <span class="ot">&lt;-</span> resvpop<span class="sc">$</span>minimum</span>
<span id="cb12-135"><a href="#cb12-135" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-136"><a href="#cb12-136" aria-hidden="true" tabindex="-1"></a>    <span class="co"># stochastic approximation of exhaustive statistics and estimation of the </span></span>
<span id="cb12-137"><a href="#cb12-137" aria-hidden="true" tabindex="-1"></a>    <span class="co"># other parameters</span></span>
<span id="cb12-138"><a href="#cb12-138" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-139"><a href="#cb12-139" aria-hidden="true" tabindex="-1"></a>    mco           <span class="ot">&lt;-</span> <span class="fu">matrix</span>((y<span class="sc">-</span><span class="fu">model1cptV</span>(psi,id,xidep,vpop))<span class="sc">^</span><span class="dv">2</span>,n,j,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb12-140"><a href="#cb12-140" aria-hidden="true" tabindex="-1"></a>    mcos          <span class="ot">&lt;-</span> <span class="fu">apply</span>(mco,<span class="dv">1</span>,sum)    </span>
<span id="cb12-141"><a href="#cb12-141" aria-hidden="true" tabindex="-1"></a>    STATEXH       <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">apply</span>(<span class="fu">log</span>(psi),<span class="dv">2</span>,mean), <span class="fu">apply</span>(<span class="fu">log</span>(psi)<span class="sc">^</span><span class="dv">2</span>,<span class="dv">2</span>,mean), <span class="fu">sum</span>(mcos))</span>
<span id="cb12-142"><a href="#cb12-142" aria-hidden="true" tabindex="-1"></a>    statexh[,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> statexh[,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span>gamma[l]<span class="sc">*</span>STATEXH</span>
<span id="cb12-143"><a href="#cb12-143" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-144"><a href="#cb12-144" aria-hidden="true" tabindex="-1"></a>    kapop           <span class="ot">&lt;-</span> <span class="fu">exp</span>(statexh[<span class="dv">1</span>,l<span class="sc">+</span><span class="dv">1</span>])</span>
<span id="cb12-145"><a href="#cb12-145" aria-hidden="true" tabindex="-1"></a>    clpop           <span class="ot">&lt;-</span> <span class="fu">exp</span>(statexh[<span class="dv">2</span>,l<span class="sc">+</span><span class="dv">1</span>])</span>
<span id="cb12-146"><a href="#cb12-146" aria-hidden="true" tabindex="-1"></a>    omega2ka        <span class="ot">&lt;-</span> statexh[<span class="dv">3</span>,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span>statexh[<span class="dv">1</span>,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb12-147"><a href="#cb12-147" aria-hidden="true" tabindex="-1"></a>    omega2cl        <span class="ot">&lt;-</span> statexh[<span class="dv">4</span>,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">-</span>statexh[<span class="dv">2</span>,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb12-148"><a href="#cb12-148" aria-hidden="true" tabindex="-1"></a>    sigma2          <span class="ot">&lt;-</span> statexh[<span class="dv">5</span>,l<span class="sc">+</span><span class="dv">1</span>]<span class="sc">/</span>n<span class="sc">/</span>j</span>
<span id="cb12-149"><a href="#cb12-149" aria-hidden="true" tabindex="-1"></a>    thetaest[,l<span class="sc">+</span><span class="dv">1</span>]  <span class="ot">&lt;-</span> <span class="fu">c</span>(kapop, vpop, clpop, omega2ka, omega2cl, sigma2)</span>
<span id="cb12-150"><a href="#cb12-150" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-151"><a href="#cb12-151" aria-hidden="true" tabindex="-1"></a>    eta2cl <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2cl</span>
<span id="cb12-152"><a href="#cb12-152" aria-hidden="true" tabindex="-1"></a>    eta2ka <span class="ot">&lt;-</span> kRW<span class="sc">*</span>omega2ka</span>
<span id="cb12-153"><a href="#cb12-153" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-154"><a href="#cb12-154" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-155"><a href="#cb12-155" aria-hidden="true" tabindex="-1"></a>    <span class="do">## Stochastic approximation of the derivatives of the complete log-likelihood</span></span>
<span id="cb12-156"><a href="#cb12-156" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-157"><a href="#cb12-157" aria-hidden="true" tabindex="-1"></a>    mco2[l,,]    <span class="ot">&lt;-</span> </span>
<span id="cb12-158"><a href="#cb12-158" aria-hidden="true" tabindex="-1"></a>      <span class="fu">matrix</span>(<span class="fu">dVmodel1cpt</span>(psi,id,xidep,vpop)<span class="sc">*</span>(y<span class="sc">-</span><span class="fu">model1cptV</span>(psi,id,xidep,vpop))<span class="sc">/</span>sigma2,</span>
<span id="cb12-159"><a href="#cb12-159" aria-hidden="true" tabindex="-1"></a>             n,j,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb12-160"><a href="#cb12-160" aria-hidden="true" tabindex="-1"></a>    mcos2[l,]    <span class="ot">&lt;-</span> <span class="fu">apply</span>(mco2[l,,],<span class="dv">1</span>,sum)</span>
<span id="cb12-161"><a href="#cb12-161" aria-hidden="true" tabindex="-1"></a>    mco3[l,,]    <span class="ot">&lt;-</span> </span>
<span id="cb12-162"><a href="#cb12-162" aria-hidden="true" tabindex="-1"></a>      <span class="fu">matrix</span>((<span class="fu">d2Vmodel1cpt</span>(psi,id,xidep,vpop)<span class="sc">*</span>(y<span class="sc">-</span><span class="fu">model1cptV</span>(psi,id,xidep,vpop))<span class="sc">-</span></span>
<span id="cb12-163"><a href="#cb12-163" aria-hidden="true" tabindex="-1"></a>                <span class="fu">dVmodel1cpt</span>(psi,id,xidep,vpop)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>sigma2,n,j,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb12-164"><a href="#cb12-164" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-165"><a href="#cb12-165" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">1</span>,] <span class="ot">&lt;-</span> (<span class="fu">log</span>(psi[,<span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">/</span>omega2ka<span class="sc">/</span>kapop</span>
<span id="cb12-166"><a href="#cb12-166" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">3</span>,] <span class="ot">&lt;-</span> (<span class="fu">log</span>(psi[,<span class="dv">2</span>])<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">/</span>omega2cl<span class="sc">/</span>clpop</span>
<span id="cb12-167"><a href="#cb12-167" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">4</span>,] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka <span class="sc">+</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(<span class="fu">log</span>(psi[,<span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb12-168"><a href="#cb12-168" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">5</span>,] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl <span class="sc">+</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>(<span class="fu">log</span>(psi[,<span class="dv">2</span>])<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb12-169"><a href="#cb12-169" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">6</span>,] <span class="ot">&lt;-</span> <span class="sc">-</span>j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">+</span><span class="fu">apply</span>(mco,<span class="dv">1</span>,sum)<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb12-170"><a href="#cb12-170" aria-hidden="true" tabindex="-1"></a>    tempderiveeas[<span class="dv">2</span>,] <span class="ot">&lt;-</span> mcos2[l,]</span>
<span id="cb12-171"><a href="#cb12-171" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-172"><a href="#cb12-172" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-173"><a href="#cb12-173" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">1</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span>  <span class="fu">sum</span>(<span class="sc">-</span><span class="fu">log</span>(psi[,<span class="dv">1</span>])<span class="sc">+</span><span class="fu">log</span>(kapop)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>omega2ka<span class="sc">/</span>kapop<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb12-174"><a href="#cb12-174" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">2</span>,<span class="dv">2</span>] <span class="ot">&lt;-</span>  <span class="fu">sum</span>(mco3[l,,])</span>
<span id="cb12-175"><a href="#cb12-175" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">3</span>,<span class="dv">3</span>] <span class="ot">&lt;-</span>  <span class="fu">sum</span>(<span class="sc">-</span><span class="fu">log</span>(psi[,<span class="dv">2</span>])<span class="sc">+</span><span class="fu">log</span>(clpop)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>omega2cl<span class="sc">/</span>clpop<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb12-176"><a href="#cb12-176" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">4</span>,<span class="dv">4</span>] <span class="ot">&lt;-</span>  n<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span></span>
<span id="cb12-177"><a href="#cb12-177" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span><span class="fu">sum</span>((<span class="fu">log</span>(psi[,<span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-178"><a href="#cb12-178" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">5</span>,<span class="dv">5</span>] <span class="ot">&lt;-</span>  n<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span></span>
<span id="cb12-179"><a href="#cb12-179" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span><span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span><span class="fu">sum</span>((<span class="fu">log</span>(psi[,<span class="dv">2</span>])<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-180"><a href="#cb12-180" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">6</span>,<span class="dv">6</span>] <span class="ot">&lt;-</span>  n<span class="sc">*</span>j<span class="sc">/</span><span class="dv">2</span><span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">2</span><span class="sc">-</span></span>
<span id="cb12-181"><a href="#cb12-181" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>((y<span class="sc">-</span><span class="fu">model1cptV</span>(psi,id,xidep,vpop))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>sigma2<span class="sc">^</span><span class="dv">3</span></span>
<span id="cb12-182"><a href="#cb12-182" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">1</span>,<span class="dv">4</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(psi[,<span class="dv">1</span>])<span class="sc">-</span><span class="fu">log</span>(kapop))<span class="sc">/</span>omega2ka<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>kapop</span>
<span id="cb12-183"><a href="#cb12-183" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">3</span>,<span class="dv">5</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(psi[,<span class="dv">2</span>])<span class="sc">-</span><span class="fu">log</span>(clpop))<span class="sc">/</span>omega2cl<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>clpop</span>
<span id="cb12-184"><a href="#cb12-184" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">2</span>,<span class="dv">6</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">sum</span>(mcos2[l,])<span class="sc">/</span>(<span class="dv">2</span><span class="sc">*</span>sigma2)</span>
<span id="cb12-185"><a href="#cb12-185" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">4</span>,<span class="dv">1</span>] <span class="ot">&lt;-</span> tempderiveeas2[<span class="dv">1</span>,<span class="dv">4</span>]</span>
<span id="cb12-186"><a href="#cb12-186" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">5</span>,<span class="dv">3</span>] <span class="ot">&lt;-</span> tempderiveeas2[<span class="dv">3</span>,<span class="dv">5</span>]</span>
<span id="cb12-187"><a href="#cb12-187" aria-hidden="true" tabindex="-1"></a>    tempderiveeas2[<span class="dv">6</span>,<span class="dv">2</span>] <span class="ot">&lt;-</span> tempderiveeas2[<span class="dv">2</span>,<span class="dv">6</span>]</span>
<span id="cb12-188"><a href="#cb12-188" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-189"><a href="#cb12-189" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-190"><a href="#cb12-190" aria-hidden="true" tabindex="-1"></a>    deltaindi[,,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> deltaindi[,,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span>gamma[l]<span class="sc">*</span>tempderiveeas</span>
<span id="cb12-191"><a href="#cb12-191" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb12-192"><a href="#cb12-192" aria-hidden="true" tabindex="-1"></a>      H[,,i,l<span class="sc">+</span><span class="dv">1</span>]<span class="ot">&lt;-</span>H[,,i,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span></span>
<span id="cb12-193"><a href="#cb12-193" aria-hidden="true" tabindex="-1"></a>        gamma[l]<span class="sc">*</span>(tempderiveeas[,i]<span class="sc">%*%</span><span class="fu">t</span>(tempderiveeas[,i]))</span>
<span id="cb12-194"><a href="#cb12-194" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-195"><a href="#cb12-195" aria-hidden="true" tabindex="-1"></a>    G2[,,l<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> G2[,,l]<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>gamma[l])<span class="sc">+</span>gamma[l]<span class="sc">*</span>(tempderiveeas2<span class="sc">/</span>n)</span>
<span id="cb12-196"><a href="#cb12-196" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-197"><a href="#cb12-197" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-198"><a href="#cb12-198" aria-hidden="true" tabindex="-1"></a>  <span class="do">## End of the em loop</span></span>
<span id="cb12-199"><a href="#cb12-199" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-200"><a href="#cb12-200" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Computation of the FIM estimations</span></span>
<span id="cb12-201"><a href="#cb12-201" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-202"><a href="#cb12-202" aria-hidden="true" tabindex="-1"></a>  isco <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,p,nbiterem)) </span>
<span id="cb12-203"><a href="#cb12-203" aria-hidden="true" tabindex="-1"></a>  iobs <span class="ot">&lt;-</span> <span class="fu">array</span>(<span class="dv">0</span>,<span class="fu">c</span>(p,p,nbiterem)) </span>
<span id="cb12-204"><a href="#cb12-204" aria-hidden="true" tabindex="-1"></a>  SH   <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">"list"</span>,nbiterem)</span>
<span id="cb12-205"><a href="#cb12-205" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-206"><a href="#cb12-206" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-207"><a href="#cb12-207" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nbiterem){</span>
<span id="cb12-208"><a href="#cb12-208" aria-hidden="true" tabindex="-1"></a>    isco[,,t] <span class="ot">&lt;-</span> deltaindi[,,t]<span class="sc">%*%</span><span class="fu">t</span>(deltaindi[,,t])<span class="sc">/</span>n</span>
<span id="cb12-209"><a href="#cb12-209" aria-hidden="true" tabindex="-1"></a>    SH[[t]]<span class="ot">&lt;-</span><span class="fu">matrix</span>(<span class="dv">0</span>,p,p)</span>
<span id="cb12-210"><a href="#cb12-210" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb12-211"><a href="#cb12-211" aria-hidden="true" tabindex="-1"></a>      SH[[t]]<span class="ot">&lt;-</span>SH[[t]]<span class="sc">+</span>H[,,i,t]</span>
<span id="cb12-212"><a href="#cb12-212" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-213"><a href="#cb12-213" aria-hidden="true" tabindex="-1"></a>    iobs[,,t] <span class="ot">&lt;-</span> <span class="sc">-</span>G2[,,t] <span class="sc">-</span> SH[[t]]<span class="sc">/</span>n <span class="sc">+</span> isco[,,t]</span>
<span id="cb12-214"><a href="#cb12-214" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb12-215"><a href="#cb12-215" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-216"><a href="#cb12-216" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">isco =</span> isco, <span class="at">iobs=</span>iobs, <span class="at">thetaest =</span> thetaest)</span>
<span id="cb12-217"><a href="#cb12-217" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-218"><a href="#cb12-218" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-219"><a href="#cb12-219" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(res)</span>
<span id="cb12-220"><a href="#cb12-220" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="sec-R-estFIMGaussian" class="level3" data-number="6.3.6">
<h3 data-number="6.3.6" class="anchored" data-anchor-id="sec-R-estFIMGaussian"><span class="header-section-number">6.3.6</span> Fisher information matrix estimation in the Gaussian mixture model</h3>
<div class="cell" data-file="functions/fisher_estimation_gaussian_mixture.R">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Function for computing Isco for Fisher Information matrix estimation </span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="do">## in the mixture of two Gaussian distributions of variances 1</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>fisher_estimation_gaussian_mixture <span class="ot">&lt;-</span> <span class="cf">function</span>(y, m1, m2, prob) {</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># y      : vector of observations</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># m1   : mean of the first Gaussian distribution</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># m2   : mean of the second Gaussian distribution</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># prob : mixture proportion of the second distribution</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  isco <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>,<span class="at">nrow=</span><span class="dv">3</span>,<span class="at">ncol=</span><span class="dv">3</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    denomi <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">-</span>prob)<span class="sc">*</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">*</span>(y[i]<span class="sc">-</span>m1)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> prob<span class="sc">*</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">*</span>(y[i]<span class="sc">-</span>m2)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    espcondi <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="dv">1</span><span class="sc">/</span>denomi <span class="sc">*</span> <span class="fu">c</span>(<span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">*</span>(y[i]<span class="sc">-</span>m2)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">-</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">*</span>(y[i]<span class="sc">-</span>m1)<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>                                       (y[i]<span class="sc">-</span>m1)<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>prob)<span class="sc">*</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">*</span>(y[i]<span class="sc">-</span>m1)<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>                                       (y[i]<span class="sc">-</span>m2)<span class="sc">*</span>prob<span class="sc">*</span><span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span><span class="sc">*</span>(y[i]<span class="sc">-</span>m2)<span class="sc">^</span><span class="dv">2</span>)),</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>                          <span class="at">nrow=</span><span class="dv">3</span>,<span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    isco <span class="ot">&lt;-</span> isco <span class="sc">+</span> espcondi<span class="sc">%*%</span><span class="fu">t</span>(espcondi)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(isco)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<!-- -->

</section>
</section>
</section>
<section id="bibliography" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Allassonniere2010" class="csl-entry" role="listitem">
Allassonnière S., Kuhn E., and Trouvé A. 2010. <span>“Construction of Bayesian Deformable Models via a Stochastic Approximation Algorithm: A Convergence Study.”</span> <em>Bernoulli</em> 16: 641–78. <a href="https://doi.org/10.3150/09-BEJ229">https://doi.org/10.3150/09-BEJ229</a>.
</div>
<div id="ref-Andrieu2005" class="csl-entry" role="listitem">
Andrieu C., Moulines E., and Priouret P. 2005. <span>“Stability of Stochastic Approximation Under Verifiable Conditions.”</span> <em>SIAM Journal on Control and Optimization</em> 44 (1): 283–312. <a href="https://doi.org/10.1137/S0363012902417267">https://doi.org/10.1137/S0363012902417267</a>.
</div>
<div id="ref-baey2019asymptotic" class="csl-entry" role="listitem">
Baey C., Cournède P.-H., and Kuhn E. 2019. <span>“Asymptotic Distribution of Likelihood Ratio Test Statistics for Variance Components in Nonlinear Mixed Effects Models.”</span> <em>Computational Statistics &amp; Data Analysis</em> 135: 107–22. <a href="https://doi.org/10.1016/j.csda.2019.01.014">https://doi.org/10.1016/j.csda.2019.01.014</a>.
</div>
<div id="ref-bickel2015mathematical" class="csl-entry" role="listitem">
Bickel P. J., and Doksum K. A. 2015. <em>Mathematical Statistics: Basic Ideas and Selected Topics, Volumes i-II Package</em>. CRC Press. <a href="https://doi.org/10.1201/9781315369266">https://doi.org/10.1201/9781315369266</a>.
</div>
<div id="ref-billingsley2013convergence" class="csl-entry" role="listitem">
Billingsley P. 2013. <em>Convergence of Probability Measures</em>. John Wiley &amp; Sons. <a href="https://doi.org/10.1002/9780470316962">https://doi.org/10.1002/9780470316962</a>.
</div>
<div id="ref-cappe2005" class="csl-entry" role="listitem">
Cappé O., Moulines E., and Rydén T. 2005. <span>“Inference in Hidden Markov Models.”</span> Springer.
</div>
<div id="ref-charkhi2018asymptotic" class="csl-entry" role="listitem">
Charkhi A., and Claeskens G. 2018. <span>“Asymptotic Post-Selection Inference for the Akaike Information Criterion.”</span> <em>Biometrika</em> 105: 645–64. <a href="https://doi.org/10.1093/biomet/asy018">https://doi.org/10.1093/biomet/asy018</a>.
</div>
<div id="ref-Delyon1999" class="csl-entry" role="listitem">
Delyon B., Lavielle M., and Moulines E. 1999. <span>“Convergence of a Stochastic Approximation Version of the EM Algorithm.”</span> <em>Annals of Statistics</em> 27: 94–128. <a href="https://doi.org/10.1214/aos/1018031103">https://doi.org/10.1214/aos/1018031103</a>.
</div>
<div id="ref-efron1978assessing" class="csl-entry" role="listitem">
Efron B., and Hinkley D. V. 1978. <span>“Assessing the Accuracy of the Maximum Likelihood Estimator: Observed Versus Expected Fisher Information.”</span> <em>Biometrika</em> 65: 457–83. <a href="https://doi.org/10.2307/2335893">https://doi.org/10.2307/2335893</a>.
</div>
<div id="ref-feller1968" class="csl-entry" role="listitem">
Feller W. 1968. <em>An Introduction to Probability Theory and Its Applications</em>. Vol. 1. Wiley. <a href="https://doi.org/10.1017/S0020269X00004679">https://doi.org/10.1017/S0020269X00004679</a>.
</div>
<div id="ref-fisher1925" class="csl-entry" role="listitem">
Fisher R.A. 1925. <em>Statistical Methods for Research Workers</em>. John Wiley &amp; Sons. <a href="https://doi.org/10.1007/978-1-4612-4380-9_6">https://doi.org/10.1007/978-1-4612-4380-9_6</a>.
</div>
<div id="ref-Fort2015" class="csl-entry" role="listitem">
Fort G., Jourdain B., Kuhn E., Lelièvre, T., and Stoltz, G. 2015. <span>“Convergence of the Wang-Landau Algorithm.”</span> <em>Mathematics of Computation</em> 84 (295): 2297–327.
</div>
<div id="ref-Gloaguen2014" class="csl-entry" role="listitem">
Gloaguen P., Mahévas S., Rivot E., Woillez M., Guitton J., Vermard Y., and Etienne M.-P. 2014. <span>“An Autoregressive Model to Describe Fishing Vessel Movement and Activity.”</span> <em>Environmetrics</em> 26: 17–28. <a href="https://doi.org/10.1002/env.2319">https://doi.org/10.1002/env.2319</a>.
</div>
<div id="ref-jarner2000" class="csl-entry" role="listitem">
Jarner S. F., and Hansen E. 2000. <span>“Geometric Ergodicity of Metropolis Algorithms.”</span> <em>Stochastic Processes and Their Applications</em> 85 (2): 341–61. <a href="https://doi.org/10.1016/S0304-4149(99)00082-4">https://doi.org/10.1016/S0304-4149(99)00082-4</a>.
</div>
<div id="ref-Kuhn2004" class="csl-entry" role="listitem">
Kuhn E., and Lavielle M. 2004. <span>“Coupling a Stochastic Approximation Version of EM with an MCMC Procedure.”</span> <em>ESAIM P&amp;S</em> 8: 115–31. <a href="https://doi.org/10.1051/ps:2004007">https://doi.org/10.1051/ps:2004007</a>.
</div>
<div id="ref-kuhn2020" class="csl-entry" role="listitem">
Kuhn E., Matias C., and Rebafka T. 2020. <span>“Properties of the Stochastic Approximation EM Algorithm with Mini-Batch Sampling.”</span> <em>Statistics and Computing</em> 30 (6): 1725–39. <a href="https://doi.org/10.1007/s11222-020-09968-0">https://doi.org/10.1007/s11222-020-09968-0</a>.
</div>
<div id="ref-kunstner2019limitations" class="csl-entry" role="listitem">
Kunstner F., Hennig P., and Balles L. 2019. <span>“Limitations of the Empirical Fisher Approximation for Natural Gradient Descent.”</span> In <em>Advances in Neural Information Processing Systems</em>. Vol. 32.
</div>
<div id="ref-le2021fisher" class="csl-entry" role="listitem">
Le Brigant A., Preston S. C., and Puechmorel S. 2021. <span>“Fisher-Rao Geometry of Dirichlet Distributions.”</span> <em>Differential Geometry and Its Applications</em> 74. <a href="https://doi.org/10.1016/j.difgeo.2020.101702">https://doi.org/10.1016/j.difgeo.2020.101702</a>.
</div>
<div id="ref-lehmann2006theory" class="csl-entry" role="listitem">
Lehmann E. L., and Casella G. 2006. <em>Theory of Point Estimation</em>. Springer Science &amp; Business Media. <a href="https://doi.org/10.1007/b98854">https://doi.org/10.1007/b98854</a>.
</div>
<div id="ref-Louis1982" class="csl-entry" role="listitem">
Louis T. A. 1982. <span>“Finding the Observed Information Matrix When Using the EM Algorithm.”</span> <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 44: 226–33. <a href="https://doi.org/10.1111/j.2517-6161.1982.tb01203.x">https://doi.org/10.1111/j.2517-6161.1982.tb01203.x</a>.
</div>
<div id="ref-McLachlan2008" class="csl-entry" role="listitem">
McLachlan G.-J., and Krishnan T. 2008. <em>The EM Algorithm and Extensions</em>. Wiley Series in Probability and Statistics. Wiley. <a href="https://doi.org/10.1002/9780470191613">https://doi.org/10.1002/9780470191613</a>.
</div>
<div id="ref-Meng2017" class="csl-entry" role="listitem">
Meng L., and Spall J. C. 2017. <span>“Efficient Computation of the Fisher Information Matrix in the EM Algorithm.”</span> In <em>Annual Conference on Information Sciences and Systems (CISS)</em>. <a href="https://doi.org/10.1109/CISS.2017.7926126">https://doi.org/10.1109/CISS.2017.7926126</a>.
</div>
<div id="ref-Meng1991" class="csl-entry" role="listitem">
Meng X.-L., and Rubin D. B. 1991. <span>“Using EM to Obtain Asymptotic Variance-Covariance Matrices: The SEM Algorithm.”</span> <em>Journal of the American Statistical Association</em> 86: 899–909. <a href="https://doi.org/10.1080/01621459.1991.10475130">https://doi.org/10.1080/01621459.1991.10475130</a>.
</div>
<div id="ref-Oakes1999" class="csl-entry" role="listitem">
Oakes D. 1999. <span>“Direct Calculation of the Information Matrix via the EM Algorithm.”</span> <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 61: 479–82. <a href="https://doi.org/10.1111/1467-9868.00188">https://doi.org/10.1111/1467-9868.00188</a>.
</div>
<div id="ref-Woodbury1972" class="csl-entry" role="listitem">
Orchard T., and Woodbury M. A. 1972. <span>“A Missing Information Principle: Theory and Applications.”</span> In <em>Proceedings of the Berkeley Symposium on Mathematical Statistics and Probability</em>.
</div>
<div id="ref-Picard2007" class="csl-entry" role="listitem">
Picard F., Robin S., Lebarbier E., and Daudin J.-J. 2007. <span>“A Segmentation/Clustering Model for the Analysis of Array CGH Data.”</span> <em>Biometrics</em> 63: 758–66. <a href="https://doi.org/10.1111/j.1541-0420.2006.00729.x">https://doi.org/10.1111/j.1541-0420.2006.00729.x</a>.
</div>
<div id="ref-mixfim2018" class="csl-entry" role="listitem">
Riviere-Jourdan M.-K., and Mentre F. 2018. <em>MIXFIM: Evaluation of the FIM in NLMEMs Using MCMC</em>. <a href="https://CRAN.R-project.org/package=MIXFIM">https://CRAN.R-project.org/package=MIXFIM</a>.
</div>
<div id="ref-Scott2002" class="csl-entry" role="listitem">
Scott W.-A. 2002. <span>“Maximum Likelihood Estimation Using the Empirical Fisher Information Matrix.”</span> <em>Journal of Statistical Computation and Simulation</em> 72: 599–611. <a href="https://doi.org/10.1080/00949650213744">https://doi.org/10.1080/00949650213744</a>.
</div>
<div id="ref-Technow2015" class="csl-entry" role="listitem">
Technow F., Messina C. D., Totir L. R., and Cooper M. 2015. <span>“Integrating Crop Growth Models with Whole Genome Prediction Through Approximate Bayesian Computation.”</span> <em>PloS One</em> 10. <a href="https://doi.org/10.1371/journal.pone.0130855">https://doi.org/10.1371/journal.pone.0130855</a>.
</div>
<div id="ref-VanderVaart2000" class="csl-entry" role="listitem">
Van der Vaart A. W. 2000. <em>Asymptotic Statistics</em>. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511802256">https://doi.org/10.1017/CBO9780511802256</a>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{delattre2023,
  author = {Delattre, Maud and Kuhn, Estelle},
  publisher = {Société Française de Statistique},
  title = {Computing an Empirical {Fisher} Information Matrix Estimate
    in Latent Variable Models Through Stochastic Approximation},
  journal = {Computo},
  date = {2023-07-10},
  doi = {xxxx},
  langid = {en},
  abstract = {The Fisher information matrix (FIM) is a key quantity in
    statistics. However its exact computation is often not trivial. In
    particular in many latent variable models, it is intricated due to
    the presence of unobserved variables. Several methods have been
    proposed to approximate the FIM when it can not be evaluated
    analytically. Different estimates have been considered, in
    particular moment estimates. However some of them require to compute
    second derivatives of the complete data log-likelihood which leads
    to some disadvantages. In this paper, we focus on the empirical
    Fisher information matrix defined as an empirical estimate of the
    covariance matrix of the score, which only requires to compute the
    first derivatives of the log-likelihood. Our contribution consists
    in presenting a new numerical method to evaluate this empirical
    Fisher information matrix in latent variable model when the proposed
    estimate can not be directly analytically evaluated. We propose a
    stochastic approximation estimation algorithm to compute this
    estimate as a by-product of the parameter estimate. We evaluate the
    finite sample size properties of the proposed estimate and the
    convergence properties of the estimation algorithm through
    simulation studies.}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-delattre2023" class="csl-entry quarto-appendix-citeas" role="listitem">
Delattre, Maud, and Estelle Kuhn. 2023. <span>“Computing an Empirical
Fisher Information Matrix Estimate in Latent Variable Models Through
Stochastic Approximation.”</span> <em>Computo</em>, July. <a href="https://doi.org/xxxx">https://doi.org/xxxx</a>.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb14" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Computing  an empirical  Fisher information matrix estimate in latent variable models through stochastic approximation"</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Maud Delattre</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">    corresponding: true</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">    email: maud.delattre@inrae.fr</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: </span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Université Paris-Saclay, INRAE, MaIAGE, 78350, Jouy-en-Josas, France</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Estelle Kuhn</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">    email: estelle.kuhn@inrae.fr</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: </span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Université Paris-Saclay, INRAE, MaIAGE, 78350, Jouy-en-Josas, France</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> last-modified</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> &gt;+</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co">  The Fisher information matrix (FIM) is a key quantity in statistics. However its exact computation is often not trivial. In particular in many latent variable models, it is intricated due to the presence of unobserved variables. Several methods have been proposed to approximate the  FIM when it can not be evaluated analytically.  Different  estimates have been considered, in particular moment estimates. However some of them require to compute second derivatives of the complete data log-likelihood which leads to some disadvantages. In this paper, we focus on the empirical Fisher information matrix defined as an empirical estimate of the covariance matrix of the score, which only requires to compute the first derivatives of the log-likelihood. Our contribution consists in presenting a new numerical method to evaluate this empirical Fisher information matrix in latent variable model when the proposed estimate can not be directly analytically evaluated. We propose a stochastic approximation estimation algorithm to compute this estimate as a by-product of the parameter estimate. We evaluate the finite sample size properties of the proposed estimate and the convergence properties of the estimation algorithm through simulation studies. </span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co"> [Model-based standard error, moment estimate, Fisher identity, stochastic approximation algorithm]</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co">  type: article-journal</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co">  container-title: "Computo"</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="co">  doi: "xxxx"</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co">  publisher: "Société Française de Statistique"</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="an">github:</span><span class="co"> https://github.com/madelattre/FIM</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="an">github-user:</span><span class="co"> computorg</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="an">repo:</span><span class="co"> "template-computo-r" </span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="co">  message: false</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="co">  keep-md: false</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> true # set to false once the build is running</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="an">published:</span><span class="co"> false # will be set to true once accepted</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-html: default</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: loadlibrary</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(flextable)</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cowplot)</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RColorBrewer)</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(devtools)</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>The Fisher information matrix (FIM) is a key quantity in statistics as it is required for examples  for evaluating asymptotic precisions of parameter estimates, for building  optimality criteria in experimental designs, for computing Wald test statistics  or classical asymptotic distributions in statistical testing <span class="co">[</span><span class="ot">@VanderVaart2000</span><span class="co">]</span>. It also appears more recently in post model selection inference <span class="co">[</span><span class="ot">@charkhi2018asymptotic</span><span class="co">]</span>, in asymptotic distribution of the likelihood ratio test statistics when testing variance component in mixed models <span class="co">[</span><span class="ot">@baey2019asymptotic</span><span class="co">]</span> or  as a particular Riemannian metric on complex manifold <span class="co">[</span><span class="ot">@le2021fisher</span><span class="co">]</span>. However its exact computation is often not trivial. This is in particular the case in many latent variables models,  also called incomplete data models, due to the presence of the unobserved variables. Though these models are increasingly used in many fields of application, such as in ecophysiology <span class="co">[</span><span class="ot">@Technow2015</span><span class="co">]</span>, in genomic <span class="co">[</span><span class="ot">@Picard2007</span><span class="co">]</span> or in ecology <span class="co">[</span><span class="ot">@Gloaguen2014</span><span class="co">]</span>. They especially allow a better consideration of the different variability sources and when appropriate, a more precise characterization of the known mechanisms at the origin of the data. When the FIM can not be exactly computed, people either approximate it numerically, for example by using Monte Carlo technics like developed in the R package MIXFIM <span class="co">[</span><span class="ot">@mixfim2018</span><span class="co">]</span> or focus on an estimate of the FIM. The probably most widely used  is the observed FIM <span class="co">[</span><span class="ot">@efron1978assessing</span><span class="co">]</span>.  When  it can not be directly computed in latent variable models, several methods have  been proposed to approximate it. Among the most frequently used approaches are Monte-Carlo methods or iterative algorithms derived from the missing information principle <span class="co">[</span><span class="ot">@Woodbury1972</span><span class="co">]</span>. Indeed according to this principle, the observed Fisher information matrix can be expressed as the difference between two matrices corresponding to the complete information and the missing information due to the unobserved variables (see *e.g.* <span class="co">[</span><span class="ot">@McLachlan2008</span><span class="co">]</span> chapter 4). It enables the development of alternative methods to compute the observed FIM: the Louis's method <span class="co">[</span><span class="ot">@Louis1982</span><span class="co">]</span>, combined with a Monte Carlo method or a stochastic approximation algorithm by <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>, the Oakes method <span class="co">[</span><span class="ot">@Oakes1999</span><span class="co">]</span> or the supplemented Expectation Maximization algorithm <span class="co">[</span><span class="ot">@Meng1991</span><span class="co">]</span>.  However as the observed FIM involves the second derivatives of the observed log-likelihood, all these methods require to compute second derivatives of the complete data log-likelihood which leads to some disadvantages from a computational point of view. More recently, <span class="co">[</span><span class="ot">@Meng2017</span><span class="co">]</span> proposed an accelerated algorithm based on numerical first order derivatives of the conditional expectation of the log-likelihood. Another estimate is the empirical Fisher information matrix. This estimator of the FIM is defined as the moment estimate of the covariance matrix of the score. It is  much less used  than the observed Fisher information matrix. However it has a nice property since it is positive definite, which is not systematically the case for the latter and  it is numerically more interesting because it  only requires the calculation of the first derivatives of the log-likelihood.</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>In this paper, our contribution consists in presenting a new numerical method to evaluate the empirical FIM in latent variables model. </span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>Indeed, when the proposed estimate can not be directly analytically evaluated, we propose a stochastic approximation estimation algorithm to compute  it, which  provides this estimate of the FIM as a by-product of model parameter estimates. </span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>The paper is organized as follows. In Section 2, we recall the three main FIM estimates  and discuss their immediate properties. In Section 3, we give practical tools for the computation of the empirical  Fisher information matrix in incomplete data models. In particular, we introduce a new stochastic approximation procedure based on the first derivatives of the complete log-likelihood only and state its asymptotic properties. In Section 4, we illustrate the finite sample size properties of both estimators and the convergence properties of the computation algorithm through simulations. The paper ends by a discussion.</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a><span class="fu"># Moment estimates of the Fisher information matrix</span></span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>Let us consider a random vector $Y$ taking value in $\mathcal{Y}$.  Assume $Y$ admits a density $g(\cdot;\theta)$ with respect to a given common measure $\mu$, depending on some parameter $\theta$ taking values in an open subset $\Theta$ of $\mathbb{R}^{d}$, such that the log-likelihood function $\log g$ is differentiable on $\Theta$ and $\|\partial_\theta  \log g(y;\theta) (\partial_\theta  \log g(y;\theta))^t\|$ is integrable with respect to $g$, where $x^t$ stands for the transpose of a vector or a matrix $x$. Then, by definition (see <span class="co">[</span><span class="ot">@lehmann2006theory</span><span class="co">]</span>), the Fisher information matrix is given for all $\theta\in\Theta$ by:</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>I(\theta) =  E_\theta\left<span class="co">[</span><span class="ot">\partial_\theta \log g(Y;\theta) (\partial_\theta \log g(Y;\theta))^t \right</span><span class="co">]</span>.</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a>$$ {#eq-fisher_der1}</span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>When this expression can not be analytically evaluated, people are interested in computing an estimate of the Fisher information matrix.</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a>Considering this expression, one can derive a first moment estimator of the Fisher information matrix based on a $n$-sample $y=(y_1, \ldots, y_{n})$ of independent observations:</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a>I_{n,sco}(\theta,y) = \frac{1}{n} \sum_{i=1}^n I_{sco}(\theta,y_i) = \frac{1}{n} \sum_{i=1}^n \partial_\theta \log g(y_i;\theta) (\partial_\theta \log g(y_i;\theta))^t.</span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a>This estimate is indeed equal to the mean of the Gram matrices of the scores.</span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a>Moreover, we can get another expression for the Fisher information (see <span class="co">[</span><span class="ot">@lehmann2006theory</span><span class="co">]</span>). If we assume that the set $A=<span class="sc">\{</span>y, g(y;\theta)&gt;0<span class="sc">\}</span>$ is independent of $\theta$,  that for $\mu$-almost all $y$, $g(y;\cdot)$ is differentiable on $\Theta$, and that  the derivative with respect to $\theta$ on the left side of </span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>$$\int g(y;\theta)d\mu(y)=1$$ {#eq-density}</span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>can be obtained by differentiating under the integral sign, then </span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>the Fisher information matrix is given for all $\theta\in\Theta$ by:</span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a>I(\theta) =  V_\theta\left<span class="co">[</span><span class="ot">\partial_\theta \log g(Y;\theta) \right</span><span class="co">]</span>.</span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a>$$ {#eq-fisher_der2}</span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a>One can also derive a second estimate from this expression defined as</span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a>I_{n,cov}(\theta,y) = \frac{1}{n} \sum_{i=1}^n \partial_\theta \log g(y_i;\theta) (\partial_\theta \log g(y_i;\theta))^t-\bar{s}(\theta,y)\bar{s}(\theta,y)^t,</span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a>where $\bar{s}(\theta,y)=\frac{1}{n}\sum_{i=1}^n \partial_\theta \log g(y_i;\theta)$ (see *e.g.* [@Scott2002]). We emphasize here that the terminology "empirical Fisher information matrix" is used  in the literature for both estimates (see *e.g.* <span class="co">[</span><span class="ot">@kunstner2019limitations</span><span class="co">]</span>). </span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a>Moreover if additionally the second derivative with respect to $\theta$ of $\log g(y;\theta)$ exists for all $y$ and $\theta$ and the second derivative with respect to $\theta$ of the left side of @eq-density can be obtained by differentiating twice under the integral sign (see <span class="co">[</span><span class="ot">@lehmann2006theory</span><span class="co">]</span>), we have</span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a>I(\theta) =  - E_\theta\left<span class="co">[</span><span class="ot">\partial_\theta^2 \log g(Y;\theta) \right</span><span class="co">]</span>.</span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a>$$ {#eq-fisher_der2}</span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a>Considering this third expression, we can derive another moment estimator of  the Fisher information matrix based on a $n$-sample $(y_1, \ldots, y_{n})$ of observations, called the observed Fisher information matrix defined as:</span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a>I_{n,obs}(\theta,y) = \frac{1}{n}\sum_{i=1}^n I_{obs}(\theta,y_i) = - \frac{1}{n} \sum_{i=1}^n \partial_\theta^2 \log g(y_i;\theta).</span>
<span id="cb14-105"><a href="#cb14-105" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a>Some detailed discussion about the three estimators above can be found in <span class="co">[</span><span class="ot">@Scott2002</span><span class="co">]</span>.</span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a>::: {.remark}</span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a>We emphasize that the estimate $I_{n,sco}(\theta,y)$ is always positive semi-definite, since it is a mean of Gram matrices, contrary to the others estimates $I_{n,obs}(\theta,y)$ and $I_{n,cov}(\theta,y)$. Moreover assuming $n$ sufficiently large allows to prove positive definiteness of $I_{n,sco}(\theta,y)$. Consider  for any nonzero vector $x$ the quantity $x^t I_{n,sco}(\theta,y) x$. We have that $x^t I_{n,sco}(\theta,y) x = ( \sum_{i=1}^n x^t \partial_{\theta} \log g(y_i;\theta) \partial_{\theta} \log g(y_i;\theta)^t x )/n= \sum_{i=1}^n (x^t \partial_{\theta} \log g(y_i;\theta))^2/n$. Thus, $x^t I_{n,sco}(\theta,y) x=0$  implies that $x^t \partial_{\theta} \log g(y_i;\theta)=0$ for all $1 \leq i \leq n$. If $n$ is sufficiently large, there exist $d$ indexes $i_1, ..., i_d$ such that the family of vectors $<span class="sc">\{</span>\partial_{\theta} \log g(y_{i_l};\theta), 1 \leq l \leq d<span class="sc">\}</span>$ is linearly independent.  Thus this implies that $x=0$ leading to the results.</span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-113"><a href="#cb14-113" aria-hidden="true" tabindex="-1"></a>::: {.remark}</span>
<span id="cb14-114"><a href="#cb14-114" aria-hidden="true" tabindex="-1"></a>The asymptotical properties of the estimates $I_{n,sco}(\theta,y)$ and $I_{n,obs}(\theta,y)$ are straighforward when considering independent and identically distributed sample $(y_1, \ldots, y_{n})$. In particular, assuming standard regularity conditions on $g$, it follows directly from the  central limit theorem that $I_{n,sco}(\theta,y)$ and $I_{n,obs}(\theta,y)$ are asymptotically normal. </span>
<span id="cb14-115"><a href="#cb14-115" aria-hidden="true" tabindex="-1"></a>If the variables $Y_1, \ldots, Y_{n}$ are independent not identically distributed, for example if their distributions depend on some individual covariates which is often the case in practice, we can also get asymptotic properties for the estimates assuming more </span>
<span id="cb14-116"><a href="#cb14-116" aria-hidden="true" tabindex="-1"></a>strengthed reguarity conditions by applying for example the Kolmogorov criterion (see *e.g.* <span class="co">[</span><span class="ot">@feller1968</span><span class="co">]</span>) for the consistency and the Lindeberg theorem for the normality result (see  theorem 27.2 of <span class="co">[</span><span class="ot">@billingsley2013convergence</span><span class="co">]</span>). </span>
<span id="cb14-117"><a href="#cb14-117" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-118"><a href="#cb14-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-119"><a href="#cb14-119" aria-hidden="true" tabindex="-1"></a>::: {.remark}</span>
<span id="cb14-120"><a href="#cb14-120" aria-hidden="true" tabindex="-1"></a>Since both estimators  $I_{n,sco}(\theta,y)$ and $I_{n,obs}(\theta,y)$ are moment estimates of $I(\theta)$, they are unbiased for all $\theta \in \Theta$. This is not the case for $I_{n,cov}(\theta,y)$. Regarding the variance, none of both estimators is better than the other one. This can be highlighted through the following examples. First consider a Gaussian sample with unknown expectation and fixed variance. Then, the variance of the estimator $I_{n,obs}(\theta,y)$ is zero whereas the variance of the estimator $I_{n,sco}(\theta,y)$ is positive. Second consider a centered Gaussian sample with unknown variance. Then, the variance of $I_{n,sco}(\theta,y)$ is smaller than the variance of $I_{n,obs}(\theta,y)$. Therefore, none of both estimators is more suitable than the other in general from this point of view. </span>
<span id="cb14-121"><a href="#cb14-121" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-122"><a href="#cb14-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-123"><a href="#cb14-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-124"><a href="#cb14-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-125"><a href="#cb14-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-126"><a href="#cb14-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-127"><a href="#cb14-127" aria-hidden="true" tabindex="-1"></a><span class="fu"># Computing the  estimator $I_{n,sco}(\theta)$ in latent variable model</span></span>
<span id="cb14-128"><a href="#cb14-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-129"><a href="#cb14-129" aria-hidden="true" tabindex="-1"></a>Let us consider independent random variables $Y_1, \ldots, Y_{n}$. Assume in the sequel that there exist independent random variables $Z_1, \ldots, Z_{n}$ taking values in $\mathcal{Z}$ and a measure $\lambda$ on $\mathcal{Z}$ such that for each $1 \leq  i \leq  n$, the random vector  $(Y_i,Z_i)$ admits a   parametric probability density function denoted by $f$ parametrized by $\theta \in \Theta$ with respect to $\mu \times \lambda$ on $\mathcal{Y}\times\mathcal{Z}$.  We present in this section dedicated tools to compute the estimator $I_{n,sco}(\theta)$ in latent variable model when it can not be evaluated analytically.</span>
<span id="cb14-130"><a href="#cb14-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-131"><a href="#cb14-131" aria-hidden="true" tabindex="-1"></a><span class="fu">## Analytical expressions in latent variable models</span></span>
<span id="cb14-132"><a href="#cb14-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-133"><a href="#cb14-133" aria-hidden="true" tabindex="-1"></a>In  latent variable models, the estimator $I_{n,sco}(\theta,y)$ can be expressed using the conditional expectation as  stated in the following proposition.</span>
<span id="cb14-134"><a href="#cb14-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-135"><a href="#cb14-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-136"><a href="#cb14-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-137"><a href="#cb14-137" aria-hidden="true" tabindex="-1"></a>:::{#prp-fisherequality}</span>
<span id="cb14-138"><a href="#cb14-138" aria-hidden="true" tabindex="-1"></a>Assume that for all $y$ and all $\theta \in \Theta$ the function $f(y,.;\theta)$ is integrable with respect to $\lambda$, that for all $y$ and for $\lambda$-almost all $z$ the function $f(y,z;\cdot)$ is   differentiable on $\Theta$, that there exists a mesurable function $m$ such that $\int m(z) \lambda(dz)&lt; \infty$ and for all $\theta \in \Theta$ and for $\lambda$-almost all $z$ $|\partial_\theta f(y,z;\theta)|\leq m(z)$. Then for all $\theta \in \Theta$ and all $n \in \mathbb{N}^*$:</span>
<span id="cb14-139"><a href="#cb14-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-140"><a href="#cb14-140" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-141"><a href="#cb14-141" aria-hidden="true" tabindex="-1"></a>I_{n,sco}(\theta) = \frac{1}{n} \sum_{i=1}^n \mathrm{E}_{Z_i|Y_i;\theta} (\partial_\theta \log f(Y_i,Z_i;\theta) ) \mathrm{E}_{Z_i|Y_i;\theta} (\partial_\theta \log f(Y_i,Z_i;\theta) )^t, </span>
<span id="cb14-142"><a href="#cb14-142" aria-hidden="true" tabindex="-1"></a>$$ {#eq-vnmis}</span>
<span id="cb14-143"><a href="#cb14-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-144"><a href="#cb14-144" aria-hidden="true" tabindex="-1"></a>where $\mathrm{E}_{Z|Y;\theta}$ denotes the expectation under the law of $Z$ conditionally to $Y$.</span>
<span id="cb14-145"><a href="#cb14-145" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-146"><a href="#cb14-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-147"><a href="#cb14-147" aria-hidden="true" tabindex="-1"></a>We apply the classical Fisher identity <span class="co">[</span><span class="ot">@fisher1925</span><span class="co">]</span> to  establish the equality stated in @prp-fisherequality. We refer to Proposition 100 of  <span class="co">[</span><span class="ot">@cappe2005</span><span class="co">]</span> for the statement of the Fisher identity. This statement  is indeed in the same spirit  as the well-known Louis formulae for the observed Fisher information matrix estimate <span class="co">[</span><span class="ot">@Louis1982</span><span class="co">]</span>. The result follows directly.</span>
<span id="cb14-148"><a href="#cb14-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-149"><a href="#cb14-149" aria-hidden="true" tabindex="-1"></a>::: {.remark}</span>
<span id="cb14-150"><a href="#cb14-150" aria-hidden="true" tabindex="-1"></a>In some specific cases  the conditional expectations involved in the previous proposition  admit exact analytical expressions for example  in mixture models which are  developed in @sec-simul in some simulation studies. </span>
<span id="cb14-151"><a href="#cb14-151" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-152"><a href="#cb14-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-153"><a href="#cb14-153" aria-hidden="true" tabindex="-1"></a><span class="fu">## Computing $I_{n,sco}(\theta)$ using stochastic approximation algorithm</span></span>
<span id="cb14-154"><a href="#cb14-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-155"><a href="#cb14-155" aria-hidden="true" tabindex="-1"></a>When exact computation of the estimator $I_{n,sco}(\theta)$ is not possible for all $\theta\in\Theta$, we propose  to evaluate its value by using a new stochastic algorithm which provides the estimate $I_{n,sco}(\bar{\theta}_{ML})$ as a by-product of the maximum likelihood  estimate $\bar{\theta}_{ML}$. More precisely we provide three algorithms: a first one in the curved exponential family context which requires to simulate the latent variable from a transition kernel of an ergodic Markov chain and assumes less strength assumptions to get theoretical convergence result thanks to a truncation on random boundaries step, a second one in the curved exponential family context which does not include this additional projection step but requires more strength assumptions to ensure theoretical convergence. This second one and the related results are presented in Appendix.  Finally we provide a third algorithm dedicated to general  latent variables models without any theoretical results as it is usually the case for such kind of methods (see @sec-generalmodel). </span>
<span id="cb14-156"><a href="#cb14-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-157"><a href="#cb14-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### Description of the algorithm with truncation on random boundaries in curved exponential family model {#sec-algoSAEM}</span></span>
<span id="cb14-158"><a href="#cb14-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-159"><a href="#cb14-159" aria-hidden="true" tabindex="-1"></a>We develop an extension of the stochastic approximation Expectation Maximization algorithm coupled with a Monte Carlo Markov Chain studied by <span class="co">[</span><span class="ot">@Allassonniere2010</span><span class="co">]</span> which allows to compute simultaneously the maximum likelihood estimate and the FIM estimate proposed in the previous section. We assume in this section that all the individual complete log-likelihoods belong to the curved exponential family (see <span class="co">[</span><span class="ot">@bickel2015mathematical</span><span class="co">]</span>) for stating the theoretical results. As our estimate involves individual conditional expectations, we have to consider an extended form of sufficient statistics for the model at the individual level. Indeed, it is necessary to compute stochastic approximation of each individual sufficient statistic at individual level since there are required to be able to compute the proposed FIM estimate. This is the main difference with the usual algorithm. Therefore we  introduce the following notations and assumptions.</span>
<span id="cb14-160"><a href="#cb14-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-161"><a href="#cb14-161" aria-hidden="true" tabindex="-1"></a>The individual complete data likelihood function is given for all $1 \leq  i \leq  n$ by:</span>
<span id="cb14-162"><a href="#cb14-162" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-163"><a href="#cb14-163" aria-hidden="true" tabindex="-1"></a>f_i(z_i;\theta) = \exp\left(-\psi_i(\theta) + \left&lt;S_i(z_i),\phi_i(\theta)\right&gt;\right),</span>
<span id="cb14-164"><a href="#cb14-164" aria-hidden="true" tabindex="-1"></a>$$ {#eq-curvedexpo}</span>
<span id="cb14-165"><a href="#cb14-165" aria-hidden="true" tabindex="-1"></a>where $\left&lt;\cdot,\cdot\right&gt;$ denotes the scalar product, $S_i$ is a function on $\mathbb{R}^{d_i}$  taking its values in a subset $\mathcal{S}_i$ of $\mathbb{R}^{m_i}$. </span>
<span id="cb14-166"><a href="#cb14-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-167"><a href="#cb14-167" aria-hidden="true" tabindex="-1"></a>Let us denote  for all $1 \leq  i \leq  n$ by  $L_i$ the function defined on $\mathcal{S}_i \times \Theta$ by $L_i(s_i; \theta)\triangleq - \psi_i(\theta) + \left&lt;s_i,\phi_i(\theta)\right&gt;$ and by $L: \mathcal{S} \times \Theta \to \mathbb{R}$ the function defined as $L(s,\theta)=\sum_i L_i(s_i; \theta)$ with $\mathcal{S}=\prod_i \mathcal{S}_i$ and $s=(s_1,\ldots,s_n)$.</span>
<span id="cb14-168"><a href="#cb14-168" aria-hidden="true" tabindex="-1"></a>For sake of simplicity, we omitted  all dependency on the observations $(y_i)_{1 \leq  i \leq  n}$  since the considered stochasticity relies here on the latent variables.</span>
<span id="cb14-169"><a href="#cb14-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-170"><a href="#cb14-170" aria-hidden="true" tabindex="-1"></a>Finally let us denote by $(\gamma_k)_{k \geq 1}$ and $(\varepsilon_k)_{k \geq 1}$ sequences of positive step sizes, by $\mathrm{K}$ a compact set of $\mathbb{R}^d$ with $d=\sum d_i$ and by $(\mathcal{K}_k)$ a sequence of increasing compact sets of $\mathcal{S}$ such that $\cup \mathcal{K}_k=\mathcal{S}$ and for all $k$ $\mathcal{K}_{k} \subset int(\mathcal{K}_{k+1} )$.</span>
<span id="cb14-171"><a href="#cb14-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-172"><a href="#cb14-172" aria-hidden="true" tabindex="-1"></a>Moreover we assume that there exists a function $\widehat{\theta} : \ \mathcal{S} \rightarrow \Theta$, such that $\forall s \in \mathcal{S}, \ \  \forall \theta \in \Theta, \ \ L(s; \widehat{\theta}(s))\geq L(s; \theta).$</span>
<span id="cb14-173"><a href="#cb14-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-174"><a href="#cb14-174" aria-hidden="true" tabindex="-1"></a>**Initialization step**: Initialize arbitrarily for all $1 \leq i \leq n$ $s_i^0$ and $\theta_0$. Set $\kappa_0=\zeta_0=\nu_0=0$.</span>
<span id="cb14-175"><a href="#cb14-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-176"><a href="#cb14-176" aria-hidden="true" tabindex="-1"></a>**Repeat until convergence the  three   steps defined at iteration $k$ by**:</span>
<span id="cb14-177"><a href="#cb14-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-178"><a href="#cb14-178" aria-hidden="true" tabindex="-1"></a><span class="ss">  -  </span>**Simulation  step**:  for $1 \leq i \leq n$ simulate a realization  $\bar{Z}_i$ from a parametric transition kernel $\Pi_i$ of a Markov Chain parametrized by the current parameter value $\theta_{k-1}$ and having the conditional distribution given the observations $Y_i$ denoted by $p_i$ as stationary distribution</span>
<span id="cb14-179"><a href="#cb14-179" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-180"><a href="#cb14-180" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Stochastic approximation step**: compute the quantities for all  $1 \leq i \leq n$</span>
<span id="cb14-181"><a href="#cb14-181" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-182"><a href="#cb14-182" aria-hidden="true" tabindex="-1"></a>\bar{s_i} = (1-\gamma_k)s_i^{k-1} +\gamma_k  S_i(Z_i^k) </span>
<span id="cb14-183"><a href="#cb14-183" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-184"><a href="#cb14-184" aria-hidden="true" tabindex="-1"></a>where $(\gamma_k)$ is a sequence of positive step sizes satisfying $\sum \gamma_k=\infty$ and $\sum \gamma_k^2 &lt;~\infty$.</span>
<span id="cb14-185"><a href="#cb14-185" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-186"><a href="#cb14-186" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Truncation step**: Let us denote $\bar{Z}=(\bar{Z_i})$, $\bar{s}=(\bar{s_i})$ and $s=(s_i)$. If $\bar{s}\in\mathcal{K}_{\kappa_{k-1}}$ and $\|\bar{s}-s_{k-1} \|\leq \varepsilon_{\zeta_{k-1}}$, then set $(Z^k,s^k)=(\bar{Z},\bar{s})$, $\kappa_{k}=\kappa_{k-1}$, $\nu_{k}=\nu_{k-1}+1$, $\zeta_{k}=\zeta_{k-1}+1$, else set $(Z^k,s^k)=(\tilde{Z},\tilde{s})\in \mathrm{K}\times \mathcal{K}_0$, $\kappa_{k}=\kappa_{k-1}+1$, $\nu_{k}=0$, $\zeta_{k}=\zeta_{k-1}+ \Psi(\nu_{k-1})$ where  $\Psi:\mathbb{N} \rightarrow \mathbb{Z}$ is a function such that $\Psi(k)&gt;k$ for any $k$ and $(\tilde{Z},\tilde{s})$ chosen arbitrarily.</span>
<span id="cb14-187"><a href="#cb14-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-188"><a href="#cb14-188" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Maximisation step**: update  of the parameter estimator  according to:</span>
<span id="cb14-189"><a href="#cb14-189" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-190"><a href="#cb14-190" aria-hidden="true" tabindex="-1"></a>\theta_{k} = \arg \max_{\theta}  \sum_{i=1}^n \left( -\psi_i(\theta) + \left&lt;s_i^k,\phi_i(\theta)\right&gt;\right) = \hat{\theta}(s^{k})</span>
<span id="cb14-191"><a href="#cb14-191" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-192"><a href="#cb14-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-193"><a href="#cb14-193" aria-hidden="true" tabindex="-1"></a>**When convergence is reached, say  at iteration $K$ of the algorithm, evaluate the FIM estimator according to**:</span>
<span id="cb14-194"><a href="#cb14-194" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-195"><a href="#cb14-195" aria-hidden="true" tabindex="-1"></a>I_{n,sco}^K = \frac{1}{n} \sum_{i=1}^n \hat{\Delta}_i\left(s^{K}\right) \hat{\Delta}_i\left(s^{K}\right)^t</span>
<span id="cb14-196"><a href="#cb14-196" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-197"><a href="#cb14-197" aria-hidden="true" tabindex="-1"></a>where $\hat{\Delta}_i(s)  =  -\partial \psi_i(\hat{\theta}(s)) + \left&lt;s_i,\partial \phi_i(\hat{\theta}(s))\right&gt;$ for all $s$.</span>
<span id="cb14-198"><a href="#cb14-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-199"><a href="#cb14-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-200"><a href="#cb14-200" aria-hidden="true" tabindex="-1"></a>::: {.remark}</span>
<span id="cb14-201"><a href="#cb14-201" aria-hidden="true" tabindex="-1"></a>Note that the projection step which is done through the truncation procedure on random boundaries ensures the stability of the algorithm in particular for the theoretical analysis provided below. More details on this projection step are available in <span class="co">[</span><span class="ot">@Andrieu2005</span><span class="co">]</span>.</span>
<span id="cb14-202"><a href="#cb14-202" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-203"><a href="#cb14-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-204"><a href="#cb14-204" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical convergence property</span></span>
<span id="cb14-205"><a href="#cb14-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-206"><a href="#cb14-206" aria-hidden="true" tabindex="-1"></a>The theoretical result provided in this section for the sequence $(\theta_k)$ generated by the algorithm with truncation on random boundaries is based on  that of <span class="co">[</span><span class="ot">@Allassonniere2010</span><span class="co">]</span>. Indeed it established convergence guarantees for the FIM estimate obtained as a by-product of that for the MLE. To that purpose,</span>
<span id="cb14-207"><a href="#cb14-207" aria-hidden="true" tabindex="-1"></a>in addition to the exponential family assumption for each individual likelihood, we also make the same type of regularity assumptions as those presented  in <span class="co">[</span><span class="ot">@Allassonniere2010</span><span class="co">]</span> at each individual level. These assumptions are detailed in the appendix section. </span>
<span id="cb14-208"><a href="#cb14-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-209"><a href="#cb14-209" aria-hidden="true" tabindex="-1"></a>We establish our theoretical result for  transition kernels $(\Pi_i)$ corresponding to those of  the random walk Metropolis Hastings algorithm <span class="co">[</span><span class="ot">@jarner2000</span><span class="co">]</span>. We denote by $(q_i)$ the family of symmetric densities used to generate the candidate with the proposal distribution.</span>
<span id="cb14-210"><a href="#cb14-210" aria-hidden="true" tabindex="-1"></a>We  introduce additional assumptions required to control the stochastic behavior of the algorithm:</span>
<span id="cb14-211"><a href="#cb14-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-212"><a href="#cb14-212" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(H1)** There exists a constant $M_0$ such that</span>
<span id="cb14-213"><a href="#cb14-213" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-214"><a href="#cb14-214" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb14-215"><a href="#cb14-215" aria-hidden="true" tabindex="-1"></a>\mathcal L=</span>
<span id="cb14-216"><a href="#cb14-216" aria-hidden="true" tabindex="-1"></a>\left<span class="sc">\{</span>s\in\mathcal S, \langle \nabla l(\hat\theta(s)), h(s)\rangle=0</span>
<span id="cb14-217"><a href="#cb14-217" aria-hidden="true" tabindex="-1"></a>\right<span class="sc">\}\\</span></span>
<span id="cb14-218"><a href="#cb14-218" aria-hidden="true" tabindex="-1"></a>\subset</span>
<span id="cb14-219"><a href="#cb14-219" aria-hidden="true" tabindex="-1"></a><span class="sc">\{</span>s\in\mathcal S, -l(\hat\theta(s))<span class="kw">&lt;M_0</span></span>
<span id="cb14-220"><a href="#cb14-220" aria-hidden="true" tabindex="-1"></a><span class="er">\}.</span></span>
<span id="cb14-221"><a href="#cb14-221" aria-hidden="true" tabindex="-1"></a><span class="er">\end{split}</span></span>
<span id="cb14-222"><a href="#cb14-222" aria-hidden="true" tabindex="-1"></a><span class="er">$$</span></span>
<span id="cb14-223"><a href="#cb14-223" aria-hidden="true" tabindex="-1"></a><span class="ot">In</span> <span class="er">addition,</span> <span class="er">there</span> <span class="er">exist</span>  <span class="er">$M_1\in(M_0,\infty]$</span> <span class="er">such</span> <span class="er">that</span></span>
<span id="cb14-224"><a href="#cb14-224" aria-hidden="true" tabindex="-1"></a><span class="er">$\{s\in\mathcal</span> <span class="er">S,</span> <span class="er">-l(\hat\theta(s))</span> <span class="er">\leq</span> <span class="er">M_1</span></span>
<span id="cb14-225"><a href="#cb14-225" aria-hidden="true" tabindex="-1"></a><span class="er">\}$</span></span>
<span id="cb14-226"><a href="#cb14-226" aria-hidden="true" tabindex="-1"></a><span class="ot">is</span> <span class="er">a</span> <span class="er">compact</span> <span class="er">set.</span> </span>
<span id="cb14-227"><a href="#cb14-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-228"><a href="#cb14-228" aria-hidden="true" tabindex="-1"></a><span class="er">-</span> <span class="er">**(H2)**</span> <span class="er">For</span> <span class="er">all</span> <span class="er">$s\in\mathcal{S}$,</span> <span class="er">$\lim_{z</span> <span class="er">\rightarrow</span> <span class="er">\infty}</span> <span class="er">n(z).\nabla_z</span>  <span class="er">\log</span> <span class="er">p(z;\hat{\theta}(s))</span><span class="ot">=</span><span class="st">-\infty$</span>  <span class="er">and</span> <span class="er">$\lim_{z</span> <span class="er">\rightarrow</span> <span class="er">\infty}</span> <span class="er">\sup</span> <span class="er">n(z).m_s(z)</span> <span class="er">&lt;0$</span> <span class="er">where</span> <span class="er">where</span> <span class="er">$n(z)</span><span class="ot">=</span><span class="st">z/|z|$</span> <span class="er">for</span> <span class="er">$z</span> <span class="er">\neq</span> <span class="er">0$,</span> <span class="er">and</span> <span class="er">$m_s(z)</span><span class="ot">=</span><span class="st">\nabla_z</span> <span class="er">p(z;\hat{\theta}(s))</span> <span class="er">/p(z;\hat{\theta}(s))$</span> <span class="er">with</span> <span class="er">$p(z;\theta)</span><span class="ot">=</span><span class="st">\prod_i</span> <span class="er">p_i(z_i;\theta)$.</span></span>
<span id="cb14-229"><a href="#cb14-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-230"><a href="#cb14-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-231"><a href="#cb14-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-232"><a href="#cb14-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-233"><a href="#cb14-233" aria-hidden="true" tabindex="-1"></a><span class="er">-</span> <span class="er">**(H3)**</span>  <span class="er">The</span> <span class="er">family</span> <span class="er">$\{q_i\}_{1\le</span> <span class="er">i</span> <span class="er">\le</span> <span class="er">n}$</span> <span class="er">of</span> <span class="er">symmetric</span> <span class="er">densities</span>   <span class="er">is</span> <span class="er">such</span> <span class="er">that,</span> <span class="er">for</span> <span class="er">$i</span> <span class="ot">=</span> <span class="st">1,\dots,n$,</span> <span class="er">there</span> <span class="er">exist</span>   <span class="er">constants</span> <span class="er">$\eta_i</span> <span class="kw">&gt;</span> 0$ and $\delta_i &lt;\infty$   such that $q_i (z) &gt; \eta_i$ for all $|z|&lt; \delta_i$.</span>
<span id="cb14-234"><a href="#cb14-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-235"><a href="#cb14-235" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(H4)** There exist $C&gt;1$, $\rho\in(0,1)$  and $\theta_0 \in \Theta$ such that, for all $z\in\mathbb{R}^d$,</span>
<span id="cb14-236"><a href="#cb14-236" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-237"><a href="#cb14-237" aria-hidden="true" tabindex="-1"></a>|S(z)|\le C p(z;\theta_0)^{-\rho}.</span>
<span id="cb14-238"><a href="#cb14-238" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-239"><a href="#cb14-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-240"><a href="#cb14-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-241"><a href="#cb14-241" aria-hidden="true" tabindex="-1"></a>::: {.remark}</span>
<span id="cb14-242"><a href="#cb14-242" aria-hidden="true" tabindex="-1"></a>Assumption $(H2)$ is standard and usually called super-exponentiality property in the literature <span class="co">[</span><span class="ot">@jarner2000</span><span class="co">]</span>.</span>
<span id="cb14-243"><a href="#cb14-243" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-244"><a href="#cb14-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-245"><a href="#cb14-245" aria-hidden="true" tabindex="-1"></a>::: {.remark}</span>
<span id="cb14-246"><a href="#cb14-246" aria-hidden="true" tabindex="-1"></a>We established our results for transition kernels corresponding to  random walk Metropolis Hastings algorithms which are of common use in practice. We emphasize that our result can be generalised to more general  transition kernels by replacing our assumptions $(H2)$ and $(H3)$ by assumption $(DRI)$ of <span class="co">[</span><span class="ot">@Andrieu2005</span><span class="co">]</span> which is more generic. The latter can be verified in practice for more general transition kernels.</span>
<span id="cb14-247"><a href="#cb14-247" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-248"><a href="#cb14-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-249"><a href="#cb14-249" aria-hidden="true" tabindex="-1"></a>::: {#thm-conv.algo}</span>
<span id="cb14-250"><a href="#cb14-250" aria-hidden="true" tabindex="-1"></a>Assume that $(M1')$ and  $(M2')$,  $(M3)$ to  $(M5)$,  $(SAEM1)$ and $(SAEM2)$, $(H1)$ to $(H4)$ are fulfilled. Let us define $\mathcal{L}=<span class="sc">\{</span>\theta \in\Theta, \partial_\theta l(y;\theta)=0<span class="sc">\}</span>$  the set of stationary points of the observed log-likelihood $l$ defined as $l(y;\theta)=\sum_{i=1}^n \log g(y_i;\theta)$. Then, for all $\theta_0 \in \Theta$, for fixed $n \in \mathbb{N}^*$, we get: $\lim_k d(\theta_k,\mathcal{L})=0$ a.s. and  $\lim_k d(I_{n,sco}^k,\mathcal{I})=0$ a.s. where $\mathcal{I}=<span class="sc">\{</span>I_{n,sco}(\theta), \theta \in \mathcal{L}<span class="sc">\}</span>$.</span>
<span id="cb14-251"><a href="#cb14-251" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-252"><a href="#cb14-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-253"><a href="#cb14-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-254"><a href="#cb14-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-255"><a href="#cb14-255" aria-hidden="true" tabindex="-1"></a>:::{.proof} </span>
<span id="cb14-256"><a href="#cb14-256" aria-hidden="true" tabindex="-1"></a>Let us denote by $S(Z)=(S_1(Z_1),\ldots,S_n(Z_n))$ the sufficient statistics of the model we consider in our approach.  Let us also define $H(Z,s)=S(Z)-s$ and $h(s)=\mathrm{E}_{Z|Y;\hat{\theta}(s)}(S(Z))-s$. The proof is composed of two steps following for example the lines of [@Allassonniere2010]. First we establish the almost sure convergence of the sequence $(s_k)$ generated by the algorithm toward the zero of the function $h$. Second we deduce the almost sure convergence of the sequences $(\theta_k)$ and $(I_{n,sco}^k)$ toward the set of critical points of the observed log-likelihood and the set $\mathcal{I}$ respectively. </span>
<span id="cb14-257"><a href="#cb14-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-258"><a href="#cb14-258" aria-hidden="true" tabindex="-1"></a>To prove the first step we apply Theorem 5.5 of <span class="co">[</span><span class="ot">@Andrieu2005</span><span class="co">]</span>.  Therefore we have to verify that their four conditions denoted $(A1)$ to $(A4)$ are fulfilled. Our proof will follow the same global strategy as for example the one of  Theorem 1 in <span class="co">[</span><span class="ot">@kuhn2020</span><span class="co">]</span>. We get first that  condition $(A1)$ is satisfied  by applying Lemma 2 of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>.</span>
<span id="cb14-259"><a href="#cb14-259" aria-hidden="true" tabindex="-1"></a> Indeed our assumptions $(M1')$ and $(M2')$  imply that assumptions  $(M1)$ and $(M2)$ of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span> are  satisfied. These assumptions $(M1')$ and $(M2')$ focus on expressions and regularity properties of the individual likelihood functions and the corresponding sufficient statistics for each index $i \in <span class="sc">\{</span>1,\ldots,n<span class="sc">\}</span>$. The implication above follows by linearity of the log-likelihood function. Then  we get that assumptions $(H1), (M1)-(M5), (SAEM2)$ ensured that  condition $(A1)$ is satisfied. </span>
<span id="cb14-260"><a href="#cb14-260" aria-hidden="true" tabindex="-1"></a>To prove assumptions $(A2)$ and $(A3)$, we will follow the strategy of <span class="co">[</span><span class="ot">@Allassonniere2010</span><span class="co">]</span> to handle the difficulty of finding a common drift function $V$ for the family of posterior distributions  indexed by $s \in \mathcal{S}$. Therefore we will construct first a family of drift functions $(V_s)$ using  Proposition 6.1 of <span class="co">[</span><span class="ot">@Andrieu2005</span><span class="co">]</span>, which stated drift conditions, called $(DRI)$, easy to very in practice. </span>
<span id="cb14-261"><a href="#cb14-261" aria-hidden="true" tabindex="-1"></a>To prove condition $(DRI1)$ for each kernels, we use Theorem 4.1 and Theorem 4.3  of <span class="co">[</span><span class="ot">@jarner2000</span><span class="co">]</span> which stated that assumptions $(H2)$,$(H3)$ and $(H4)$ imply that Equations $(6.1)$ and $(6.3)$ of $(DRI1)$ are satisfied with $m=1$ and $V_s(z)= p(z;\hat{\theta}(s))^{- \rho}$ with $\rho$ given by $(H4)$. Then the common drift function is defined  by $V(z)= p(z;\theta_0)^{- \rho}$ using assumption $(H4)$. Thus for any compact $\mathcal{K}$ of $\Theta$, there exist  constants $c_{\mathcal{K}}&gt;0$ and $C_{\mathcal{K}}&gt;0$ such that for all $\theta \in \mathcal{K}$ and for all $z$, $c_{\mathcal{K}} V(z)\leq p(z;\hat{\theta}(s))^{- \rho} \leq C_{\mathcal{K}}V(z)$. Therefore Equations $(6.1)$ and $(6.3)$ are satisfied for this common drift function $V$. Equation $(6.2)$ follows also from Theorem 2.1 of <span class="co">[</span><span class="ot">@jarner2000</span><span class="co">]</span> which concludes the proof of $(DRI1)$. The first part of $(DRI2)$ is ensured by assumption $(H4)$. The second part is satisfied directly with Lipschitz exponent $\beta$ equal to $1$ in our case. Finally assumption $(DRI3)$ is satisfied also with $\beta=1$ in our framework. This proof is obtained by using the usual strategy of splitting the whole space in four parts depending on the acceptance region and on the rejection region (see  the proof of Lemma 4.7 in <span class="co">[</span><span class="ot">@Fort2015</span><span class="co">]</span> for example) and the fact that  the function $\hat\theta$ is twice continuously differentiable. </span>
<span id="cb14-262"><a href="#cb14-262" aria-hidden="true" tabindex="-1"></a>Finally assumption $(SAEM1)$ allows to choose a sequence $(\varepsilon_k)$ such that $(A4)$ is satisfied (see constructive details in <span class="co">[</span><span class="ot">@Andrieu2005</span><span class="co">]</span> after the statement of assumption $(A4)$). This concludes the proof of the first step.</span>
<span id="cb14-263"><a href="#cb14-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-264"><a href="#cb14-264" aria-hidden="true" tabindex="-1"></a>The function $\hat\theta$ being continuous, we get that $\lim_k d(\theta_k,\mathcal{L})=0$ applying Lemma 2 of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>. Moreover we get that for $1 \leq i \leq n$, each sequence $(s_i^k)$ converges almost surely toward $\mathrm{E}_{Z_i|Y_i;\theta} (S_i(Z_i) )$. Since  assumption $(M2')$ ensures that for all $1 \leq i \leq n$ the functions $\psi_i$ and $\phi_i$ are twice continuously differentiable and assumption $(M5)$ ensures that the function $\hat{\theta}$ is continuously differentiable, the function $\Phi_n$ defined by $\Phi_n(s^{k})=\frac1{n}\sum_{i=1}^n \hat{\Delta}_i(s^{k})\hat{\Delta}_i(s^{k})$ is continuous. Therefore  we get that $\lim_k d(I_{n,sco}^k,\mathcal{I})=0$ which concludes the whole proof.</span>
<span id="cb14-265"><a href="#cb14-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-266"><a href="#cb14-266" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-267"><a href="#cb14-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-268"><a href="#cb14-268" aria-hidden="true" tabindex="-1"></a><span class="fu">### Description of the algorithm for general latent variables models {#sec-generalmodel} </span></span>
<span id="cb14-269"><a href="#cb14-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-270"><a href="#cb14-270" aria-hidden="true" tabindex="-1"></a>In  general settings, the SAEM algorithm can yet  be applied to approximate numerically the maximum likelihood estimate of the model parameter. Nevertheless  there are no more theoretical guarantees of convergence for the algorithm. However we propose an extended version of our algorithm which allows to get an estimate  of the Fisher information matrix as a by-product of the estimation algorithm. </span>
<span id="cb14-271"><a href="#cb14-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-272"><a href="#cb14-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-273"><a href="#cb14-273" aria-hidden="true" tabindex="-1"></a>**Initialization step**:  Initialize arbitrarily $\Delta_i^0$ for all $1 \leq i \leq n$, $Q_0$ and $\theta_0$. </span>
<span id="cb14-274"><a href="#cb14-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-275"><a href="#cb14-275" aria-hidden="true" tabindex="-1"></a>**Repeat until convergence the three steps defined at iteration $k$ by**:</span>
<span id="cb14-276"><a href="#cb14-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-277"><a href="#cb14-277" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Simulation  step**:  for $1 \leq i \leq n$ simulate a realization  $Z_i^k$ direct from  the conditional distribution given the observations $Y_i$, denoted by $p_i$, or from a transition kernel of an ergodic  Markov Chain having $p_i$ as stationary distribution,  using the current parameter $\theta_{k-1}$. </span>
<span id="cb14-278"><a href="#cb14-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-279"><a href="#cb14-279" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Stochastic approximation step**: compute the quantities for all  $1 \leq i \leq n$</span>
<span id="cb14-280"><a href="#cb14-280" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-281"><a href="#cb14-281" aria-hidden="true" tabindex="-1"></a>Q_{k}(\theta) = (1-\gamma_k)Q_{k-1}(\theta)+\gamma_k \sum_{i=1}^n \log f(y_i,Z_i^k;\theta)</span>
<span id="cb14-282"><a href="#cb14-282" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-283"><a href="#cb14-283" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-284"><a href="#cb14-284" aria-hidden="true" tabindex="-1"></a>\Delta_i^{k} = (1-\gamma_k)\Delta_i^{k-1} +\gamma_k \partial_\theta \log f(y_i,Z_i^k;\theta_{k-1})</span>
<span id="cb14-285"><a href="#cb14-285" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-286"><a href="#cb14-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-287"><a href="#cb14-287" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>**Maximisation step**: update  of the parameter estimator  according to:</span>
<span id="cb14-288"><a href="#cb14-288" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-289"><a href="#cb14-289" aria-hidden="true" tabindex="-1"></a>\theta_{k} = \arg \max_{\theta} Q_{k}(\theta).</span>
<span id="cb14-290"><a href="#cb14-290" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-291"><a href="#cb14-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-292"><a href="#cb14-292" aria-hidden="true" tabindex="-1"></a>**When convergence is reached, say  at iteration $K$ of the algorithm, evaluate  the FIM estimator according to**:</span>
<span id="cb14-293"><a href="#cb14-293" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-294"><a href="#cb14-294" aria-hidden="true" tabindex="-1"></a>I_{n,sco}^K = \frac{1}{n} \sum_{i=1}^n \Delta_i^K (\Delta_i^K )^t.</span>
<span id="cb14-295"><a href="#cb14-295" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-296"><a href="#cb14-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-297"><a href="#cb14-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-298"><a href="#cb14-298" aria-hidden="true" tabindex="-1"></a>We illustrate through simulations  in a nonlinear mixed effects model the performance of this algorithm in @sec-SimusNLMM.</span>
<span id="cb14-299"><a href="#cb14-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-300"><a href="#cb14-300" aria-hidden="true" tabindex="-1"></a><span class="fu"># Simulation study {#sec-simul}</span></span>
<span id="cb14-301"><a href="#cb14-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-302"><a href="#cb14-302" aria-hidden="true" tabindex="-1"></a><span class="fu">## Asymptotic properties of the estimators $I_{n,sco}(\theta)$ and $I_{n,obs}(\theta)$ </span></span>
<span id="cb14-303"><a href="#cb14-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-304"><a href="#cb14-304" aria-hidden="true" tabindex="-1"></a>In this section, we investigate the properties of the estimators $I_{n,sco}(\theta)$ and $I_{n,obs}(\theta)$ when the sample size $n$ grows. </span>
<span id="cb14-305"><a href="#cb14-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-306"><a href="#cb14-306" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulation settings</span></span>
<span id="cb14-307"><a href="#cb14-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-308"><a href="#cb14-308" aria-hidden="true" tabindex="-1"></a>First  we consider the following linear mixed effects model $y_{ij} = \beta + z_{i} + \varepsilon_{ij},$</span>
<span id="cb14-309"><a href="#cb14-309" aria-hidden="true" tabindex="-1"></a>where $y_{ij} \in \mathbb{R}$ denotes the $j^{th}$ observation of individual $i$, $1\leq i \leq n$, $1\leq j \leq J$, $z_i \in \mathbb{R}$  the unobserved random effect of individual $i$ and $\varepsilon_{ij} \in \mathbb{R}$  the residual term. The random effects $(z_{i})$ are assumed independent and identically distributed such that $z_{i} \underset{i.i.d.}{\sim} \mathcal{N}(0,\eta^2)$, the residuals $(\varepsilon_{ij})$ are assumed independent and identically distributed such that $\varepsilon_{ij} \underset{i.i.d.}{\sim} \mathcal{N}(0,\sigma^2)$ and the sequences $(z_i)$ and $(\varepsilon_{ij})$ are assumed mutually independent. Here, the model parameters are $\theta = (\beta, \eta^2, \sigma^2)$. We set $\beta=3$, $\eta^2=2$, $\sigma^2=5$ and $J=12$.</span>
<span id="cb14-310"><a href="#cb14-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-311"><a href="#cb14-311" aria-hidden="true" tabindex="-1"></a>Second we consider the following Poisson mixture model where the distribution of each observation $y_i$, $1\leq i \leq n$, depends on a state variable $z_i$ which is latent leading to</span>
<span id="cb14-312"><a href="#cb14-312" aria-hidden="true" tabindex="-1"></a>$y_i|z_i=k  \sim  \mathcal{P}(\lambda_k)$ with $P(z_i=k)  =  \alpha_k$ and $\sum_{k=1}^{K} \alpha_k  = 1.$</span>
<span id="cb14-313"><a href="#cb14-313" aria-hidden="true" tabindex="-1"></a>The model parameters are $\theta=(\lambda_1,\ldots,\lambda_K,\alpha_1,\ldots,\alpha_{K-1})$. For the simulation study, we consider a mixture of $K=3$ components, and the following values for the parameters $\lambda_1=2$, $\lambda_2=5$, $\lambda_3=9$, $\alpha_1=0.3$ and $\alpha_2=0.5$.</span>
<span id="cb14-314"><a href="#cb14-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-315"><a href="#cb14-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-316"><a href="#cb14-316" aria-hidden="true" tabindex="-1"></a>For each model, we generate $M=500$ datasets for different sample sizes $n \in \left<span class="sc">\{</span>20,100,500 \right<span class="sc">\}</span>$. As a first step, we assume that the true parameter values, denoted by $\theta^{\star}$, are known in order to investigate the asymptotic properties of both $I_{n,sco}$ and $I_{n,obs}$ without adding extra noise induced by the estimation of the parameters. Hence, for each value of $n$ and for each $1 \leq m \leq M$, we derive $I_{n,sco}^{(m)}(\theta^{\star})$ and $I_{n,obs}^{(m)}(\theta^{\star})$. The estimators $I_{n,sco}(\theta^{\star})$ and $I_{n,obs}(\theta^{\star})$ can be computed explicitly in both models by applying formula @eq-vnmis and Louis' formula <span class="co">[</span><span class="ot">@Louis1982</span><span class="co">]</span> (see R functions provided in the Appendix section). We then compute the empirical bias and the root mean squared deviation of each component $(\ell,\ell')$ of the estimated matrix as:</span>
<span id="cb14-317"><a href="#cb14-317" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-318"><a href="#cb14-318" aria-hidden="true" tabindex="-1"></a>\frac{1}{M} \sum\limits_{m=1}^{M} I_{n,sco,\ell,\ell'}^{(m)}(\theta^\star) - I_{\ell,\ell'}(\theta^\star)  \; \; \;  \mathrm{and} \; \; \; \sqrt{\frac{1}{M} \sum\limits_{m=1}^{M} \left(I_{n,sco,\ell,\ell'}^{(m)}(\theta^\star) - I_{\ell,\ell'}(\theta^\star)\right)^2}.</span>
<span id="cb14-319"><a href="#cb14-319" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-320"><a href="#cb14-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-321"><a href="#cb14-321" aria-hidden="true" tabindex="-1"></a>In the previous quantities, $I(\theta^\star)$ is explicit in the linear mixed effects model and approximated by a Monte-Carlo estimation based on a sample of size $10^8$ in the Poisson mixture model. The results are presented in @tbl-BiasLMM and @tbl-SdLMM for the linear mixed effects model and in @tbl-BiasMixt and @tbl-SdMixt for the mixture model.</span>
<span id="cb14-322"><a href="#cb14-322" aria-hidden="true" tabindex="-1"></a>In a second step, we use the linear mixed effects model to look at what happens when the parameter $\theta$ is unknown and the estimation of the Fisher information matrix requires to compute an estimate $\hat{\theta}_n$. We use the datasets simulated with $n=500$ and we compute the $M=500$ asymptotic confidence intervals of the three model parameters. We then deduce empirical coverage rates for the following nominal rates $1-\alpha \in \{0.90, 0.95, 0.99\}$ by using the diagonal terms of either the inversed $I_{n,sco}^{(m)}(\theta^{\star})$ (resp. $I_{n,obs}^{(m)}(\theta^{\star})$) or the inversed $I_{n,sco}^{(m)}(\hat{\theta}_n)$ (resp. $I_{n,obs}^{(m)}(\hat{\theta}_n)$). The results are depicted in @tbl-coverageLMM-n100 and @tbl-coverageLMM-n500.</span>
<span id="cb14-323"><a href="#cb14-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-326"><a href="#cb14-326" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-327"><a href="#cb14-327" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuLMM-functions</span></span>
<span id="cb14-328"><a href="#cb14-328" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-329"><a href="#cb14-329" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-330"><a href="#cb14-330" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/Fisher_LMM.R'</span>)</span>
<span id="cb14-331"><a href="#cb14-331" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/Isco_LMM.R'</span>)</span>
<span id="cb14-332"><a href="#cb14-332" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/Iobs_LMM.R'</span>)</span>
<span id="cb14-333"><a href="#cb14-333" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-334"><a href="#cb14-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-337"><a href="#cb14-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-338"><a href="#cb14-338" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuLMM-FIM-sco-obs</span></span>
<span id="cb14-339"><a href="#cb14-339" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb14-340"><a href="#cb14-340" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-341"><a href="#cb14-341" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb14-342"><a href="#cb14-342" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuLMM-estimFIM.R</span></span>
<span id="cb14-343"><a href="#cb14-343" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-344"><a href="#cb14-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-347"><a href="#cb14-347" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-348"><a href="#cb14-348" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuPoissonMixture-functions</span></span>
<span id="cb14-349"><a href="#cb14-349" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-350"><a href="#cb14-350" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-351"><a href="#cb14-351" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/sim_poisson_mixture.R'</span>)</span>
<span id="cb14-352"><a href="#cb14-352" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/em_poisson_mixture.R'</span>)</span>
<span id="cb14-353"><a href="#cb14-353" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/fisher_estimation_poisson_mixture.R'</span>)</span>
<span id="cb14-354"><a href="#cb14-354" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-355"><a href="#cb14-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-356"><a href="#cb14-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-359"><a href="#cb14-359" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-360"><a href="#cb14-360" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuPoissonMixture-exactFIM-MCMC</span></span>
<span id="cb14-361"><a href="#cb14-361" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-362"><a href="#cb14-362" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuPoissonMixture-exactFIM-MCMC.R</span></span>
<span id="cb14-363"><a href="#cb14-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-364"><a href="#cb14-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-367"><a href="#cb14-367" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-368"><a href="#cb14-368" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuPoissonMixture-FIM-sco-obs</span></span>
<span id="cb14-369"><a href="#cb14-369" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb14-370"><a href="#cb14-370" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-371"><a href="#cb14-371" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuPoissonMixture-estimFIM.R</span></span>
<span id="cb14-372"><a href="#cb14-372" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-373"><a href="#cb14-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-374"><a href="#cb14-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-375"><a href="#cb14-375" aria-hidden="true" tabindex="-1"></a><span class="fu">### Results</span></span>
<span id="cb14-376"><a href="#cb14-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-377"><a href="#cb14-377" aria-hidden="true" tabindex="-1"></a>From @tbl-BiasLMM, @tbl-SdLMM, @tbl-BiasMixt and @tbl-SdMixt, we observe that whatever the model and whatever the components of $I_{n,sco}(\theta^{\star})$ and $I_{n,obs}(\theta^{\star})$, the bias is very small even for small values of $n$. Note that in the linear mixed effects model the second derivative with respect to parameter $\beta$ is deterministic, which explains why the bias and the dispersion of the estimations $I_{n,obs}(\theta^{\star})$ are zero for every value of $n$. The bias and the standard deviation decrease as $n$ increases overall, which illustrates the consistency of both M-estimators. The distributions of the normalized estimations $\sqrt{n} \left(I_{n,sco}^{(m)}(\theta^\star) - I(\theta^\star)\right)$ and $\sqrt{n} \left(I_{n,obs}^{(m)}(\theta^\star) - I(\theta^\star)\right)$ are also represented when $n=500$ for some components of the matrices in @fig-simuLMM (linear mixed effects model) and @fig-simuPoissonMixture (Poisson mixture model). The empirical distributions have the shape of Gaussian distributions and illustrate the asymptotic normality of the two estimators. The numerical results highlight that neither $I_{n,sco}(\theta^{\star})$ nor $I_{n,obs}(\theta^{\star})$ is systematically better than the other one in terms of bias and asymptotic covariance matrix. In the same model, different behaviors can be observed depending on the components of the parameter vector.</span>
<span id="cb14-378"><a href="#cb14-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-379"><a href="#cb14-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-382"><a href="#cb14-382" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-383"><a href="#cb14-383" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-simuLMM</span></span>
<span id="cb14-384"><a href="#cb14-384" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-385"><a href="#cb14-385" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-386"><a href="#cb14-386" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Linear mixed effects model. Kernel density estimates of the normalized values of some components of the estimated Fisher information matrix based on the score ($I_{n,sco}$) and of the observed Fisher information matrix ($I_{n,obs}$) computed in the true parameter values from the 500 simulated datasets with n=500.</span></span>
<span id="cb14-387"><a href="#cb14-387" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuLMM-resPlots.R</span></span>
<span id="cb14-388"><a href="#cb14-388" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-389"><a href="#cb14-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-390"><a href="#cb14-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-393"><a href="#cb14-393" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-394"><a href="#cb14-394" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-simuPoissonMixture</span></span>
<span id="cb14-395"><a href="#cb14-395" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-396"><a href="#cb14-396" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-397"><a href="#cb14-397" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Poisson mixture model. Kernel density estimates of the normalized values of some components of the estimated Fisher information matrix based on the score ($I_{n,sco}$) and of the observed Fisher information matrix ($I_{n,obs}$) computed in the true parameter values from the 500 simulated datasets with n=500.</span></span>
<span id="cb14-398"><a href="#cb14-398" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuPoissonMixture-resPlots.R</span></span>
<span id="cb14-399"><a href="#cb14-399" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-400"><a href="#cb14-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-401"><a href="#cb14-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-404"><a href="#cb14-404" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-405"><a href="#cb14-405" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-BiasLMM</span></span>
<span id="cb14-406"><a href="#cb14-406" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Linear mixed effects model. Empirical bias to the Fisher Information matrix of $I_{n,sco}$ and $I_{n,obs}$ computed in the true parameter values for different values of n.</span></span>
<span id="cb14-407"><a href="#cb14-407" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-408"><a href="#cb14-408" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-409"><a href="#cb14-409" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb14-410"><a href="#cb14-410" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb14-411"><a href="#cb14-411" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/tableBiasLMM.R</span></span>
<span id="cb14-412"><a href="#cb14-412" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-413"><a href="#cb14-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-416"><a href="#cb14-416" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-417"><a href="#cb14-417" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-SdLMM</span></span>
<span id="cb14-418"><a href="#cb14-418" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Linear mixed effects model. Empirical squared deviation to the Fisher Information matrix of $I_{n,sco}$ and $I_{n,obs}$ computed in the true parameter values for different values of n.</span></span>
<span id="cb14-419"><a href="#cb14-419" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-420"><a href="#cb14-420" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-421"><a href="#cb14-421" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb14-422"><a href="#cb14-422" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb14-423"><a href="#cb14-423" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/tableSdLMM.R</span></span>
<span id="cb14-424"><a href="#cb14-424" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-425"><a href="#cb14-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-426"><a href="#cb14-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-429"><a href="#cb14-429" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-430"><a href="#cb14-430" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-BiasMixt</span></span>
<span id="cb14-431"><a href="#cb14-431" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Poisson mixture model. Empirical bias to the Fisher Information matrix of $I_{n,sco}$ and $I_{n,obs}$ computed in the true parameter values for different values of n.</span></span>
<span id="cb14-432"><a href="#cb14-432" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-433"><a href="#cb14-433" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb14-434"><a href="#cb14-434" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb14-435"><a href="#cb14-435" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/tableBiasPoissonMixture.R</span></span>
<span id="cb14-436"><a href="#cb14-436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-437"><a href="#cb14-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-440"><a href="#cb14-440" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-441"><a href="#cb14-441" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-SdMixt</span></span>
<span id="cb14-442"><a href="#cb14-442" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Poisson mixture model. Empirical squared deviation to the Fisher Information matrix of $I_{n,sco}$ and $I_{n,obs}$ computed in the true parameter values for different values of n.</span></span>
<span id="cb14-443"><a href="#cb14-443" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-444"><a href="#cb14-444" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb14-445"><a href="#cb14-445" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb14-446"><a href="#cb14-446" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/tableSdPoissonMixture.R</span></span>
<span id="cb14-447"><a href="#cb14-447" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-448"><a href="#cb14-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-449"><a href="#cb14-449" aria-hidden="true" tabindex="-1"></a>@tbl-coverageLMM-n100 and @tbl-coverageLMM-n500 show that the empirical coverage rates computed from $I_{n,sco}$ and $I_{n,obs}$ in the linear mixed effects model are close to the nominal values, which corroborates the relevance of both estimators. Moreover there is little difference between the results obtained when using $I_{n,sco}$ or $I_{n,obs}$ to estimate the Fisher information matrix. When the parameter value is unknown, the uncertainty related to the parameter estimation leads to a deterioration of the coverage rates. Still, this deterioration diminishes when $n$ increases.</span>
<span id="cb14-450"><a href="#cb14-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-453"><a href="#cb14-453" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-454"><a href="#cb14-454" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-coverageLMM-n100</span></span>
<span id="cb14-455"><a href="#cb14-455" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Linear mixed effects model. Comparison of the coverage rates computed from both estimates of the Fisher information matrix in either the true or the estimated parameter values when n=100.</span></span>
<span id="cb14-456"><a href="#cb14-456" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-457"><a href="#cb14-457" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb14-458"><a href="#cb14-458" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb14-459"><a href="#cb14-459" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuLMM-coverage-n100.R</span></span>
<span id="cb14-460"><a href="#cb14-460" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-461"><a href="#cb14-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-464"><a href="#cb14-464" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-465"><a href="#cb14-465" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-coverageLMM-n500</span></span>
<span id="cb14-466"><a href="#cb14-466" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: Linear mixed effects model. Comparison of the coverage rates computed from both estimates of the Fisher information matrix in either the true or the estimated parameter values when n=500.</span></span>
<span id="cb14-467"><a href="#cb14-467" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-468"><a href="#cb14-468" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb14-469"><a href="#cb14-469" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb14-470"><a href="#cb14-470" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuLMM-coverage-n500.R</span></span>
<span id="cb14-471"><a href="#cb14-471" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-472"><a href="#cb14-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-473"><a href="#cb14-473" aria-hidden="true" tabindex="-1"></a><span class="fu">## Asymptotic properties of the stochastic approximation algorithm {#sec-SimusNLMM}</span></span>
<span id="cb14-474"><a href="#cb14-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-475"><a href="#cb14-475" aria-hidden="true" tabindex="-1"></a>We now investigate the properties of our algorithm with truncation on random boundaries in the curved exponential family when the number of iterations grows (@sec-simuExpo) and the good performance of its extended version in more general latent variable models (@sec-simuNonExpo). We also present a short comparison with existing methods (@sec-simuComparison).</span>
<span id="cb14-476"><a href="#cb14-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-477"><a href="#cb14-477" aria-hidden="true" tabindex="-1"></a><span class="fu">### In curved exponential family models {#sec-simuExpo}</span></span>
<span id="cb14-478"><a href="#cb14-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-479"><a href="#cb14-479" aria-hidden="true" tabindex="-1"></a>We consider the following nonlinear mixed effects model which is widely used in pharmacokinetics for describing the evolution of drug concentration over time:</span>
<span id="cb14-480"><a href="#cb14-480" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-481"><a href="#cb14-481" aria-hidden="true" tabindex="-1"></a>y_{ij}= g_i(t_{ij},z_i) + \varepsilon_{ij},</span>
<span id="cb14-482"><a href="#cb14-482" aria-hidden="true" tabindex="-1"></a>$$ {#eq-modelPK}</span>
<span id="cb14-483"><a href="#cb14-483" aria-hidden="true" tabindex="-1"></a>where $z_i=(\log ka_i, \log Cl_i, \log V_i)'$ are individual random parameters such that </span>
<span id="cb14-484"><a href="#cb14-484" aria-hidden="true" tabindex="-1"></a>$$\log ka_{i}  =  \log(ka) + \eta_{i,1}, \log Cl_{i}  =  \log(Cl) + \eta_{i,2}, \log V_i  =  \log(V) + \eta_{i,3},$$ </span>
<span id="cb14-485"><a href="#cb14-485" aria-hidden="true" tabindex="-1"></a>and </span>
<span id="cb14-486"><a href="#cb14-486" aria-hidden="true" tabindex="-1"></a>$$g_i(t_{ij},z_i) = \frac{d_i ka_{i}}{V_i ka_{i}-Cl_{i}}\left<span class="co">[</span><span class="ot">e^{-\frac{Cl_{i}}{V_i} t_{ij}} - e^{-ka_{i} t_{ij}}\right</span><span class="co">]</span>.$$ </span>
<span id="cb14-487"><a href="#cb14-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-488"><a href="#cb14-488" aria-hidden="true" tabindex="-1"></a>For all $1 \leq i \leq n$ and all $1\leq j \leq J$, $y_{ij}$ denotes the measure of drug concentration on individual $i$ at time $t_{ij}$, $d_i$  the dose of drug administered to individual $i$, and $V_i$, $ka_i$ and $Cl_i$ respectively denote the volume of the central compartment, the drug's absorption rate constant and the drug's clearance of individual $i$. </span>
<span id="cb14-489"><a href="#cb14-489" aria-hidden="true" tabindex="-1"></a>The terms $\eta_{i} = (\eta_{i,1},\eta_{i,2},\eta_{i,3})' \in \mathbb{R}^3$ are unobserved random effects which are assumed independent and identically distributed such that $\eta_i \underset{i.i.d.}{\sim} \mathcal{N}(0,\Omega)$, where $\Omega = \mathrm{diag}(\omega^2_{ka},\omega^2_{Cl},\omega^2_{V})$, the residuals $(\varepsilon_{ij})$ are assumed independent and identically distributed such that $\varepsilon_{ij} \underset{i.i.d.}{\sim} \mathcal{N}(0,\sigma^2)$ and the sequences $(\eta_i)$ and $(\varepsilon_{ij})$ are assumed mutually independent. Here, the model parameter is $\theta = (ka,V,Cl,\omega^2_{ka},\omega^2_{V},\omega^2_{Cl},\sigma^2)$. </span>
<span id="cb14-490"><a href="#cb14-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-491"><a href="#cb14-491" aria-hidden="true" tabindex="-1"></a>In this model, as in a large majority of nonlinear mixed effects models, the likelihood does not have any analytical expression. As a consequence, neither the Fisher Information Matrix, nor the estimators $I_{n,sco}(\theta)$, $I_{n,obs}(\theta)$ have explicit expressions. However, as the complete data log-likelihood is explicit, stochastic approximations of $I_{n,sco}(\theta)$, $I_{n,obs}(\theta)$ can be implemented. Note moreover that this model belongs to the curved exponential family as defined in @eq-curvedexpo with </span>
<span id="cb14-492"><a href="#cb14-492" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-493"><a href="#cb14-493" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb14-494"><a href="#cb14-494" aria-hidden="true" tabindex="-1"></a>S_i(z_i) = \left(\sum_{j=1}^{J} (y_{ij} g_i(t_{ij}, z_i)), (\log ka_i), (\log Cl_i), (\log V_i), (\log ka_i)^2, (\log Cl_i)^2, (\log V_i)^2 \right)'<span class="sc">\\</span></span>
<span id="cb14-495"><a href="#cb14-495" aria-hidden="true" tabindex="-1"></a>\phi_i(\theta) =  \left(\frac{1}{2\sigma^2},\frac{\log ka}{\omega_{ka}^2}, \frac{\log Cl}{\omega_{Cl}^2}, \frac{\log V}{\omega_{V}^2},-\frac{1}{2\omega_{ka}^2},-\frac{1}{2\omega_{Cl}^2},-\frac{1}{2\omega_{V}^2}\right),<span class="sc">\\</span></span>
<span id="cb14-496"><a href="#cb14-496" aria-hidden="true" tabindex="-1"></a>\psi_i(\theta) = \frac{1}{2}\left(\frac{(\log ka)^2}{\omega_{ka}^2} + \frac{(\log Cl)^2}{\omega_{Cl}^2} + \frac{(\log V)^2}{\omega_{V}^2}\right).</span>
<span id="cb14-497"><a href="#cb14-497" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb14-498"><a href="#cb14-498" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-499"><a href="#cb14-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-500"><a href="#cb14-500" aria-hidden="true" tabindex="-1"></a>The algorithm described in @sec-algoSAEM can therefore be easily implemented to estimate $\theta$ and the Fisher information matrix simultaneously (see R function provided in the Appendix section).</span>
<span id="cb14-501"><a href="#cb14-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-502"><a href="#cb14-502" aria-hidden="true" tabindex="-1"></a>We take the following values for the parameters $V=31$, $ka=1.6$, $Cl=2.8$, $\omega^2_V=0.40$, $\omega^2_{ka}=0.40$, $\omega^2_{Cl}=0.40$ and $\sigma^2=0.75$. We consider the same dose $d_i=320$ and the same observation times (in hours): $0.25$,$0.5$, $1$, $2$, $3.5$, $5$, $7$, $9$, $12$, $24$ for all the individuals. We simulate one dataset with $n=100$ individuals under model specified by @eq-modelPK. On this simulated dataset, we run $M=500$ times the stochastic approximation algorithm described in @sec-algoSAEM for computing $I_{n,sco}(\hat{\theta})$ together with $\hat{\theta}$ and the algorithm of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span> for computing $I_{n,obs}(\hat{\theta})$. We perform $K=3000$ iterations in total for each algorithm by setting $\gamma_k=0.95$ for $1 \leq k \leq 1000$ (burn in iterations) and $\gamma_k=(k-1000)^{-3/5}$ otherwise, $\varepsilon_k=5.10^4\gamma_k^{2/5}$ and $\mathcal{K}_{\kappa} = [-20-\kappa,20+\kappa]^6\times[0,5.10^4+\kappa]$. At any iteration, we compute the empirical relative bias and the empirical relative standard deviation of each component $(\ell,\ell')$ of $I_{n,sco}$ defined respectively as: </span>
<span id="cb14-503"><a href="#cb14-503" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-504"><a href="#cb14-504" aria-hidden="true" tabindex="-1"></a>\frac{1}{M} \sum\limits_{m=1}^{M} \frac{\widehat{I_{n,sco,\ell,\ell'}^{(k,m)}} - I_{n,sco,\ell,\ell'}^{\star}}{I_{n,sco,\ell,\ell'}^{\star}} \; \; \; \mathrm{and} </span>
<span id="cb14-505"><a href="#cb14-505" aria-hidden="true" tabindex="-1"></a>\; \; \; \sqrt{\frac{1}{M} \sum\limits_{m=1}^{M} \left(\frac{\widehat{I_{n,sco,\ell,\ell'}^{(k,m)}} - I_{n,sco,\ell,\ell'}^{\star}}{I_{n,sco,\ell,\ell'}^{\star}}</span>
<span id="cb14-506"><a href="#cb14-506" aria-hidden="true" tabindex="-1"></a>\right)^2} </span>
<span id="cb14-507"><a href="#cb14-507" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-508"><a href="#cb14-508" aria-hidden="true" tabindex="-1"></a>where $\widehat{I_{n,sco}^{(k,m)}}$ denotes the estimated value of $I_{n,sco}(\hat{\theta})$ at iteration $k$ of the $m^{th}$ algorithm. We compute the same quantities for $I_{n,obs}$. As the true values of $I_{n,sco}^{\star}=I_{n,sco}(\theta^{\star})$ and $I_{n,obs}^{\star}=I_{n,obs}(\theta^{\star})$ are not known, they are estimated by Monte-Carlo integration based on $10^5$ iterations, including $5000$ burnin, of a Metropolis-Hastings algorithm. </span>
<span id="cb14-509"><a href="#cb14-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-512"><a href="#cb14-512" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-513"><a href="#cb14-513" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuNlmeExponential-functions</span></span>
<span id="cb14-514"><a href="#cb14-514" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-515"><a href="#cb14-515" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-516"><a href="#cb14-516" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/model-nlme.R'</span>)</span>
<span id="cb14-517"><a href="#cb14-517" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/saem_nlme_exponential_bis.R'</span>)</span>
<span id="cb14-518"><a href="#cb14-518" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/fim-mcmc-nlme.R'</span>)</span>
<span id="cb14-519"><a href="#cb14-519" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-520"><a href="#cb14-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-523"><a href="#cb14-523" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-524"><a href="#cb14-524" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuNlme-exponential</span></span>
<span id="cb14-525"><a href="#cb14-525" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb14-526"><a href="#cb14-526" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-527"><a href="#cb14-527" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuNLME-exponential-bis.R</span></span>
<span id="cb14-528"><a href="#cb14-528" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-529"><a href="#cb14-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-530"><a href="#cb14-530" aria-hidden="true" tabindex="-1"></a>The results are displayed in @fig-simuNlme-exponential-bias and @fig-simuNlme-exponential-sd.</span>
<span id="cb14-531"><a href="#cb14-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-534"><a href="#cb14-534" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-535"><a href="#cb14-535" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-simuNlme-exponential-bias</span></span>
<span id="cb14-536"><a href="#cb14-536" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-537"><a href="#cb14-537" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-538"><a href="#cb14-538" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Non linear mixed effects model. Representation over iterations of the mean relative bias of the diagonal components of the estimated Fisher information matrix computed from the $M=500$ runs of the stochastic algorithm. Red line corresponds to $I_{n,sco}(\theta)$ and blue line corresponds to $I_{n,obs}(\theta)$. The burn-in iterations of the algorithm are not depicted.</span></span>
<span id="cb14-539"><a href="#cb14-539" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuNLME-exponential-plots-bias.R</span></span>
<span id="cb14-540"><a href="#cb14-540" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-541"><a href="#cb14-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-542"><a href="#cb14-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-545"><a href="#cb14-545" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-546"><a href="#cb14-546" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-simuNlme-exponential-sd</span></span>
<span id="cb14-547"><a href="#cb14-547" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-548"><a href="#cb14-548" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-549"><a href="#cb14-549" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Non linear mixed effects model. Representation over iterations of the mean relative standard error of the diagonal components of the estimated Fisher information matrix computed from the $M=500$ runs of the stochastic algorithm. Red line corresponds to $I_{n,sco}(\theta)$ and blue line corresponds to $I_{n,obs}(\theta)$. The burn-in iterations of the algorithme are not depicted</span></span>
<span id="cb14-550"><a href="#cb14-550" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuNLME-exponential-plots-sd.R</span></span>
<span id="cb14-551"><a href="#cb14-551" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-552"><a href="#cb14-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-553"><a href="#cb14-553" aria-hidden="true" tabindex="-1"></a>We observe that the bias and the standard deviations of the estimates of the components of both matrices decrease over iterations, and that for both estimates the bias is nearly zero when the convergence of the algorithm is reached. According to these simulation results, there is no evidence that one method is better than the other in terms of bias or standard deviation.</span>
<span id="cb14-554"><a href="#cb14-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-555"><a href="#cb14-555" aria-hidden="true" tabindex="-1"></a><span class="fu">### In general latent variable models {#sec-simuNonExpo}</span></span>
<span id="cb14-556"><a href="#cb14-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-557"><a href="#cb14-557" aria-hidden="true" tabindex="-1"></a>We use model specified by @eq-modelPK again, but we now consider that individual parameter $V_i$ is fixed, *i.e.* $V_i \equiv V$ $\forall i = 1,\ldots,n$. The model is no longer exponential in the sense of equation @eq-curvedexpo. We must therefore use the general version of the stochastic approximation algorithm from @sec-generalmodel to compute $I_{n,sco}(\hat{\theta})$  (see R function provided in the Appendix section). We simulate 500 datasets according to this model and we estimate $I_{n,sco}(\hat{\theta})$ and $\hat{\theta}$ for each one. We perform $K=3000$ iterations of the algorithm by setting $\gamma_k=k^{-0.501}$. We compute the 500 asymptotic confidence intervals of the model parameters, by using either the inversed $I_{n,sco}(\hat{\theta}_k)$'s or the inversed $I_{n,obs}(\hat{\theta}_k)$'s and then deduce from them empirical coverage rates. </span>
<span id="cb14-558"><a href="#cb14-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-559"><a href="#cb14-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-562"><a href="#cb14-562" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-563"><a href="#cb14-563" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuNlmeNonExponential-functions</span></span>
<span id="cb14-564"><a href="#cb14-564" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-565"><a href="#cb14-565" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-566"><a href="#cb14-566" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/saem_nlme_non_exponential.R'</span>)</span>
<span id="cb14-567"><a href="#cb14-567" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-568"><a href="#cb14-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-571"><a href="#cb14-571" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-572"><a href="#cb14-572" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuNlme-non-exponential</span></span>
<span id="cb14-573"><a href="#cb14-573" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb14-574"><a href="#cb14-574" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-575"><a href="#cb14-575" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuNLME-nonexponential.R</span></span>
<span id="cb14-576"><a href="#cb14-576" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-577"><a href="#cb14-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-580"><a href="#cb14-580" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-581"><a href="#cb14-581" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuNlme-non-exponential-coverage</span></span>
<span id="cb14-582"><a href="#cb14-582" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-583"><a href="#cb14-583" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-584"><a href="#cb14-584" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuNLME-nonexponential-coverage.R</span></span>
<span id="cb14-585"><a href="#cb14-585" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-586"><a href="#cb14-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-587"><a href="#cb14-587" aria-hidden="true" tabindex="-1"></a>We obtain for the six parameters $(ka,V,Cl,\omega^2_{ka},\omega^2_{Cl},\sigma^2)$ empirical covering rates of \newline $<span class="in">`r covering.isco/nbsim`</span>$ respectively for a nominal covering rate of $0.95$. This highlights that our estimate accurately quantifies the precisions of parameter estimates. Note that empirical coverage rates computed from $I_{n,obs}$ are similar (here $<span class="in">`r covering.iobs/nbsim`</span>$) but that the real advantage of our method is that it requires stochastic approximation only on the first-order derivatives of the complete log-likelihood, contrary to $I_{n,obs}$ which requires deriving the complete log-likelihood at the second order and thus implies more complicated formulas since the model does not belong to the exponential family.</span>
<span id="cb14-588"><a href="#cb14-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-589"><a href="#cb14-589" aria-hidden="true" tabindex="-1"></a>Convergence graphs obtained from a simulated data set are shown in @fig-NLMEnonexponential-conv-plot. Although theoretical guarantee is missing in non exponential models, the stochastic approximation algorithm proposed in @sec-generalmodel converges in practice on this example for both the estimation of the model parameters and the estimation of the Fisher information matrix. </span>
<span id="cb14-590"><a href="#cb14-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-593"><a href="#cb14-593" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-594"><a href="#cb14-594" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simusNLMEnonexponential-single-dataset</span></span>
<span id="cb14-595"><a href="#cb14-595" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-596"><a href="#cb14-596" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-597"><a href="#cb14-597" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuNLME-nonexponential-single-dataset.R</span></span>
<span id="cb14-598"><a href="#cb14-598" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-599"><a href="#cb14-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-602"><a href="#cb14-602" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-603"><a href="#cb14-603" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-NLMEnonexponential-conv-plot</span></span>
<span id="cb14-604"><a href="#cb14-604" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-605"><a href="#cb14-605" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-606"><a href="#cb14-606" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Non linear mixed effects model. Convergence plot for some parameter estimates and for some diagonal components of $I_{n,sco}(\hat{\theta})$ over iterations of the stochastic approximation algorithm.</span></span>
<span id="cb14-607"><a href="#cb14-607" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuNLME-nonexponential-conv-plot.R</span></span>
<span id="cb14-608"><a href="#cb14-608" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-609"><a href="#cb14-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-610"><a href="#cb14-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-611"><a href="#cb14-611" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparison with other methods {#sec-simuComparison}</span></span>
<span id="cb14-612"><a href="#cb14-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-613"><a href="#cb14-613" aria-hidden="true" tabindex="-1"></a>To the best of our knowledge, although there exists contributions focusing on the estimation of the Fisher information matrix in latent variable models, there is currently no method based on the first derivatives of the log-likelihood. We compare to <span class="co">[</span><span class="ot">@Meng2017</span><span class="co">]</span> who proposed an iterative method based on numerical first order derivatives of the Q function that is computed at each E-step of the EM algorithm. The model used by <span class="co">[</span><span class="ot">@Meng2017</span><span class="co">]</span> in their simulation study is a mixture of two Gaussian distributions with unknown expectations $\mu_1$ and $\mu_2$, fixed variances equal to $1$ and unknown proportion $\pi$. The model parameters are denoted by $\theta=(\mu_1,\mu_2,\pi)$.</span>
<span id="cb14-614"><a href="#cb14-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-615"><a href="#cb14-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-618"><a href="#cb14-618" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-619"><a href="#cb14-619" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuGaussianMixture-functions</span></span>
<span id="cb14-620"><a href="#cb14-620" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-621"><a href="#cb14-621" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-622"><a href="#cb14-622" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/sim_gaussian_mixture.R'</span>)</span>
<span id="cb14-623"><a href="#cb14-623" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/em_gaussian_mixture.R'</span>)</span>
<span id="cb14-624"><a href="#cb14-624" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">'functions/fisher_estimation_gaussian_mixture.R'</span>)</span>
<span id="cb14-625"><a href="#cb14-625" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-626"><a href="#cb14-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-627"><a href="#cb14-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-630"><a href="#cb14-630" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-631"><a href="#cb14-631" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simusMeng</span></span>
<span id="cb14-632"><a href="#cb14-632" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb14-633"><a href="#cb14-633" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb14-634"><a href="#cb14-634" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: scripts/simuGaussianMixture.R</span></span>
<span id="cb14-635"><a href="#cb14-635" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-636"><a href="#cb14-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-639"><a href="#cb14-639" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-640"><a href="#cb14-640" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simusMeng-results</span></span>
<span id="cb14-641"><a href="#cb14-641" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb14-642"><a href="#cb14-642" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-643"><a href="#cb14-643" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"Rfiles/ResGaussianMixture.Rdata"</span>)</span>
<span id="cb14-644"><a href="#cb14-644" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-645"><a href="#cb14-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-646"><a href="#cb14-646" aria-hidden="true" tabindex="-1"></a>We simulate 10000 datasets according to this Gaussian mixture model, using the same setting as <span class="co">[</span><span class="ot">@Meng2017</span><span class="co">]</span>, *i.e.* $n=750$, $\pi=2/3$, $\mu_1=3$ and $\mu_2=0$. For each dataset $k=1,\ldots,10000$, we compute the parameter maximum likelihood estimate $\hat{\theta}_k = (\hat{\pi}_k,\widehat{\mu_1}_k,\widehat{\mu_2}_k)$ with an EM algorithm and then we derive $I_{n,sco}(\hat{\theta}_k)$ directly according to @eq-vnmis (see R function provided in the Appendix section) contrary to <span class="co">[</span><span class="ot">@Meng2017</span><span class="co">]</span> who used an iterative method. We compute the empirical mean of the  10000 estimated matrices leading to: </span>
<span id="cb14-647"><a href="#cb14-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-648"><a href="#cb14-648" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-649"><a href="#cb14-649" aria-hidden="true" tabindex="-1"></a>\frac1{10000} \sum _k I_{n,sco}(\hat{\theta}_k)= \begin{pmatrix}</span>
<span id="cb14-650"><a href="#cb14-650" aria-hidden="true" tabindex="-1"></a><span class="in">`r res$isco[1,1]`</span> &amp; <span class="in">`r res$isco[1,2]`</span> &amp; <span class="in">`r res$isco[1,3]`</span><span class="sc">\\</span></span>
<span id="cb14-651"><a href="#cb14-651" aria-hidden="true" tabindex="-1"></a><span class="in">`r res$isco[2,1]`</span> &amp; <span class="in">`r res$isco[2,2]`</span> &amp; <span class="in">`r res$isco[2,3]`</span> <span class="sc">\\</span></span>
<span id="cb14-652"><a href="#cb14-652" aria-hidden="true" tabindex="-1"></a><span class="in">`r res$isco[3,1]`</span> &amp; <span class="in">`r res$isco[3,2]`</span> &amp; <span class="in">`r res$isco[3,3]`</span><span class="sc">\\</span></span>
<span id="cb14-653"><a href="#cb14-653" aria-hidden="true" tabindex="-1"></a>\end{pmatrix}.</span>
<span id="cb14-654"><a href="#cb14-654" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-655"><a href="#cb14-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-656"><a href="#cb14-656" aria-hidden="true" tabindex="-1"></a>Comparison with the results of <span class="co">[</span><span class="ot">@Meng2017</span><span class="co">]</span> is delicate since their numerical illustration of their method is based on a single simulated dataset thus potentially sensitive to sampling variations. However, they provide an estimation of the Fisher information matrix from this unique dataset   </span>
<span id="cb14-657"><a href="#cb14-657" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-658"><a href="#cb14-658" aria-hidden="true" tabindex="-1"></a>I_{Meng} = \begin{pmatrix}</span>
<span id="cb14-659"><a href="#cb14-659" aria-hidden="true" tabindex="-1"></a>2591.3 &amp; -237.9 &amp; -231.8<span class="sc">\\</span></span>
<span id="cb14-660"><a href="#cb14-660" aria-hidden="true" tabindex="-1"></a>-237.9 &amp; 155.8 &amp; -86.7<span class="sc">\\</span></span>
<span id="cb14-661"><a href="#cb14-661" aria-hidden="true" tabindex="-1"></a>-231.8 &amp; -86.7 &amp; 394.5</span>
<span id="cb14-662"><a href="#cb14-662" aria-hidden="true" tabindex="-1"></a>\end{pmatrix}.</span>
<span id="cb14-663"><a href="#cb14-663" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-664"><a href="#cb14-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-665"><a href="#cb14-665" aria-hidden="true" tabindex="-1"></a>Our results are coherent with their ones. To check the reliability of our results, we then compute as above the 10000 asymptotic confidence intervals of the three model parameters. We obtain for the three parameters $(\pi,\mu_1,\mu_2)$ empirical covering rates of $<span class="in">`r res$recouvprob`</span>$, $<span class="in">`r res$recouvm1`</span>$, $<span class="in">`r res$recouvm2`</span>$ respectively for a nominal covering rate of $0.95$. Thus $I_{n,sco}$ accurately quantifies the precisions of parameter estimates. </span>
<span id="cb14-666"><a href="#cb14-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-667"><a href="#cb14-667" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion and discussion</span></span>
<span id="cb14-668"><a href="#cb14-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-669"><a href="#cb14-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-670"><a href="#cb14-670" aria-hidden="true" tabindex="-1"></a>In this work, we address the estimation of the Fisher information matrix in general latent variable models. We focus on the empirical Fisher information matrix which is a moment estimate of the covariance matrix of the score.  We propose stochastic approximation algorithms to compute this estimate when it can not be calculated analytically and establish theoretical convergence properties in the curved exponential family setting. We carry out a simulation study in mixed effects model and in a Poisson mixture model to compare the performances of several estimates, namely the considered empirical Fisher information matrix and the observed  Fisher information matrix. We emphasize that the  empirical FIM requires less regularity assumptions than the  observed  FIM. From a computational point of view, the implementation of the algorithm for evaluating the empirical FIM only involves the first derivatives of the log-likelihood, in contrary to the one for evaluating the observed FIM which involves the second derivatives of the log-likelihood.</span>
<span id="cb14-671"><a href="#cb14-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-672"><a href="#cb14-672" aria-hidden="true" tabindex="-1"></a>The main perspective of this work is to adapt the procedure for statistical models whose derivatives of the log-likelihood have no tractable expressions, coupling the algorithm with numerical derivative procedures. </span>
<span id="cb14-673"><a href="#cb14-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-674"><a href="#cb14-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-675"><a href="#cb14-675" aria-hidden="true" tabindex="-1"></a><span class="fu"># Appendix</span></span>
<span id="cb14-676"><a href="#cb14-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-677"><a href="#cb14-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-678"><a href="#cb14-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-679"><a href="#cb14-679" aria-hidden="true" tabindex="-1"></a><span class="fu">## Description of the algorithm without truncation on random boundaries in curved exponential family model {#sec-algoSAEM-appendix}</span></span>
<span id="cb14-680"><a href="#cb14-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-681"><a href="#cb14-681" aria-hidden="true" tabindex="-1"></a>We provide here a simpler algorithm based on an extension of the stochastic approximation Expectation Maximization algorithm proposed by <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span> using a simulation step performed from the conditional distribution and without truncation on random boundaries. Theoretical results are established assuming a stability condition which is usually quite difficult to check. However, this algorithm can be easily applied in practice.</span>
<span id="cb14-682"><a href="#cb14-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-683"><a href="#cb14-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-684"><a href="#cb14-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-685"><a href="#cb14-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-686"><a href="#cb14-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-687"><a href="#cb14-687" aria-hidden="true" tabindex="-1"></a>**Initialization step**: Initialize arbitrarily for all $1 \leq i \leq n$ $s_i^0$ and $\theta_0$. </span>
<span id="cb14-688"><a href="#cb14-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-689"><a href="#cb14-689" aria-hidden="true" tabindex="-1"></a>**Repeat until convergence the  three   steps defined at iteration $k$ by**:</span>
<span id="cb14-690"><a href="#cb14-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-691"><a href="#cb14-691" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Simulation  step**:  for $1 \leq i \leq n$ simulate a realization  $Z_i^k$ from  the conditional distribution given the observations $Y_i$ denoted by $p_i$ using  the current parameter value $\theta_{k-1}$. </span>
<span id="cb14-692"><a href="#cb14-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-693"><a href="#cb14-693" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Stochastic approximation step**: compute the quantities for all  $1 \leq i \leq n$</span>
<span id="cb14-694"><a href="#cb14-694" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-695"><a href="#cb14-695" aria-hidden="true" tabindex="-1"></a>s_i^{k} = (1-\gamma_k)s_i^{k-1} +\gamma_k  S_i(Z_i^k) </span>
<span id="cb14-696"><a href="#cb14-696" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-697"><a href="#cb14-697" aria-hidden="true" tabindex="-1"></a>where $(\gamma_k)$ is a sequence of positive step sizes satisfying $\sum \gamma_k=\infty$ and $\sum \gamma_k^2 &lt;~\infty$.</span>
<span id="cb14-698"><a href="#cb14-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-699"><a href="#cb14-699" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Maximisation step**: update  of the parameter estimator  according to:</span>
<span id="cb14-700"><a href="#cb14-700" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-701"><a href="#cb14-701" aria-hidden="true" tabindex="-1"></a>\theta_{k} = \arg \max_{\theta}  \sum_{i=1}^n \left( -\psi_i(\theta) + \left&lt;s_i^k,\phi_i(\theta)\right&gt;\right) = \hat{\theta}(s^{k})</span>
<span id="cb14-702"><a href="#cb14-702" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-703"><a href="#cb14-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-704"><a href="#cb14-704" aria-hidden="true" tabindex="-1"></a>**When convergence is reached, say  at iteration $K$ of the algorithm, evaluate the FIM estimator according to**:</span>
<span id="cb14-705"><a href="#cb14-705" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-706"><a href="#cb14-706" aria-hidden="true" tabindex="-1"></a>I_{n,sco}^K = \frac{1}{n} \sum_{i=1}^n \hat{\Delta}_i\left(s^{K}\right) \hat{\Delta}_i\left(s^{K}\right)^t</span>
<span id="cb14-707"><a href="#cb14-707" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-708"><a href="#cb14-708" aria-hidden="true" tabindex="-1"></a>where $\hat{\Delta}_i(s)  =  -\partial \psi_i(\hat{\theta}(s)) + \left&lt;s_i,\partial \phi_i(\hat{\theta}(s))\right&gt;$ for all $s$.</span>
<span id="cb14-709"><a href="#cb14-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-710"><a href="#cb14-710" aria-hidden="true" tabindex="-1"></a>::: {.remark}</span>
<span id="cb14-711"><a href="#cb14-711" aria-hidden="true" tabindex="-1"></a>In the cases where the latent variables can not be simulated from the conditional distribution, one can apply the extension coupling the stochastic algorithm with a Monte Carlo Markov Chain procedure as presented in <span class="co">[</span><span class="ot">@Kuhn2004</span><span class="co">]</span>. All the following results can be extended to this case.</span>
<span id="cb14-712"><a href="#cb14-712" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-713"><a href="#cb14-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-714"><a href="#cb14-714" aria-hidden="true" tabindex="-1"></a><span class="fu">## Theoretical convergence properties</span></span>
<span id="cb14-715"><a href="#cb14-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-716"><a href="#cb14-716" aria-hidden="true" tabindex="-1"></a>The theoretical following results provided convergence guarantees for the FIM estimate obtained as a by-product of the MLE. Therefore they extend  those  of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>.   To that purpose,</span>
<span id="cb14-717"><a href="#cb14-717" aria-hidden="true" tabindex="-1"></a>in addition to the exponential family assumption for each individual likelihood, we also make the same type of regularity assumptions as those presented  in <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span> at each individual level. These regularity assumptions on the model are detailed at the end of the appendix section.</span>
<span id="cb14-718"><a href="#cb14-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-719"><a href="#cb14-719" aria-hidden="true" tabindex="-1"></a>::: {#thm-conv.algo}</span>
<span id="cb14-720"><a href="#cb14-720" aria-hidden="true" tabindex="-1"></a>Assume that $(M1')$ and  $(M2')$,  $(M3)$ to  $(M5)$ and $(SAEM1)$ to $(SAEM4)$  are fulfilled. Assume also that with probability 1 $\mathrm{clos}(<span class="sc">\{</span>s_k<span class="sc">\}</span>_{k \geq 1})$ is a compact subset of $\mathcal{S}$. Let us define $\mathcal{L}=\{\theta \in\Theta, \partial_\theta l(y;\theta)=0\}$  the set of stationary points of the observed log-likelihood $l$ defined as $l(y;\theta)=\sum_{i=1}^n \log g(y_i;\theta)$. Then, for all $\theta_0 \in \Theta$, for fixed $n \in \mathbb{N}^*$, we get: $\lim_k d(\theta_k,\mathcal{L})=0$ and  $\lim_k d(I_{n,sco}^k,\mathcal{I})=0$ a.s. where $\mathcal{I}=\{I_{n,sco}(\theta), \theta \in \mathcal{L}<span class="sc">\}</span>$.</span>
<span id="cb14-721"><a href="#cb14-721" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-722"><a href="#cb14-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-723"><a href="#cb14-723" aria-hidden="true" tabindex="-1"></a>:::{.proof}</span>
<span id="cb14-724"><a href="#cb14-724" aria-hidden="true" tabindex="-1"></a>Let us denote by $S(Z)=(S_1(Z_1),\ldots,S_n(Z_n))$ the sufficient statistics of the model we consider in our approach. Note as recalled in <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>, these are not unique. Let us also define $H(Z,s)=S(Z)-s$ and $h(s) = \mathrm{E}_{Z|Y;\hat{\theta}(s)}(S(Z))-s$.</span>
<span id="cb14-725"><a href="#cb14-725" aria-hidden="true" tabindex="-1"></a>Assumptions $(M1')$ and $(M2')$  imply that assumptions  $(M1)$ and $(M2)$ of Theorem 5 of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span> are  fulfilled. Indeed these assumptions focus on expressions and regularity properties of the individual likelihood functions and the corresponding sufficient statistics for each index $i \in <span class="sc">\{</span>1,\ldots,n<span class="sc">\}</span>$. Then by linearity of the log-likelihood function and of the stochastic approximation and applying Theorem 5 of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>, we get that $\lim_k d(\theta_k,\mathcal{L})=0$. </span>
<span id="cb14-726"><a href="#cb14-726" aria-hidden="true" tabindex="-1"></a>Moreover we get that for $1 \leq i \leq n$, each sequence $(s_i^k)$ converges almost surely toward $\mathrm{E}_{Z_i|Y_i;\theta} (S_i(Z_i) )$.</span>
<span id="cb14-727"><a href="#cb14-727" aria-hidden="true" tabindex="-1"></a>Since  assumption $(M2')$ ensures that for all $1 \leq i \leq n$ the functions $\psi_i$ and $\phi_i$ are twice continuously differentiable and assumption $(M5)$ ensures that the function $\hat{\theta}$ is continuously differentiable, the function $\Phi_n$ defined by $\Phi_n(s^{k})=\frac1{n}\sum_{i=1}^n \hat{\Delta}_i(s^{k})\hat{\Delta}_i(s^{k})$ is continuous. Therefore  we get that $\lim_k d(I_{n,sco}^k,\mathcal{I})=0$.</span>
<span id="cb14-728"><a href="#cb14-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-729"><a href="#cb14-729" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-730"><a href="#cb14-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-731"><a href="#cb14-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-732"><a href="#cb14-732" aria-hidden="true" tabindex="-1"></a>We now establish the asymptotic normality of the estimate $\bar{I}_{n,sco}^k$ defined as $\bar{I}_{n,sco}^k=\Phi_n(\bar{s}^{k})$ with $\bar{s}^{k}=\sum_{l=1}^k s^l /k$ using the results stated by <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>.  Let us denote by $Vect(A)$ the vector composed of the elements of the triangular superior part of matrix $A$ ordered by columns.</span>
<span id="cb14-733"><a href="#cb14-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-734"><a href="#cb14-734" aria-hidden="true" tabindex="-1"></a>::: {#thm-conv2}</span>
<span id="cb14-735"><a href="#cb14-735" aria-hidden="true" tabindex="-1"></a>Assume that $(M1')$ and  $(M2')$,  $(M3)$ to  $(M5)$, $(SAEM1)$,  $(SAEM2)$,  $(SAEM3)$, $(SAEM4)$, $(SAEM4')$ and $(LOC1)$ to $(LOC3)$ are fulfilled.  Then, there exists a regular stable stationary point $\theta^* \in \Theta$ such that $\lim_k \theta_k=\theta^*$ a.s. Moreover  the sequence $(\sqrt{k}(Vect(\bar{I}_{n,sco}^k)-Vect(\bar{I}_{n,sco}(\theta^*))))\mathbb{1}_{\lim \| \theta_k-\theta^*\|=0 }$ converges in distribution toward a centered Gaussian random vector  when $k$ goes to infinity. The asymptotic covariance matrix is characterized.  </span>
<span id="cb14-736"><a href="#cb14-736" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-737"><a href="#cb14-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-738"><a href="#cb14-738" aria-hidden="true" tabindex="-1"></a>::: {.proof}</span>
<span id="cb14-739"><a href="#cb14-739" aria-hidden="true" tabindex="-1"></a>The proof follows the lines of this of Theorem 7 of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>. </span>
<span id="cb14-740"><a href="#cb14-740" aria-hidden="true" tabindex="-1"></a>Assumptions $(LOC1)$ to $(LOC3)$ are those of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span> and  ensure the existence of a regular stable stationary point $s^*$ for $h$ and therefore of $\theta^*=\hat{\theta}(s^*)$ for the observed log-likelihood $l$. Then applying Theorem 4 of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span>, we get that:</span>
<span id="cb14-741"><a href="#cb14-741" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-742"><a href="#cb14-742" aria-hidden="true" tabindex="-1"></a>\sqrt{k}( \bar{s}^k - s^*) \mathbb{1}_{\lim \| s^k-s^*\|=0 } \overset{\mathcal{L}}{ \rightarrow} \mathcal{N}(0, J(s^*)^{-1}  \Gamma(s^*) J(s^*)^{-1}  )\mathbb{1}_{\lim \| s_k-s^*\|=0 }</span>
<span id="cb14-743"><a href="#cb14-743" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-744"><a href="#cb14-744" aria-hidden="true" tabindex="-1"></a>where the function $\Gamma$ defined in assumption $(SAEM4')$ and $J$ is the Jacobian matrix of the function $h$. </span>
<span id="cb14-745"><a href="#cb14-745" aria-hidden="true" tabindex="-1"></a>Applying the Delta method, we get that:</span>
<span id="cb14-746"><a href="#cb14-746" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-747"><a href="#cb14-747" aria-hidden="true" tabindex="-1"></a>\sqrt{k}( Vect(\Phi_n(\bar{s}^k)) - Vect(\Phi_n(s^*))) \mathbb{1}_{\lim \| s^k-s^*\|=0 } \overset{\mathcal{L}}{ \rightarrow} W\mathbb{1}_{\lim \| s^k-s^*\|=0 }</span>
<span id="cb14-748"><a href="#cb14-748" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-749"><a href="#cb14-749" aria-hidden="true" tabindex="-1"></a>where $W \sim \mathcal{N}(0, \partial Vect(\Phi_n (s^*)) J(s^*)^{-1}  \Gamma(s^*) J(s^*)^{-1} \partial Vect(\Phi_n (s^*))^t )$ which leads to the result.</span>
<span id="cb14-750"><a href="#cb14-750" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb14-751"><a href="#cb14-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-752"><a href="#cb14-752" aria-hidden="true" tabindex="-1"></a>Note that as usually in stochastic approximation results, the rate $\sqrt{k}$ is achieved when considering an average estimator (see Theorem 7 of <span class="co">[</span><span class="ot">@Delyon1999</span><span class="co">]</span> *e.g*). </span>
<span id="cb14-753"><a href="#cb14-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-754"><a href="#cb14-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-755"><a href="#cb14-755" aria-hidden="true" tabindex="-1"></a>It is assumed that the random variables $s^0, z_1, z_2, \cdots$ are </span>
<span id="cb14-756"><a href="#cb14-756" aria-hidden="true" tabindex="-1"></a>defined on the same probability space $(\Omega, \mathcal{A}, P)$. We denote $\mathcal{F} = <span class="sc">\{</span> \mathcal{F}_k \}_{k \geq 0}$ the increasing family of </span>
<span id="cb14-757"><a href="#cb14-757" aria-hidden="true" tabindex="-1"></a>$\sigma$-algebras generated by the random variables $s_0, z_1, z_2, \cdots, z_k$. We assume the following conditions:</span>
<span id="cb14-758"><a href="#cb14-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-759"><a href="#cb14-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-760"><a href="#cb14-760" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(M1')** The parameter space $\Theta$ is an open subset of $\mathbb{R}^{p}$. The individual complete data likelihood function is given for all $i=1,\ldots,n$  by:</span>
<span id="cb14-761"><a href="#cb14-761" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-762"><a href="#cb14-762" aria-hidden="true" tabindex="-1"></a>f_i(z_i;\theta)</span>
<span id="cb14-763"><a href="#cb14-763" aria-hidden="true" tabindex="-1"></a>= \exp\left(-\psi_i(\theta) + \left&lt;S_i(z_i),\phi_i(\theta)\right&gt;\right),</span>
<span id="cb14-764"><a href="#cb14-764" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-765"><a href="#cb14-765" aria-hidden="true" tabindex="-1"></a>where  $\left&lt;\cdot,\cdot\right&gt;$ denotes the scalar product, $S_i$ is a Borel</span>
<span id="cb14-766"><a href="#cb14-766" aria-hidden="true" tabindex="-1"></a>function on $\mathbb{R}^{d_i}$  taking its values in an open subset $\mathcal{S}_i$ of $\mathbb{R}^{d_i}$, $\phi_i$ and $\psi_i$ are measurable function of $\Theta$ taking values in  open subsets of $\mathbb{R}^{d_i}$ and $\mathbb{R}$ respectively. Moreover, the convex hull of $S(\mathbb{R}^{\sum d_i})$  is included in $\mathcal{S}$ and for all $\theta \in \Theta$ $\int S(z) \prod p_i(z_i;\theta) \mu(dz) &lt; \infty$</span>
<span id="cb14-767"><a href="#cb14-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-768"><a href="#cb14-768" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(M2')** Define for each $i$ $L_i : \mathcal{S}_i \times \Theta \to \mathbb{R}$ as $L_i(s_i; \theta)\triangleq - \psi_i(\theta) + \left&lt;s_i,\phi_i(\theta)\right&gt;$.The functions $\psi_i$ and $\phi_i$ are twice </span>
<span id="cb14-769"><a href="#cb14-769" aria-hidden="true" tabindex="-1"></a>continuously differentiable on $\Theta$. </span>
<span id="cb14-770"><a href="#cb14-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-771"><a href="#cb14-771" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(M3)** The function $\bar{s} : \Theta \rightarrow \mathcal{S}$ defined as</span>
<span id="cb14-772"><a href="#cb14-772" aria-hidden="true" tabindex="-1"></a>$\bar{s}(\theta) \triangleq \int S(z) p(z; \theta) \mu(dz)$ is continuously differentiable on $\Theta$.</span>
<span id="cb14-773"><a href="#cb14-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-774"><a href="#cb14-774" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(M4)** For all $1 \leq  i\leq n$ the function $l_i:\Theta \rightarrow \mathbb{R}$ defined as </span>
<span id="cb14-775"><a href="#cb14-775" aria-hidden="true" tabindex="-1"></a>$l_i(\theta)  = \log \int f_i(z_i;\theta) \mu_i(dz_i)$ is continuously differentiable on $\Theta$ and $\partial_\theta \int f_i(z_i; \theta) \mu_i(dz_i)= \int \partial_\theta f_i(z_i; \theta)  \mu_i(dz_i)$.</span>
<span id="cb14-776"><a href="#cb14-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-777"><a href="#cb14-777" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(M5)** There exists a continuously differentiable function</span>
<span id="cb14-778"><a href="#cb14-778" aria-hidden="true" tabindex="-1"></a>$\widehat{\theta} : \ \mathcal{S} \rightarrow \Theta$, such that:</span>
<span id="cb14-779"><a href="#cb14-779" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb14-780"><a href="#cb14-780" aria-hidden="true" tabindex="-1"></a>\forall s \in \mathcal{S}, \ \  \forall \theta \in \Theta, \ \ </span>
<span id="cb14-781"><a href="#cb14-781" aria-hidden="true" tabindex="-1"></a>L(s; \widehat{\theta}(s))\geq L(s; \theta).</span>
<span id="cb14-782"><a href="#cb14-782" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb14-783"><a href="#cb14-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-784"><a href="#cb14-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-785"><a href="#cb14-785" aria-hidden="true" tabindex="-1"></a>In addition, we define:</span>
<span id="cb14-786"><a href="#cb14-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-787"><a href="#cb14-787" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(SAEM1)** For all $k$ in $\mathbb{N}$, $\gamma_k \in <span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, </span>
<span id="cb14-788"><a href="#cb14-788" aria-hidden="true" tabindex="-1"></a>$\sum_{k=1}^\infty \gamma_k = \infty$ and  $\sum_{k=1}^\infty \gamma_k^2 &lt; \infty$.</span>
<span id="cb14-789"><a href="#cb14-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-790"><a href="#cb14-790" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(SAEM2)**  $l:\Theta  \rightarrow  \mathbb{R}$ and  $\widehat{\theta} :  \mathcal{S} \rightarrow \Theta$ are $m$ times differentiable, where $m$ is the integer such that $\mathcal{S}$ is an open subset of $\mathbb{R}^m$. </span>
<span id="cb14-791"><a href="#cb14-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-792"><a href="#cb14-792" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(SAEM3)** For all positive Borel functions $\Phi$, we have $E<span class="co">[</span><span class="ot"> \Phi( z_{k+1}) | \mathcal{F}_k </span><span class="co">]</span> = \int \Phi( z  ) p ( z; \theta_k) \mu( dz).$</span>
<span id="cb14-793"><a href="#cb14-793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-794"><a href="#cb14-794" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(SAEM4)** For all $\theta \in \Theta$, $\mathrm{E}_\theta(\|S(Z)\|^{2})&lt; \infty$, and the function </span>
<span id="cb14-795"><a href="#cb14-795" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-796"><a href="#cb14-796" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb14-797"><a href="#cb14-797" aria-hidden="true" tabindex="-1"></a>\Gamma(\theta) \triangleq \mathrm{Cov}_\theta <span class="co">[</span><span class="ot">S(z)</span><span class="co">]</span>\triangleq &amp;\int</span>
<span id="cb14-798"><a href="#cb14-798" aria-hidden="true" tabindex="-1"></a>S(z)^t S(z) p(z;\theta)\mu(dz)<span class="sc">\\</span></span>
<span id="cb14-799"><a href="#cb14-799" aria-hidden="true" tabindex="-1"></a>&amp;-\left<span class="co">[</span><span class="ot">\int S(z)p(z;\theta)\mu(dz)\right</span><span class="co">]</span>^t\left<span class="co">[</span><span class="ot">\int S(z)p(z;\theta)\mu(dz)\right</span><span class="co">]</span></span>
<span id="cb14-800"><a href="#cb14-800" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb14-801"><a href="#cb14-801" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb14-802"><a href="#cb14-802" aria-hidden="true" tabindex="-1"></a>is continuous w.r.t. $\theta$, where $\mathrm{E}_\theta$ stands for the expectation with respect to the posterior distribution $p(\cdot;\theta)$.</span>
<span id="cb14-803"><a href="#cb14-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-804"><a href="#cb14-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-805"><a href="#cb14-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-806"><a href="#cb14-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-807"><a href="#cb14-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-808"><a href="#cb14-808" aria-hidden="true" tabindex="-1"></a>We also define assumptions required for the normality result:</span>
<span id="cb14-809"><a href="#cb14-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-810"><a href="#cb14-810" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(SAEM1')** There exist $\gamma^*&gt;0$ and $1/2&lt; \alpha&lt;1$ such that $\lim k^\alpha /\gamma_k =\gamma^*$, and $\gamma_k / \gamma_{k+1}=1 + O(k^{-1})$.</span>
<span id="cb14-811"><a href="#cb14-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-812"><a href="#cb14-812" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(SAEM4')** For some $\varepsilon&gt;0$, $\sup_\theta \mathrm{E}_\theta(\|S(Z)\|^{2+\varepsilon})&lt; \infty$ and $\theta \rightarrow \Gamma(\theta)$ is continuous w.r.t. $\theta$. </span>
<span id="cb14-813"><a href="#cb14-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-814"><a href="#cb14-814" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(LOC1)** The stationary points of $l$ are isolated: any compact subset of $\Theta$ contains only a finite number of such points.</span>
<span id="cb14-815"><a href="#cb14-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-816"><a href="#cb14-816" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(LOC2)** For every stationary point $\theta^*$, the matrices $\mathrm{E}_\theta^*(\partial_\theta L(S(Z),\theta^*) (\partial_\theta L(S(Z),\theta^*))^t)$  and $\partial_\theta^2  L(\mathrm{E}_\theta^* (S(Z)),\theta^*)$ are positive definite.</span>
<span id="cb14-817"><a href="#cb14-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-818"><a href="#cb14-818" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**(LOC3)** The minimum eigenvalue of the covariance matrix $R(\theta)=\mathrm{E}_\theta((S(Z)-\bar{s}(\theta))(S(Z)-\bar{s}(\theta))^t)$</span>
<span id="cb14-819"><a href="#cb14-819" aria-hidden="true" tabindex="-1"></a>is bounded away from zero for $\theta$ in any compact subset of $\Theta$.</span>
<span id="cb14-820"><a href="#cb14-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-821"><a href="#cb14-821" aria-hidden="true" tabindex="-1"></a><span class="fu">## R functions</span></span>
<span id="cb14-822"><a href="#cb14-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-823"><a href="#cb14-823" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exact computation of the Fisher information matrix in the linear mixed effects model {#sec-R-exactFIMLMM}</span></span>
<span id="cb14-824"><a href="#cb14-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-827"><a href="#cb14-827" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-828"><a href="#cb14-828" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-829"><a href="#cb14-829" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: functions/Fisher_LMM.R</span></span>
<span id="cb14-830"><a href="#cb14-830" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: LMM-exactFIM-function-show</span></span>
<span id="cb14-831"><a href="#cb14-831" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-832"><a href="#cb14-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-833"><a href="#cb14-833" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fisher information matrix extimation in the linear mixed effects model {#sec-R-estFIMLMM}</span></span>
<span id="cb14-834"><a href="#cb14-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-837"><a href="#cb14-837" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-838"><a href="#cb14-838" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-839"><a href="#cb14-839" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: functions/Isco_LMM.R</span></span>
<span id="cb14-840"><a href="#cb14-840" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: LMM-Isco-function-show</span></span>
<span id="cb14-841"><a href="#cb14-841" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-842"><a href="#cb14-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-845"><a href="#cb14-845" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-846"><a href="#cb14-846" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-847"><a href="#cb14-847" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: functions/Iobs_LMM.R</span></span>
<span id="cb14-848"><a href="#cb14-848" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: LMM-Iobs-function-show</span></span>
<span id="cb14-849"><a href="#cb14-849" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-850"><a href="#cb14-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-851"><a href="#cb14-851" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fisher information matrix estimation in the Poisson mixture model {#sec-R-estFIMPoisson}</span></span>
<span id="cb14-852"><a href="#cb14-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-855"><a href="#cb14-855" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-856"><a href="#cb14-856" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-857"><a href="#cb14-857" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: functions/fisher_estimation_poisson_mixture.R</span></span>
<span id="cb14-858"><a href="#cb14-858" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuPoissonMixture-function-show</span></span>
<span id="cb14-859"><a href="#cb14-859" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-860"><a href="#cb14-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-861"><a href="#cb14-861" aria-hidden="true" tabindex="-1"></a><span class="fu">### SAEM algorithm in the PK model belonging to the curved exponential family {#sec-R-saemNLMEexp}</span></span>
<span id="cb14-862"><a href="#cb14-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-865"><a href="#cb14-865" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-866"><a href="#cb14-866" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-867"><a href="#cb14-867" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: functions/saem_nlme_exponential_bis.R</span></span>
<span id="cb14-868"><a href="#cb14-868" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuNlmeExp-function-show</span></span>
<span id="cb14-869"><a href="#cb14-869" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-870"><a href="#cb14-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-871"><a href="#cb14-871" aria-hidden="true" tabindex="-1"></a><span class="fu">### SAEM algorithm in the PK model not belonging to the curved exponential family {#sec-R-saemNLMEnonexp}</span></span>
<span id="cb14-872"><a href="#cb14-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-875"><a href="#cb14-875" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-876"><a href="#cb14-876" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-877"><a href="#cb14-877" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: functions/saem_nlme_non_exponential.R</span></span>
<span id="cb14-878"><a href="#cb14-878" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuNlmeNonExp-function-show</span></span>
<span id="cb14-879"><a href="#cb14-879" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-880"><a href="#cb14-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-881"><a href="#cb14-881" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fisher information matrix estimation in the Gaussian mixture model {#sec-R-estFIMGaussian}</span></span>
<span id="cb14-882"><a href="#cb14-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-885"><a href="#cb14-885" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb14-886"><a href="#cb14-886" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb14-887"><a href="#cb14-887" aria-hidden="true" tabindex="-1"></a><span class="co">#| file: functions/fisher_estimation_gaussian_mixture.R</span></span>
<span id="cb14-888"><a href="#cb14-888" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: simuGaussianMixture-function-show</span></span>
<span id="cb14-889"><a href="#cb14-889" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>